{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02c05ab",
   "metadata": {},
   "source": [
    "# Load and test trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f7996",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5114873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from enduro_lstm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc320a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_cuda(use_cuda):\n",
    "    \n",
    "    if use_cuda:\n",
    "        \n",
    "        # torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "        is_cuda = torch.cuda.is_available()\n",
    "\n",
    "        # If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "        if is_cuda:\n",
    "            device = torch.device(\"cuda\")\n",
    "            print(\"GPU is available\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            print(\"GPU not available, CPU used\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Selected CPU\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c87a302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CPU\n"
     ]
    }
   ],
   "source": [
    "device = conf_cuda(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea85b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec63db4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dadaf8",
   "metadata": {},
   "source": [
    "## Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c6fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_teste_m1_f1to1030_epoch5000_H200\n",
      "loss_file.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir_path = \"models/CNN_teste_m1_f1to1030_epoch5000_H200\" + \"/\"\n",
    "arr = os.listdir(f'./{dir_path}')\n",
    "for i in range(len(arr)):\n",
    "    print(arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9374a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = dir_path + \"CNN_teste_m1_f1to1030_epoch5000_H200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5140a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_match = 9\n",
    "end_match = 9\n",
    "\n",
    "hidden_neurons = 200\n",
    "zigzag = False\n",
    "is_softmax = True\n",
    "\n",
    "start_frame = 1\n",
    "end_frame = 1030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8746a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"../1-generate/data/\"\n",
    "\n",
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57340087",
   "metadata": {},
   "outputs": [],
   "source": [
    "if zigzag:\n",
    "    output_size = 2\n",
    "else:\n",
    "    output_size = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf3c89",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c560225",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1067126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_model import *\n",
    "from setup_model_types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde9ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, filename='checkpoint.pth.tar'):\n",
    "    \n",
    "    print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "    checkpoint = torch.load(filename, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    return model, checkpoint['optimizer']['state'][0]['step'], checkpoint['losslogger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e43baa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-77d7af1e851c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNNLSTMModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_neurons\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_logger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\UnB\\tcc\\rnn_enduro\\2-pytorch_train\\setup_model_types.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, device, input_shape, output_size, hidden_dim, n_layers)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mCNNLSTMModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCNNLSTMModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = CNNLSTMModel(device=device, input_shape=(1,1,100,100), output_size=output_size, hidden_dim=hidden_neurons, n_layers=1)\n",
    "model, last_epoch, last_logger = load_checkpoint(model, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ff1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_LIST = get_actions_list(zigzag=zigzag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_frames_arr = []\n",
    "frames_arr = []\n",
    "actions_arr = []\n",
    "\n",
    "start_frame = 1\n",
    "end_frame = 1000\n",
    "\n",
    "for m in range(start_match, end_match + 1):\n",
    "    \n",
    "    num_of_frames, frames, actions, rewards, lifes = load_npz(data_path, m)\n",
    "    frames = frames[start_frame - 1:end_frame, 30:130, 10:110]\n",
    "    actions = actions[start_frame - 1:end_frame]\n",
    "    \n",
    "    action_one_hot = [prepare_action_data(i, ACTIONS_LIST) for i in actions]\n",
    "    actions = np.array(action_one_hot)\n",
    "    actions = actions.reshape(len(actions), -1)\n",
    "    \n",
    "    frames_arr.append(frames)\n",
    "    actions_arr.append(actions)\n",
    "    num_of_frames_arr.append(end_frame - start_frame + 1) \n",
    "\n",
    "X_train = np.array(frames_arr)/255\n",
    "Y_train = np.array(actions_arr)\n",
    "num_of_frames_arr = np.array(num_of_frames_arr)\n",
    "\n",
    "X_train = torch.tensor(X_train).float()\n",
    "Y_train = torch.tensor(Y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1, end_frame-start_frame+1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1aa4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d55682",
   "metadata": {},
   "source": [
    "## Prepare cell with trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2147390",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=(3,3))\n",
    "activation = nn.ReLU()\n",
    "bnorm = nn.BatchNorm2d(num_features=3)\n",
    "pool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "\n",
    "lstmcell = nn.LSTMCell(49*49*3, hidden_neurons)\n",
    "linear = nn.Linear(hidden_neurons, output_size)\n",
    "output = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a08a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935d5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmcell.weight_ih = model.lstm.weight_ih_l0\n",
    "lstmcell.weight_hh = model.lstm.weight_hh_l0\n",
    "lstmcell.bias_hh = model.lstm.bias_hh_l0\n",
    "lstmcell.bias_ih = model.lstm.bias_ih_l0\n",
    "linear.weight = model.fc.weight\n",
    "linear.bias = model.fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99940fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hx = torch.zeros(1, hidden_neurons)\n",
    "cx = torch.zeros(1, hidden_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f1274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.lstm.weight_ih_l0.shape)\n",
    "print(model.lstm.weight_hh_l0.shape)\n",
    "print(model.lstm.bias_ih_l0.shape)\n",
    "print(model.lstm.bias_hh_l0.shape)\n",
    "print(model.fc.weight.shape)\n",
    "print(model.fc.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac739f7",
   "metadata": {},
   "source": [
    "## Testing outputs of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c231c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "Y_train = torch.tensor(Y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b59dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d988171",
   "metadata": {},
   "outputs": [],
   "source": [
    "hx = torch.zeros(1, hidden_neurons)\n",
    "out_arr = []\n",
    "for i in range(1000):\n",
    "    step_input = X_train[0][i]\n",
    "    step_input = step_input.view(1, 1, 100, 100)\n",
    "    step_input = pool(bnorm(activation(conv(step_input))))\n",
    "    step_input = step_input.reshape(1, -1)\n",
    "    hx, cx = lstmcell(step_input, (hx,cx))\n",
    "    out = linear(hx)\n",
    "    out = output(out)\n",
    "    out_arr.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71facede",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape(-1, len(ACTIONS_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4844170d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acertou = 0\n",
    "errou = 0\n",
    "for i in range(1000):\n",
    "    if torch.argmax(Y_train[i]) == torch.argmax(out_arr[i]):\n",
    "        acertou += 1\n",
    "    else:\n",
    "        errou += 1\n",
    "        \n",
    "print(acertou)\n",
    "print(errou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acertou/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308ded2",
   "metadata": {},
   "source": [
    "## Play Gym Enduro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd5989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64a6b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if zigzag:\n",
    "        \n",
    "    ACTIONS = {\n",
    "        \"right\": 2,\n",
    "        \"left\": 3,\n",
    "    }\n",
    "\n",
    "else:\n",
    "\n",
    "    ACTIONS = {\n",
    "        \"noop\": 0,\n",
    "        \"accelerate\": 1,\n",
    "        \"right\": 2,\n",
    "        \"left\": 3,\n",
    "        \"break\": 4,\n",
    "        \"right_break\": 5,\n",
    "        \"left_break\": 6,\n",
    "        \"right_accelerate\": 7,\n",
    "        \"left_accelerate\": 8,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec251108",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_min, y_max, x_min, x_max = 30, 130, 10, 110\n",
    "shape_of_single_frame = (1, (y_max-y_min),(x_max-x_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39688ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_time = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ece84",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Enduro-v0\")\n",
    "frame = env.reset()\n",
    "reward, action, done, info = 0, 0, False, {'ale.lives': 0}\n",
    "\n",
    "hx = torch.zeros(1, hidden_neurons)\n",
    "cx = torch.zeros(1, hidden_neurons)\n",
    "\n",
    "env.render()\n",
    "time.sleep(1)\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    time.sleep(sleep_time)\n",
    "    env.render()\n",
    "    \n",
    "    frame = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    frame = Image.fromarray(frame)\n",
    "    frame = frame.convert(\"L\")\n",
    "    \n",
    "    frame = np.asarray(frame)\n",
    "    frame = frame.reshape(1, -1)\n",
    "    frame = torch.tensor(frame)/255\n",
    "    \n",
    "    hx = lstmcell(frame, hx)\n",
    "    out = linear(hx)\n",
    "    action = output(out)\n",
    "    \n",
    "    action = list(ACTIONS.values())[torch.argmax(action, axis=1)]\n",
    "    print(action)\n",
    "    frame, reward, done, info = env.step(action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
