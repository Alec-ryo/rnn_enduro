{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d651e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[  0,  62,  80, 106, 117, 137, 142, 156, 159, 166, 185, 215, 226, 235, 242, 252, 259, 279, 281, 292, 296, 299, \n",
    "            303, 308, 315, 318, 321, 329, 333, 335, 354, 360, 374, 377, 382, 386, 390, 393, 402, 414, 420, 444, 447, 465, \n",
    "            469, 487, 491, 504, 506, 510, 513, 525, 528, 538, 552, 558, 570, 576, 581, 584, 588, 595, 598, 604, 607, 610, \n",
    "            618, 619, 622, 631, 641, 645, 662, 672, 685, 693, 697, 704, 718, 724, 726, 735, 739, 745, 754, 755, 770, 773, \n",
    "            789, 790, 799, 805, 809, 823, 834, 850, 854, 857, 868, 874, 875, 877, 883, 885, 904, 906, 911, 919, 923, 926, \n",
    "            932, 943, 962, 965, 984, 991, 999, 1007, 1010, 1015, 1017, 1018],\n",
    "           [  0,  31,  45,  47,  56,  63,  69,  85,  88,  92,  96, 112, 118, 124, 130, 137, 143, 151, 158, 170, 184, 202, \n",
    "            223, 243, 249, 255, 260, 269, 272, 275, 276, 282, 285, 295, 296, 297, 306, 308, 318, 322, 331, 334, 337, 338, \n",
    "            341, 343, 354, 357, 381, 387, 400, 402, 408, 420, 423, 426, 429, 441, 443, 445, 448, 454, 463, 465, 474, 481,\n",
    "            502, 506, 524, 533, 538, 548, 556, 562, 566, 570, 581, 588, 603, 604, 609, 652, 668, 681, 698, 710, 714, 725, \n",
    "            729, 736, 739, 743, 748, 749, 752, 766, 770, 774, 778, 781, 792, 795, 803, 804, 806, 814, 818, 821, 828, 834, \n",
    "            837, 843, 849, 855, 862, 868, 874, 884, 888, 895, 896, 919, 935, 942, 945, 957, 958, 963, 964, 965, 977, 980,\n",
    "            984, 989, 997, 1000], \n",
    "           [  0,  37,  53,  81,  94,  99, 119, 123, 124, 142, 144, 146, 162, 193, 211, 213, 222, 230, 232, 235, 238, 240, \n",
    "            252, 255, 258, 267, 270, 275, 278, 284, 287, 289, 300, 307, 313, 331, 352, 359, 371, 379, 386, 389, 392, 409, \n",
    "            412, 432, 435, 440, 442, 446, 462, 467, 472, 506, 527, 531, 535, 553, 557, 561, 571, 579, 589, 602, 607, 609, \n",
    "            612, 616, 621, 631, 634, 638, 640, 644, 645, 661, 669, 673, 676, 692, 695, 698, 701, 711, 717, 720, 721, 734, \n",
    "            744, 747, 750, 755, 759, 774, 785, 793, 807, 859, 891, 895, 912, 927, 948, 958, 969, 980, 997, 998, 1004], \n",
    "           [  0,  33,  58,  75,  86, 100, 118, 120, 139, 142, 147, 159, 162, 165, 167, 174, 179, 180, 183, 192, 197, 199, \n",
    "            209, 214, 217, 222, 227, 231, 232, 239, 244, 251, 262, 266, 271, 275, 277, 282, 287, 291, 294, 297, 308, 311, \n",
    "            316, 318, 322, 327, 339, 342, 348, 352, 362, 372, 383, 397, 399, 402, 405, 417, 420, 425, 428, 454, 457, 464, \n",
    "            470, 477, 481, 485, 488, 494, 495, 503, 507, 517, 535, 537, 540, 553, 556, 558, 577, 588, 598, 601, 609, 620, \n",
    "            634, 638, 647, 650, 656, 659, 660, 663, 669, 672, 681, 684, 696, 702, 705, 708, 716, 719, 726, 730, 739, 743, \n",
    "            746, 758, 765, 766, 777, 783, 785, 786, 790, 792, 800, 802, 808, 809, 810, 816, 819, 823, 827, 835, 837, 842, \n",
    "            845, 853, 865, 868, 873, 885, 889, 891, 897, 904, 906, 918, 941, 949, 956, 961, 969, 973, 976, 981, 984, 991, \n",
    "            996, 999, 1002], \n",
    "           [  0,  59,  68,  73,  76,  86,  94,  97, 101, 104, 109, 118, 120, 123, 128, 134, 136, 139, 143, 145, 148, 154, \n",
    "            160, 162, 177, 190, 195, 199, 204, 208, 212, 220, 221, 222, 232, 234, 246, 251, 253, 256, 263, 270, 273, 287, \n",
    "            302, 314, 322, 355, 357, 368, 396, 397, 401, 416, 428, 433, 437, 442, 446, 452, 456, 469, 475, 490, 500, 506, \n",
    "            525, 526, 538, 545, 551, 554, 558, 562, 571, 579, 582, 586, 587, 600, 612, 664, 823, 824, 832, 850, 858, 870, \n",
    "            879, 881, 889, 898, 901, 913, 916, 924, 932, 936, 943, 952, 955, 975, 985, 992, 997, 1001], \n",
    "           [  0,  36,  56,  94, 114, 121, 136, 140, 143, 153, 159, 162, 171, 174, 182, 190, 197, 201, 215, 219, 237, 239, \n",
    "            249, 251, 254, 265, 269, 297, 322, 335, 340, 343, 348, 352, 355, 363, 368, 371, 375, 384, 388, 395, 405, 411, \n",
    "            439, 461, 464, 468, 477, 483, 485, 487, 494, 497, 501, 503, 514, 519, 521, 526, 529, 532, 538, 547, 551, 555, \n",
    "            560, 579, 584, 597, 600, 602, 607, 609, 617, 623, 626, 634, 638, 644, 649, 652, 663, 671, 672, 675, 678, 685, \n",
    "            688, 699, 700, 712, 719, 724, 726, 735, 744, 753, 756, 775, 797, 806, 812, 818, 826, 829, 832, 848, 852, 856, \n",
    "            866, 869, 872, 875, 881, 886, 891, 893, 895, 901, 910, 930, 936, 940, 953, 958, 989, 997, 1004, 1006] \n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9288d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5af879df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34dfd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seq = 5\n",
    "maior = 0\n",
    "for i in range(len(indices[num_seq]) - 1):\n",
    "    tam = indices[num_seq][i+1] - indices[num_seq][i]\n",
    "    if tam > maior:\n",
    "        maior = tam\n",
    "maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab76759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "menor = 0\n",
    "for i in range(len(indices[0]) - 1):\n",
    "    tam = indices[0][i+1] - indices[0][i]\n",
    "    if tam < menor:\n",
    "        menor = tam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef63b959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca2db87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "424d42a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da9da07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c9b70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb25d2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f23226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from enduro_lstm import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7084614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU (y/n) y\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "use_gpu = input(\"Use GPU (y/n) \")\n",
    "\n",
    "if use_gpu == 'y':\n",
    "    use_gpu = True\n",
    "else:\n",
    "    use_gpu = False\n",
    "    \n",
    "device = conf_cuda(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8adb5d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escreva uma observacao (sem espaco): teste_lstm\n"
     ]
    }
   ],
   "source": [
    "obs = input('escreva uma observacao (sem espaco): ')\n",
    "\n",
    "if obs == 'zigzag':\n",
    "    zigzag = True\n",
    "else:\n",
    "    zigzag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90a27ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epochs: 300\n",
      "number of hidden neurons: 200\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"../1-generate/data/\"\n",
    "n_epochs = int(input(\"number of epochs: \") ) #5000\n",
    "hidden_neurons = int(input(\"number of hidden neurons: \")) #500\n",
    "stop_train = 1e-5\n",
    "\n",
    "# start_match = int(input(\"start match: \")) #45\n",
    "# end_match = int(input(\"end match: \")) #49\n",
    "\n",
    "start_match = 0\n",
    "end_match = 0\n",
    "\n",
    "# start_frame = int(input(\"start frame: \")) #1\n",
    "# end_frame = int(input(\"end frame: \")) #1000\n",
    "\n",
    "start_frame = 1\n",
    "end_frame = 120\n",
    "\n",
    "is_softmax = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a76d211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/teste_lstm_m0to0_f1to120_epoch300_H200 created\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{obs}_m{start_match}to{end_match}_f{start_frame}to{end_frame}_epoch{n_epochs}_H{hidden_neurons}\"\n",
    "newpath = f\"models/\" + model_name\n",
    "if not os.path.exists(newpath):\n",
    "    print(f\"models/\" + model_name + \" created\")\n",
    "    os.makedirs(newpath)\n",
    "else:\n",
    "    print(f\"models/\" + model_name)\n",
    "    print(\"ATTENTION! folder not created. Training informations will overwrite the existing one\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ebe3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_LIST = get_actions_list(zigzag=zigzag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "556bf9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded NPZ.\n"
     ]
    }
   ],
   "source": [
    "num_of_frames_arr = []\n",
    "frames_arr = []\n",
    "actions_arr = []\n",
    "\n",
    "for m in range(start_match, end_match + 1):\n",
    "    \n",
    "    num_of_frames, frames, actions, rewards, lifes = load_npz(data_path, m)\n",
    "    frames = frames[start_frame - 1:end_frame]\n",
    "    frames = frames.reshape(end_frame - start_frame + 1, 170, 120)\n",
    "    frames = frames[:, 30:130, :]\n",
    "    frames = frames.reshape(end_frame - start_frame + 1, 12000)\n",
    "    actions = actions[start_frame - 1:end_frame]\n",
    "    \n",
    "    action_one_hot = [prepare_action_data(i, ACTIONS_LIST) for i in actions]\n",
    "    actions = np.array(action_one_hot)\n",
    "    actions = actions.reshape(len(actions), -1)\n",
    "    \n",
    "    frames_arr.append(frames)\n",
    "    actions_arr.append(actions)\n",
    "    num_of_frames_arr.append(end_frame - start_frame + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "695e2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunked = []\n",
    "target_chunked = []\n",
    "for i in range(len(frames_arr)):\n",
    "    for j in range(len(indices[i]) - 1):\n",
    "        data_chunked.append(frames_arr[i][indices[i][j]:indices[i][j+1]])\n",
    "        target_chunked.append(actions_arr[i][indices[i][j]:indices[i][j+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "264fbd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alece\\miniconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\alece\\miniconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(data_chunked)/255\n",
    "Y_train = np.array(target_chunked)\n",
    "num_of_frames_arr = np.array(num_of_frames_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae9dcdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtrado = []\n",
    "Y_train_filtrado = []\n",
    "for i in range(len(X_train)):\n",
    "    if len(X_train[i]) > 100:\n",
    "        pass\n",
    "    else:\n",
    "        X_train_filtrado.append(X_train[i])\n",
    "        Y_train_filtrado.append(Y_train[i])\n",
    "X_train = X_train_filtrado\n",
    "Y_train = Y_train_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186224ae",
   "metadata": {},
   "source": [
    "teste com zigzag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eecca307",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(frames_arr)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34b48f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = actions_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2d39b",
   "metadata": {},
   "source": [
    "voltando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec2b09cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(map(lambda x: torch.tensor(x), X_train))\n",
    "Y_train = list(map(lambda x: torch.tensor(x), Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "715fe2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([120.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = torch.FloatTensor(list(map(len,X_train)))\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fba98461",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequence(X_train, batch_first=True).float()\n",
    "Y_train = pad_sequence(Y_train, batch_first=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36e7d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pack_padded_sequence(X_train, seq_len, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ff029f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, device, input_size, output_size, hidden_dim, n_layers, is_softmax):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # self.h0 = torch.zeros(self.n_layers, 1, self.hidden_dim).to(self.device)\n",
    "        # self.c0 = torch.zeros(self.n_layers, 1, self.hidden_dim).to(self.device)\n",
    "\n",
    "        self.init_hidden()\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)  \n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        if is_softmax:\n",
    "            self.out = nn.Softmax()\n",
    "        else:\n",
    "            self.out = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # batch_size = x.size(0)\n",
    "        batch_size = 1\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        # hidden = self.init_hidden(batch_size)\n",
    "        # self.h0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        # self.c0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "\n",
    "        hidden = self.init_hidden()\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        # out, hidden = self.lstm(x)\n",
    "        \n",
    "        pad_embed_pack_lstm = self.lstm(x, hidden)\n",
    "        pad_embed_pack_lstm_pad = pad_packed_sequence(pad_embed_pack_lstm[0], batch_first=True)\n",
    "        \n",
    "        outs, lens = pad_embed_pack_lstm_pad\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = outs.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        out = self.out(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden_a = torch.randn(1, self.input_size, self.hidden_dim)\n",
    "        hidden_b = torch.randn(1, self.input_size, self.hidden_dim)\n",
    "\n",
    "        if self.device.type == 'cuda':\n",
    "            hidden_a = hidden_a.cuda()\n",
    "            hidden_b = hidden_b.cuda()\n",
    "\n",
    "        hidden_a = Variable(hidden_a)\n",
    "        hidden_b = Variable(hidden_b)\n",
    "\n",
    "        return (hidden_a, hidden_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4309aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(device=device, input_size=12000, output_size=len(ACTIONS_LIST), hidden_dim=hidden_neurons, n_layers=1, is_softmax=is_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac7f0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    X_train = X_train.cuda() \n",
    "    Y_train = Y_train.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b3a18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 1e-05\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04faee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_arr = np.array([])\n",
    "train_acc_arr = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5f89a34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/300-------------------------------------------\n",
      "Train -> Loss: 0.068408273160458 Acc: 0.500000000000000\n",
      "Epoch: 20/300-------------------------------------------\n",
      "Train -> Loss: 0.059207458049059 Acc: 0.525000035762787\n",
      "Epoch: 30/300-------------------------------------------\n",
      "Train -> Loss: 0.057216241955757 Acc: 0.500000000000000\n",
      "Epoch: 40/300-------------------------------------------\n",
      "Train -> Loss: 0.056603807955980 Acc: 0.483333349227905\n",
      "Epoch: 50/300-------------------------------------------\n",
      "Train -> Loss: 0.056408718228340 Acc: 0.500000000000000\n",
      "Epoch: 60/300-------------------------------------------\n",
      "Train -> Loss: 0.056275960057974 Acc: 0.500000000000000\n",
      "Epoch: 70/300-------------------------------------------\n",
      "Train -> Loss: 0.055801182985306 Acc: 0.516666710376740\n",
      "Epoch: 80/300-------------------------------------------\n",
      "Train -> Loss: 0.055477283895016 Acc: 0.616666674613953\n",
      "Epoch: 90/300-------------------------------------------\n",
      "Train -> Loss: 0.054883878678083 Acc: 0.766666710376740\n",
      "Epoch: 100/300-------------------------------------------\n",
      "Train -> Loss: 0.054208289831877 Acc: 0.808333396911621\n",
      "Epoch: 110/300-------------------------------------------\n",
      "Train -> Loss: 0.053276896476746 Acc: 0.833333373069763\n",
      "Epoch: 120/300-------------------------------------------\n",
      "Train -> Loss: 0.052062265574932 Acc: 0.866666734218597\n",
      "Epoch: 130/300-------------------------------------------\n",
      "Train -> Loss: 0.051164280623198 Acc: 0.858333349227905\n",
      "Epoch: 140/300-------------------------------------------\n",
      "Train -> Loss: 0.049708344042301 Acc: 0.883333384990692\n",
      "Epoch: 150/300-------------------------------------------\n",
      "Train -> Loss: 0.048198126256466 Acc: 0.916666686534882\n",
      "Epoch: 160/300-------------------------------------------\n",
      "Train -> Loss: 0.047044698148966 Acc: 0.916666686534882\n",
      "Epoch: 170/300-------------------------------------------\n",
      "Train -> Loss: 0.045772906392813 Acc: 0.933333396911621\n",
      "Epoch: 180/300-------------------------------------------\n",
      "Train -> Loss: 0.043988749384880 Acc: 0.950000047683716\n",
      "Epoch: 190/300-------------------------------------------\n",
      "Train -> Loss: 0.042399257421494 Acc: 0.950000047683716\n",
      "Epoch: 200/300-------------------------------------------\n",
      "Train -> Loss: 0.040748551487923 Acc: 0.966666698455811\n",
      "Epoch: 210/300-------------------------------------------\n",
      "Train -> Loss: 0.039440806955099 Acc: 0.966666698455811\n",
      "Epoch: 220/300-------------------------------------------\n",
      "Train -> Loss: 0.037677552551031 Acc: 0.975000023841858\n",
      "Epoch: 230/300-------------------------------------------\n",
      "Train -> Loss: 0.036143951117992 Acc: 0.975000023841858\n",
      "Epoch: 240/300-------------------------------------------\n",
      "Train -> Loss: 0.034514799714088 Acc: 0.975000023841858\n",
      "Epoch: 250/300-------------------------------------------\n",
      "Train -> Loss: 0.033178776502609 Acc: 0.983333408832550\n",
      "Epoch: 260/300-------------------------------------------\n",
      "Train -> Loss: 0.032010208815336 Acc: 0.991666734218597\n",
      "Epoch: 270/300-------------------------------------------\n",
      "Train -> Loss: 0.030488148331642 Acc: 0.991666734218597\n",
      "Epoch: 280/300-------------------------------------------\n",
      "Train -> Loss: 0.029827300459146 Acc: 0.991666734218597\n",
      "Epoch: 290/300-------------------------------------------\n",
      "Train -> Loss: 0.028373321518302 Acc: 1.000000000000000\n",
      "Epoch: 300/300-------------------------------------------\n",
      "Train -> Loss: 0.026957670226693 Acc: 1.000000000000000\n",
      "--- 67.35344934463501 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time_processing = time.time()\n",
    "\n",
    "# Training Run\n",
    "loss_file = open(newpath + '/' + \"loss_file.txt\", \"w\")\n",
    "first_time = True\n",
    "\n",
    "best_loss = 1\n",
    "first_epoch = True\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    X_train.to(device)\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, Y_train.view(-1,len(ACTIONS_LIST)).float())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordinglyw\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "\n",
    "        train_loss_arr = np.append(train_loss_arr, loss.item())\n",
    "        train_acc_arr  = np.append(train_acc_arr, get_acc(output, Y_train.reshape(-1, len(ACTIONS_LIST))))\n",
    "        # train_acc_arr  = np.append(train_acc_arr, get_acc_2(output, target_padded.reshape(-1, len(ACTIONS_LIST))))\n",
    "        \n",
    "        loss_file.write(\"Epoch: {}/{}-------------------------------------------\\n\".format(epoch, n_epochs))\n",
    "        loss_file.write(\"Train -> Loss: {:.15f} Acc: {:.15f}\\n\".format(train_loss_arr[-1], train_acc_arr[-1]))\n",
    "            \n",
    "        print(\"Epoch: {}/{}-------------------------------------------\".format(epoch, n_epochs))\n",
    "        print(\"Train -> Loss: {:.15f} Acc: {:.15f}\".format(train_loss_arr[-1], train_acc_arr[-1]))\n",
    "        \n",
    "        if train_loss_arr[-1] < best_loss:\n",
    "            state = { 'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
    "                      'optimizer': optimizer.state_dict(), 'losslogger': loss.item(), }\n",
    "            torch.save(state, newpath + '/' + model_name)\n",
    "            best_loss = loss.item()\n",
    "        else:\n",
    "            print(\"model not saved\")\n",
    "            \n",
    "loss_file.write(\"--- %s seconds ---\" % (time.time() - start_time_processing))\n",
    "loss_file.close()\n",
    "np.savez(newpath + '/' + \"train_loss_arr\", train_loss_arr)\n",
    "#np.savez(newpath + '/' + \"valid_acc_table\", valid_loss_mean_arr)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_processing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab519858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 9])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9a023ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for loss\n",
    "plt.clf()\n",
    "plt.plot(train_loss_arr, color='blue')\n",
    "plt.title('model train loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.yscale('log')\n",
    "plt.savefig(newpath + '/' + 'train_loss.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
