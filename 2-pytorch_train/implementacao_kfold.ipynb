{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96edf5b9",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0b6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import time\n",
    "from setup_dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890fc07",
   "metadata": {},
   "source": [
    "# Load matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a03d8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions_list(zigzag=False):\n",
    "\n",
    "    if zigzag:\n",
    "\n",
    "        ACTIONS = {\n",
    "            \"right\": 2,\n",
    "            \"left\": 3,\n",
    "        }\n",
    "\n",
    "    else:\n",
    "\n",
    "        ACTIONS = {\n",
    "            \"noop\": 0,\n",
    "            \"accelerate\": 1,\n",
    "            \"right\": 2,\n",
    "            \"left\": 3,\n",
    "            \"break\": 4,\n",
    "            \"right_break\": 5,\n",
    "            \"left_break\": 6,\n",
    "            \"right_accelerate\": 7,\n",
    "            \"left_accelerate\": 8,\n",
    "        }\n",
    "\n",
    "    return list(ACTIONS.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ddca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "\n",
    "    use_gpu = input((\"Do you want to use GPU (y/n)\"))\n",
    "\n",
    "    if use_gpu == 'y' and torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"GPU is available\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Selected CPU\")\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b07150a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to use GPU (y/n)y\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "data_info = {\n",
    "    'datapath' : r\"../1-generate/data/\",\n",
    "    'available_targets' : get_actions_list(zigzag=False),\n",
    "    'match_list' : [2, 3],\n",
    "    'start_frame' : 1,\n",
    "    'end_frame' : 200,\n",
    "    'device' : set_device(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43502ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset():\n",
    "\n",
    "    def __init__(self, data_info):\n",
    "        self.datapath = data_info['datapath']\n",
    "        self.available_targets = data_info['available_targets']\n",
    "        self.match_list = data_info['match_list']\n",
    "        self.start_frame = data_info['start_frame']\n",
    "        self.end_frame = data_info['end_frame']\n",
    "        self.device = data_info['device']\n",
    "        self.data, self.targets = self.setDataFromMatch()\n",
    "        self.target_size = self.targets.shape\n",
    "        self.seq_len = self.setSeqLen(self.data)\n",
    "    \n",
    "    def setSeqLen(self, X_train):\n",
    "        return torch.FloatTensor(list(map(len,X_train)))\n",
    "\n",
    "    def setDataFromMatch(self):\n",
    "        frames_arr = []\n",
    "        actions_arr = []\n",
    "\n",
    "        for m in self.match_list:\n",
    "            \n",
    "            _, frames, actions, _, _ = self.load_npz(self.datapath, m)\n",
    "            frames = frames[self.start_frame - 1:self.end_frame, 30:130, :]\n",
    "            actions = actions[self.start_frame - 1:self.end_frame]\n",
    "            \n",
    "            action_one_hot = [self.prepare_action_data(i, self.available_targets) for i in actions]\n",
    "            actions = np.array(action_one_hot)\n",
    "            actions = actions.reshape(len(actions), -1)\n",
    "            \n",
    "            frames_arr.append(frames)\n",
    "            actions_arr.append(actions)\n",
    "\n",
    "        frames_arr = np.array(frames_arr)\n",
    "        actions_arr = np.array(actions_arr)\n",
    "\n",
    "        return frames_arr, actions_arr\n",
    "    \n",
    "    def normalize_images(self, frames):\n",
    "        return frames/255\n",
    "\n",
    "    def load_npz(self, data_path, m):\n",
    "        \n",
    "        path = data_path + \"match_\" + str(m) + \"/npz/\"\n",
    "\n",
    "        actions = np.load(path + 'actions.npz')\n",
    "        #lifes = np.load(path + 'lifes.npz')\n",
    "        frames = np.load(path + 'frames.npz')\n",
    "        rewards = np.load(path + 'rewards.npz')\n",
    "\n",
    "        arr_actions = np.float32(actions.f.arr_0)\n",
    "        # arr_lifes = lifes.f.arr_0\n",
    "        arr_lifes = np.float32(np.array([]))\n",
    "        arr_frames = np.float32(frames.f.arr_0)\n",
    "        arr_rewards = np.float32(rewards.f.arr_0)\n",
    "\n",
    "        print(\"Successfully loaded NPZ.\")\n",
    "\n",
    "        return arr_actions.shape[0], arr_frames, arr_actions, arr_rewards, arr_lifes\n",
    "\n",
    "    def prepare_action_data(self, action, ACTIONS_LIST):\n",
    "\n",
    "        new_action = np.zeros((1, len(ACTIONS_LIST)), dtype=int) \n",
    "\n",
    "        new_action[0, ACTIONS_LIST.index(action)] = 1\n",
    "\n",
    "        return new_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc1c2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n"
     ]
    }
   ],
   "source": [
    "data = dataset(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57e71e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([200., 200.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce359c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data = torch.tensor(data.data)\n",
    "data.targets = torch.tensor(data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6de6e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data = data.data.view(data.data.shape[0], data.data.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22492445",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data = data.data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7520c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = chunk_dataset(match_list=[1,2,3,4,5,6,7,8],\\n                     start_frame = 1,\\n                     end_frame = 1020\\n                    )\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data = chunk_dataset(match_list=[1,2,3,4,5,6,7,8],\n",
    "                     start_frame = 1,\n",
    "                     end_frame = 1020\n",
    "                    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "947537dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padSequence(raw):\n",
    "    return pad_sequence(raw, batch_first=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1573f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def packPaddedSequence(seq, seq_len):\n",
    "    return pack_padded_sequence(seq, seq_len, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab705d16",
   "metadata": {},
   "source": [
    "Prepare frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "209f627d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data.data = padSequence(data.data)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data.data = padSequence(data.data)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3683a92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'padded_shape = data.data.shape'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"padded_shape = data.data.shape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd30b7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data.data = packPaddedSequence(data.data, data.seq_len)'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data.data = packPaddedSequence(data.data, data.seq_len)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e1378",
   "metadata": {},
   "source": [
    "Prepare targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "002cf8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data.targets = padSequence(data.targets)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"data.targets = padSequence(data.targets)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b190da0",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba435e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_type_name():\n",
    "    print(\"Choose type of RNN model:\")\n",
    "    print(\"1 - Simple RNN\")\n",
    "    print(\"2 - LSTM\")\n",
    "    print(\"3 - CNN\")\n",
    "    choise = int(input(\"type: \"))\n",
    "    if choise == 1:\n",
    "        return \"RNN\"\n",
    "    elif choise == 2:\n",
    "        return \"LSTM\"\n",
    "    elif choise == 3:\n",
    "        return \"CNN\"\n",
    "    else:\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c7dd86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hidden neurons: 200\n",
      "Number of epochs: 500\n",
      "Choose type of RNN model:\n",
      "1 - Simple RNN\n",
      "2 - LSTM\n",
      "3 - CNN\n",
      "type: 2\n"
     ]
    }
   ],
   "source": [
    "model_info = {\n",
    "    'input_size' : 12000,\n",
    "    'hidden_neurons' : int(input(\"Number of hidden neurons: \")),\n",
    "    'output_size' : 9,\n",
    "    'n_epochs' : int(input(\"Number of epochs: \")),\n",
    "    'min_loss' : 1e-5,\n",
    "    'n_layers' : 1,\n",
    "    'type' : set_type_name(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47e5625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, data_info, model_info):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.device = data_info['device']\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.input_size = model_info['input_size']\n",
    "        self.hidden_dim = model_info['hidden_neurons']\n",
    "        self.n_layers = model_info['n_layers']\n",
    "        self.output_size = model_info['output_size']\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_dim, self.n_layers, batch_first=True)  \n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_size)\n",
    "        \n",
    "        self.out = nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        out, _ = self.lstm(x, hidden)\n",
    "\n",
    "        \"\"\"\n",
    "        pad_embed_pack_lstm = self.lstm(x, hidden)\n",
    "        pad_embed_pack_lstm_pad = pad_packed_sequence(pad_embed_pack_lstm[0], batch_first=True)\n",
    "        \n",
    "        outs, _ = pad_embed_pack_lstm_pad\n",
    "        \"\"\"\n",
    "\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        out = self.out(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden_a = torch.randn(1, batch_size, self.hidden_dim).float()\n",
    "        hidden_b = torch.randn(1, batch_size, self.hidden_dim).float()\n",
    "\n",
    "        if self.device.type == 'cuda':\n",
    "            hidden_a = hidden_a.cuda()\n",
    "            hidden_b = hidden_b.cuda()\n",
    "\n",
    "        hidden_a = Variable(hidden_a)\n",
    "        hidden_b = Variable(hidden_b)\n",
    "\n",
    "        return (hidden_a, hidden_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f76326a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model(model_info):\n",
    "\n",
    "    if model_info['type'] == \"RNN\":\n",
    "        model = RNNModel(device=model_structure.device, \n",
    "                         input_size=model_structure.data_size, \n",
    "                         output_size=model_structure.output_size, \n",
    "                         hidden_dim=model_structure.hidden_neurons, \n",
    "                         n_layers=1)\n",
    "    elif model_info['type'] == \"LSTM\":\n",
    "        model = LSTMModel(data_info, model_info)\n",
    "    elif model_info['type'] == \"CNN\":\n",
    "        model = CNNLSTMModel(device=model_structure.device, \n",
    "                             input_size=model_structure.data_size, \n",
    "                             output_size=model_structure.output_size, \n",
    "                             hidden_dim=model_structure.hidden_neurons, \n",
    "                             n_layers=1)\n",
    "    else:\n",
    "        print(\"ERROR defining Model\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33ff5f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "model = set_model(model_info)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986733f",
   "metadata": {},
   "source": [
    "# Prepare to store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c21774b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setName(data_info, model_info):\n",
    "    x = [str(num) for num in data_info['match_list']]\n",
    "    x = '-'.join(x)\n",
    "    obs = input(\"write a observations without space and punctuations:\")\n",
    "    name = f\"{model_info['type']}_{obs}_m{x}_f{data_info['start_frame']}to{data_info['end_frame']}_epoch{model_info['n_epochs']}_h{model_info['hidden_neurons']}\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4bc1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setPath(data_info, model_info):\n",
    "    name = setName(data_info, model_info)\n",
    "    newpath = f\"models/\" + name\n",
    "    if not os.path.exists(newpath):\n",
    "        print(f\"models/\" + name + \" created\")\n",
    "        os.makedirs(newpath)\n",
    "    else:\n",
    "        print(f\"models/\" + name)\n",
    "        print(\"ATTENTION! folder not created. Training informations will overwrite the existing one\")\n",
    "    return newpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "667dd8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write a observations without space and punctuations:teste\n",
      "models/LSTM_teste_m2-3_f1to200_epoch500_h200 created\n"
     ]
    }
   ],
   "source": [
    "model_path = setPath(data_info, model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c9e829",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97803994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(predicted, target):\n",
    "    \n",
    "    predicted = torch.argmax(predicted, axis=1)\n",
    "    target = torch.argmax(target, axis=1)\n",
    "\n",
    "    correct = torch.sum(predicted == target)\n",
    "\n",
    "    acc = correct/predicted.shape[0]\n",
    "    return float(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "654ae07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_info['device'].type == 'cuda':\n",
    "    mymodel = model.cuda()\n",
    "    X_train = data.data.cuda() \n",
    "    Y_train = data.targets.cuda()\n",
    "else:\n",
    "    mymodel = model\n",
    "    X_train = data.data \n",
    "    Y_train = data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "900294f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_arr = np.array([])\n",
    "train_acc_arr = np.array([])\n",
    "valid_acc_arr = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ef264d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_info_string(current_epoch, last_epoch, train_loss, train_acc, valid_acc):\n",
    "    epoch_info = f\"Epoch: {current_epoch}/{last_epoch}-------------------------------------------\\n\"\n",
    "    train_info = f\"Train -> Loss: {train_loss:.15f} Acc: {train_acc:.15f}\\n\"\n",
    "    valid_info = f\"Valid -> Acc: {valid_acc:.15f}\\n\"\n",
    "    return epoch_info, train_info, valid_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a15ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=len(data.data), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13ddbee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alece\\miniconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/500-------------------------------------------\n",
      "Train -> Loss: 0.026529757305980 Acc: 0.855000019073486\n",
      "Valid -> Acc: 0.810000002384186\n",
      "Epoch: 20/500-------------------------------------------\n",
      "Train -> Loss: 0.017210021615028 Acc: 0.930000007152557\n",
      "Valid -> Acc: 0.904999971389771\n",
      "Epoch: 30/500-------------------------------------------\n",
      "Train -> Loss: 0.011362924240530 Acc: 0.954999983310699\n",
      "Valid -> Acc: 0.774999976158142\n",
      "Epoch: 40/500-------------------------------------------\n",
      "Train -> Loss: 0.008974323049188 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.824999988079071\n",
      "Epoch: 50/500-------------------------------------------\n",
      "Train -> Loss: 0.007899773307145 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.824999988079071\n",
      "Epoch: 60/500-------------------------------------------\n",
      "Train -> Loss: 0.007780951447785 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.859999954700470\n",
      "Epoch: 70/500-------------------------------------------\n",
      "Train -> Loss: 0.007162958383560 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.839999973773956\n",
      "Epoch: 80/500-------------------------------------------\n",
      "Train -> Loss: 0.007041519042104 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.814999997615814\n",
      "Epoch: 90/500-------------------------------------------\n",
      "Train -> Loss: 0.006884909234941 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.805000007152557\n",
      "Epoch: 100/500-------------------------------------------\n",
      "Train -> Loss: 0.006781660951674 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.794999957084656\n",
      "Epoch: 110/500-------------------------------------------\n",
      "Train -> Loss: 0.006683233659714 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.805000007152557\n",
      "Epoch: 120/500-------------------------------------------\n",
      "Train -> Loss: 0.006805810146034 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.805000007152557\n",
      "model not saved\n",
      "Epoch: 130/500-------------------------------------------\n",
      "Train -> Loss: 0.006551692727953 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.810000002384186\n",
      "Epoch: 140/500-------------------------------------------\n",
      "Train -> Loss: 0.006555395666510 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.810000002384186\n",
      "model not saved\n",
      "Epoch: 150/500-------------------------------------------\n",
      "Train -> Loss: 0.006428364664316 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.794999957084656\n",
      "Epoch: 160/500-------------------------------------------\n",
      "Train -> Loss: 0.006492795888335 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.794999957084656\n",
      "model not saved\n",
      "Epoch: 170/500-------------------------------------------\n",
      "Train -> Loss: 0.006300638895482 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.810000002384186\n",
      "Epoch: 180/500-------------------------------------------\n",
      "Train -> Loss: 0.006065358407795 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.819999992847443\n",
      "Epoch: 190/500-------------------------------------------\n",
      "Train -> Loss: 0.005844094324857 Acc: 0.964999973773956\n",
      "Valid -> Acc: 0.799999952316284\n",
      "Epoch: 200/500-------------------------------------------\n",
      "Train -> Loss: 0.004988010972738 Acc: 0.990000009536743\n",
      "Valid -> Acc: 0.824999988079071\n",
      "Epoch: 210/500-------------------------------------------\n",
      "Train -> Loss: 0.004694989416748 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.799999952316284\n",
      "Epoch: 220/500-------------------------------------------\n",
      "Train -> Loss: 0.004394498653710 Acc: 0.995000004768372\n",
      "Valid -> Acc: 0.799999952316284\n",
      "Epoch: 230/500-------------------------------------------\n",
      "Train -> Loss: 0.004123711492866 Acc: 0.995000004768372\n",
      "Valid -> Acc: 0.805000007152557\n",
      "Epoch: 240/500-------------------------------------------\n",
      "Train -> Loss: 0.003873524256051 Acc: 0.995000004768372\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 250/500-------------------------------------------\n",
      "Train -> Loss: 0.003655883017927 Acc: 0.995000004768372\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 260/500-------------------------------------------\n",
      "Train -> Loss: 0.003436995204538 Acc: 0.995000004768372\n",
      "Valid -> Acc: 0.794999957084656\n",
      "Epoch: 270/500-------------------------------------------\n",
      "Train -> Loss: 0.003086414886639 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 280/500-------------------------------------------\n",
      "Train -> Loss: 0.002770852530375 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.779999971389771\n",
      "Epoch: 290/500-------------------------------------------\n",
      "Train -> Loss: 0.002416154369712 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.779999971389771\n",
      "Epoch: 300/500-------------------------------------------\n",
      "Train -> Loss: 0.002164913341403 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.784999966621399\n",
      "Epoch: 310/500-------------------------------------------\n",
      "Train -> Loss: 0.001948619727045 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 320/500-------------------------------------------\n",
      "Train -> Loss: 0.001868806430139 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 330/500-------------------------------------------\n",
      "Train -> Loss: 0.001891796593554 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "model not saved\n",
      "Epoch: 340/500-------------------------------------------\n",
      "Train -> Loss: 0.001493975403719 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 350/500-------------------------------------------\n",
      "Train -> Loss: 0.001894121174701 Acc: 0.995000004768372\n",
      "Valid -> Acc: 0.789999961853027\n",
      "model not saved\n",
      "Epoch: 360/500-------------------------------------------\n",
      "Train -> Loss: 0.001471391180530 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 370/500-------------------------------------------\n",
      "Train -> Loss: 0.001227500382811 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 380/500-------------------------------------------\n",
      "Train -> Loss: 0.001153663499281 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 390/500-------------------------------------------\n",
      "Train -> Loss: 0.001092304126360 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 400/500-------------------------------------------\n",
      "Train -> Loss: 0.001057898858562 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.784999966621399\n",
      "Epoch: 410/500-------------------------------------------\n",
      "Train -> Loss: 0.001000162097625 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 420/500-------------------------------------------\n",
      "Train -> Loss: 0.000958151998930 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 430/500-------------------------------------------\n",
      "Train -> Loss: 0.000920181744732 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.784999966621399\n",
      "Epoch: 440/500-------------------------------------------\n",
      "Train -> Loss: 0.000886037887540 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 450/500-------------------------------------------\n",
      "Train -> Loss: 0.000863314198796 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 460/500-------------------------------------------\n",
      "Train -> Loss: 0.000937436125241 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "model not saved\n",
      "Epoch: 470/500-------------------------------------------\n",
      "Train -> Loss: 0.000798045075499 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 480/500-------------------------------------------\n",
      "Train -> Loss: 0.000911746290512 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "model not saved\n",
      "Epoch: 490/500-------------------------------------------\n",
      "Train -> Loss: 0.000774557120167 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "Epoch: 500/500-------------------------------------------\n",
      "Train -> Loss: 0.000737342517823 Acc: 1.000000000000000\n",
      "Valid -> Acc: 0.789999961853027\n",
      "--- 106.60188174247742 seconds ---\n",
      "Fold: 1\n",
      "Epoch: 10/500-------------------------------------------\n",
      "Train -> Loss: 0.016944089904428 Acc: 0.904999971389771\n",
      "Valid -> Acc: 0.779999971389771\n",
      "Epoch: 20/500-------------------------------------------\n",
      "Train -> Loss: 0.010143344290555 Acc: 0.954999983310699\n",
      "Valid -> Acc: 0.819999992847443\n",
      "Epoch: 30/500-------------------------------------------\n",
      "Train -> Loss: 0.008127611130476 Acc: 0.959999978542328\n",
      "Valid -> Acc: 0.899999976158142\n",
      "Epoch: 40/500-------------------------------------------\n",
      "Train -> Loss: 0.006920844316483 Acc: 0.970000028610229\n",
      "Valid -> Acc: 0.879999995231628\n",
      "Epoch: 50/500-------------------------------------------\n",
      "Train -> Loss: 0.006365674547851 Acc: 0.970000028610229\n",
      "Valid -> Acc: 0.909999966621399\n",
      "Epoch: 60/500-------------------------------------------\n",
      "Train -> Loss: 0.005924207158387 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.870000004768372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/500-------------------------------------------\n",
      "Train -> Loss: 0.005585136357695 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.834999978542328\n",
      "Epoch: 80/500-------------------------------------------\n",
      "Train -> Loss: 0.005383864510804 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.829999983310699\n",
      "Epoch: 90/500-------------------------------------------\n",
      "Train -> Loss: 0.005253995768726 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.870000004768372\n",
      "Epoch: 100/500-------------------------------------------\n",
      "Train -> Loss: 0.005108710378408 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.799999952316284\n",
      "Epoch: 110/500-------------------------------------------\n",
      "Train -> Loss: 0.005569972563535 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.799999952316284\n",
      "model not saved\n",
      "Epoch: 120/500-------------------------------------------\n",
      "Train -> Loss: 0.005005047656596 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.779999971389771\n",
      "Epoch: 130/500-------------------------------------------\n",
      "Train -> Loss: 0.005371481645852 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.754999995231628\n",
      "model not saved\n",
      "Epoch: 140/500-------------------------------------------\n",
      "Train -> Loss: 0.005334198940545 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.745000004768372\n",
      "model not saved\n",
      "Epoch: 150/500-------------------------------------------\n",
      "Train -> Loss: 0.005631431005895 Acc: 0.975000023841858\n",
      "Valid -> Acc: 0.759999990463257\n",
      "model not saved\n",
      "Epoch: 160/500-------------------------------------------\n",
      "Train -> Loss: 0.004953092429787 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.779999971389771\n",
      "Epoch: 170/500-------------------------------------------\n",
      "Train -> Loss: 0.004735749680549 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.764999985694885\n",
      "Epoch: 180/500-------------------------------------------\n",
      "Train -> Loss: 0.004605370573699 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.779999971389771\n",
      "Epoch: 190/500-------------------------------------------\n",
      "Train -> Loss: 0.004708070307970 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.769999980926514\n",
      "model not saved\n",
      "Epoch: 200/500-------------------------------------------\n",
      "Train -> Loss: 0.004551008343697 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.754999995231628\n",
      "Epoch: 210/500-------------------------------------------\n",
      "Train -> Loss: 0.004512354731560 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.754999995231628\n",
      "Epoch: 220/500-------------------------------------------\n",
      "Train -> Loss: 0.004433979745954 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.754999995231628\n",
      "Epoch: 230/500-------------------------------------------\n",
      "Train -> Loss: 0.004374372772872 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.769999980926514\n",
      "Epoch: 240/500-------------------------------------------\n",
      "Train -> Loss: 0.004334352910519 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.740000009536743\n",
      "Epoch: 250/500-------------------------------------------\n",
      "Train -> Loss: 0.004402285441756 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.754999995231628\n",
      "model not saved\n",
      "Epoch: 260/500-------------------------------------------\n",
      "Train -> Loss: 0.004479259718210 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.754999995231628\n",
      "model not saved\n",
      "Epoch: 270/500-------------------------------------------\n",
      "Train -> Loss: 0.004204037133604 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.759999990463257\n",
      "Epoch: 280/500-------------------------------------------\n",
      "Train -> Loss: 0.004157484974712 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.759999990463257\n",
      "Epoch: 290/500-------------------------------------------\n",
      "Train -> Loss: 0.004164369776845 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.754999995231628\n",
      "model not saved\n",
      "Epoch: 300/500-------------------------------------------\n",
      "Train -> Loss: 0.004210156854242 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.759999990463257\n",
      "model not saved\n",
      "Epoch: 310/500-------------------------------------------\n",
      "Train -> Loss: 0.004005317110568 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.774999976158142\n",
      "Epoch: 320/500-------------------------------------------\n",
      "Train -> Loss: 0.004044129513204 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.774999976158142\n",
      "model not saved\n",
      "Epoch: 330/500-------------------------------------------\n",
      "Train -> Loss: 0.003826478263363 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.764999985694885\n",
      "Epoch: 340/500-------------------------------------------\n",
      "Train -> Loss: 0.003725844202563 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.764999985694885\n",
      "Epoch: 350/500-------------------------------------------\n",
      "Train -> Loss: 0.003776613622904 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.784999966621399\n",
      "model not saved\n",
      "Epoch: 360/500-------------------------------------------\n",
      "Train -> Loss: 0.003528224769980 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.769999980926514\n",
      "Epoch: 370/500-------------------------------------------\n",
      "Train -> Loss: 0.003614950459450 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.754999995231628\n",
      "model not saved\n",
      "Epoch: 380/500-------------------------------------------\n",
      "Train -> Loss: 0.003708248725161 Acc: 0.980000019073486\n",
      "Valid -> Acc: 0.759999990463257\n",
      "model not saved\n",
      "Epoch: 390/500-------------------------------------------\n",
      "Train -> Loss: 0.003698783228174 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.784999966621399\n",
      "model not saved\n",
      "Epoch: 400/500-------------------------------------------\n",
      "Train -> Loss: 0.003212061012164 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.745000004768372\n",
      "Epoch: 410/500-------------------------------------------\n",
      "Train -> Loss: 0.003196789184585 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.759999990463257\n",
      "Epoch: 420/500-------------------------------------------\n",
      "Train -> Loss: 0.003122146241367 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.759999990463257\n",
      "Epoch: 430/500-------------------------------------------\n",
      "Train -> Loss: 0.003124499926344 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.759999990463257\n",
      "model not saved\n",
      "Epoch: 440/500-------------------------------------------\n",
      "Train -> Loss: 0.002985043218359 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.759999990463257\n",
      "Epoch: 450/500-------------------------------------------\n",
      "Train -> Loss: 0.003000376513228 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.754999995231628\n",
      "model not saved\n",
      "Epoch: 460/500-------------------------------------------\n",
      "Train -> Loss: 0.002933331765234 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.754999995231628\n",
      "Epoch: 470/500-------------------------------------------\n",
      "Train -> Loss: 0.002807589946315 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.754999995231628\n",
      "Epoch: 480/500-------------------------------------------\n",
      "Train -> Loss: 0.003023618832231 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.754999995231628\n",
      "model not saved\n",
      "Epoch: 490/500-------------------------------------------\n",
      "Train -> Loss: 0.002689568791538 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.745000004768372\n",
      "Epoch: 500/500-------------------------------------------\n",
      "Train -> Loss: 0.002676127245650 Acc: 0.985000014305115\n",
      "Valid -> Acc: 0.759999990463257\n",
      "--- 104.46166110038757 seconds ---\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data.data)):\n",
    "        \n",
    "    start_time_processing = time.time()\n",
    "\n",
    "    best_loss = 1\n",
    "    first_epoch = True\n",
    "    \n",
    "    loss_file = open(model_path + '/' + f\"loss_file_{fold}.txt\", \"w\")\n",
    "    \n",
    "    print(f'Fold: {fold}')\n",
    "\n",
    "    X_train = data.data[train_ids]\n",
    "    Y_train = data.targets[train_ids]\n",
    "    X_valid = data.data[test_ids]\n",
    "    Y_valid = data.targets[test_ids]\n",
    "\n",
    "    #X_train = padSequence(tuple(X_train))\n",
    "    #X_valid = padSequence(tuple(X_valid))\n",
    "    \"\"\"\n",
    "    X_train_padded_shape = X_train.shape\n",
    "    X_train_seq_len = data.seq_len[train_ids]\n",
    "    X_train = packPaddedSequence(X_train, X_train_seq_len)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    X_valid_padded_shape = X_valid.shape\n",
    "    X_valid_seq_len = data.seq_len[test_ids]\n",
    "    X_valid = packPaddedSequence(X_valid, X_valid_seq_len)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if data_info['device'].type == 'cuda':\n",
    "        mymodel = model.cuda()\n",
    "        X_train = X_train.cuda() \n",
    "        Y_train = Y_train.cuda()\n",
    "        X_valid = X_valid.cuda() \n",
    "        Y_valid = Y_valid.cuda()\n",
    "    \"\"\"\n",
    "    if data_info['device'].type == 'cuda':\n",
    "        mymodel = model.cuda()\n",
    "        X_valid = X_valid.cuda() \n",
    "        Y_valid = Y_valid.cuda()\n",
    "    \n",
    "    for epoch in range(1, model_info['n_epochs'] + 1):\n",
    "        \n",
    "        predicted_outputs = torch.tensor([])\n",
    "\n",
    "        for sequence, targets in zip(X_train, Y_train):\n",
    "            \n",
    "            if data_info['device'].type == 'cuda':\n",
    "                sequence = sequence.cuda()\n",
    "                targets = targets.cuda()\n",
    "            \n",
    "            mymodel.train()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = mymodel(sequence.view(1, sequence.shape[0], sequence.shape[1]))\n",
    "            predicted_outputs = torch.cat((predicted_outputs.to('cpu'), output.to('cpu')), 0)\n",
    "\n",
    "            loss = criterion(output, targets.view(-1, model_info['output_size']).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "\n",
    "            train_loss_arr = np.append(train_loss_arr, loss.item())\n",
    "            train_acc_arr  = np.append(train_acc_arr, get_acc(predicted_outputs.reshape(-1, len(data.available_targets)), Y_train.reshape(-1, len(data.available_targets))))\n",
    "            \n",
    "            mymodel.eval()\n",
    "            \n",
    "            output = mymodel(X_valid)\n",
    "            valid_acc_arr  = np.append(valid_acc_arr, get_acc(output, Y_valid.reshape(-1, len(data.available_targets))))\n",
    "                        \n",
    "            epoch_info, train_info, valid_info = create_info_string(epoch, \n",
    "                                                                    model_info['n_epochs'], \n",
    "                                                                    train_loss_arr[-1], \n",
    "                                                                    train_acc_arr[-1],\n",
    "                                                                    valid_acc_arr[-1])\n",
    "            loss_file.write(epoch_info)\n",
    "            loss_file.write(train_info)\n",
    "            loss_file.write(valid_info)\n",
    "            print(epoch_info, end = '')\n",
    "            print(train_info, end = '')\n",
    "            print(valid_info, end = '')\n",
    "\n",
    "            if train_loss_arr[-1] < best_loss:\n",
    "                state = {'epoch': epoch, \n",
    "                         'state_dict': mymodel.state_dict(),\n",
    "                         'optimizer': optimizer.state_dict(), \n",
    "                         'losslogger': loss.item(), \n",
    "                        }\n",
    "                torch.save(state, model_path + '/' + f'model_fold_{fold}')\n",
    "                best_loss = loss.item()\n",
    "            else:\n",
    "                print(\"model not saved\")\n",
    "                \n",
    "    time_info = \"--- %s seconds ---\" % (time.time() - start_time_processing)\n",
    "    loss_file.write(time_info)\n",
    "    print(time_info)\n",
    "\n",
    "    loss_file.close()\n",
    "    np.savez(model_path + '/' + f\"train_loss_arr_{fold}\", train_loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84fbf500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06779106 0.06019022 0.05163167 0.04355165 0.03756144 0.03416507\n",
      " 0.03138779 0.02904316 0.02673046 0.02524197 0.02300601 0.02141168\n",
      " 0.01987032 0.01858283 0.01737118 0.01624748 0.01497382 0.01395418\n",
      " 0.01313718 0.01204579 0.01116655 0.01040545 0.00957519 0.00893641\n",
      " 0.00839831 0.00805861 0.0073733  0.00694257 0.00651737 0.00616217\n",
      " 0.00594118 0.00515433 0.00440766 0.00386135 0.00304779 0.00244569\n",
      " 0.00191445 0.00152155 0.00131    0.00125397 0.00091779 0.00080722\n",
      " 0.00085187 0.00075091 0.00063316 0.00055143 0.00056753 0.00046632\n",
      " 0.0004399  0.00054244 0.05188608 0.04749809 0.04384062 0.04055969\n",
      " 0.03683074 0.0342757  0.03172548 0.03005379 0.02826169 0.02666542\n",
      " 0.02567464 0.02506769 0.02333365 0.02172856 0.02031099 0.01941531\n",
      " 0.01883428 0.01798033 0.01919792 0.01736029 0.01684406 0.01558691\n",
      " 0.01488767 0.0138324  0.01366408 0.01265527 0.01201956 0.01141775\n",
      " 0.01089693 0.01180601 0.01096421 0.00981329 0.00989723 0.00968197\n",
      " 0.00872147 0.00813628 0.00791865 0.00782203 0.00739184 0.00760412\n",
      " 0.00671418 0.00620586 0.00606268 0.0057059  0.00561824 0.00525485\n",
      " 0.00508304 0.00490514 0.00477771 0.00579758 0.02987878 0.01980741\n",
      " 0.01309526 0.01095228 0.00963012 0.00897271 0.00843926 0.00802636\n",
      " 0.00764665 0.00737153 0.00721962 0.0070361  0.00695431 0.0068037\n",
      " 0.00670734 0.00669461 0.00655129 0.00648913 0.0063267  0.0064577\n",
      " 0.00616909 0.00609668 0.00606948 0.00599382 0.00594427 0.00593094\n",
      " 0.00585722 0.00633191 0.00590461 0.00575809 0.00570478 0.00567053\n",
      " 0.00563547 0.00573952 0.00557691 0.00555975 0.00554174 0.00547816\n",
      " 0.0054505  0.00542717 0.00539989 0.00536288 0.00534028 0.00531901\n",
      " 0.00539037 0.00527244 0.00524841 0.00518987 0.0048377  0.00393585\n",
      " 0.01973482 0.01170992 0.00880171 0.00746232 0.00678535 0.00637668\n",
      " 0.0061465  0.02652976 0.01721002 0.01136292 0.00897432 0.00789977\n",
      " 0.00778095 0.00716296 0.00704152 0.00688491 0.00678166 0.00668323\n",
      " 0.00680581 0.00655169 0.0065554  0.00642836 0.0064928  0.00630064\n",
      " 0.00606536 0.00584409 0.00498801 0.00469499 0.0043945  0.00412371\n",
      " 0.00387352 0.00365588 0.003437   0.00308641 0.00277085 0.00241615\n",
      " 0.00216491 0.00194862 0.00186881 0.0018918  0.00149398 0.00189412\n",
      " 0.00147139 0.0012275  0.00115366 0.0010923  0.0010579  0.00100016\n",
      " 0.00095815 0.00092018 0.00088604 0.00086331 0.00093744 0.00079805\n",
      " 0.00091175 0.00077456 0.00073734]\n",
      "[0.06779106 0.06019022 0.05163167 0.04355165 0.03756144 0.03416507\n",
      " 0.03138779 0.02904316 0.02673046 0.02524197 0.02300601 0.02141168\n",
      " 0.01987032 0.01858283 0.01737118 0.01624748 0.01497382 0.01395418\n",
      " 0.01313718 0.01204579 0.01116655 0.01040545 0.00957519 0.00893641\n",
      " 0.00839831 0.00805861 0.0073733  0.00694257 0.00651737 0.00616217\n",
      " 0.00594118 0.00515433 0.00440766 0.00386135 0.00304779 0.00244569\n",
      " 0.00191445 0.00152155 0.00131    0.00125397 0.00091779 0.00080722\n",
      " 0.00085187 0.00075091 0.00063316 0.00055143 0.00056753 0.00046632\n",
      " 0.0004399  0.00054244 0.05188608 0.04749809 0.04384062 0.04055969\n",
      " 0.03683074 0.0342757  0.03172548 0.03005379 0.02826169 0.02666542\n",
      " 0.02567464 0.02506769 0.02333365 0.02172856 0.02031099 0.01941531\n",
      " 0.01883428 0.01798033 0.01919792 0.01736029 0.01684406 0.01558691\n",
      " 0.01488767 0.0138324  0.01366408 0.01265527 0.01201956 0.01141775\n",
      " 0.01089693 0.01180601 0.01096421 0.00981329 0.00989723 0.00968197\n",
      " 0.00872147 0.00813628 0.00791865 0.00782203 0.00739184 0.00760412\n",
      " 0.00671418 0.00620586 0.00606268 0.0057059  0.00561824 0.00525485\n",
      " 0.00508304 0.00490514 0.00477771 0.00579758 0.02987878 0.01980741\n",
      " 0.01309526 0.01095228 0.00963012 0.00897271 0.00843926 0.00802636\n",
      " 0.00764665 0.00737153 0.00721962 0.0070361  0.00695431 0.0068037\n",
      " 0.00670734 0.00669461 0.00655129 0.00648913 0.0063267  0.0064577\n",
      " 0.00616909 0.00609668 0.00606948 0.00599382 0.00594427 0.00593094\n",
      " 0.00585722 0.00633191 0.00590461 0.00575809 0.00570478 0.00567053\n",
      " 0.00563547 0.00573952 0.00557691 0.00555975 0.00554174 0.00547816\n",
      " 0.0054505  0.00542717 0.00539989 0.00536288 0.00534028 0.00531901\n",
      " 0.00539037 0.00527244 0.00524841 0.00518987 0.0048377  0.00393585\n",
      " 0.01973482 0.01170992 0.00880171 0.00746232 0.00678535 0.00637668\n",
      " 0.0061465  0.02652976 0.01721002 0.01136292 0.00897432 0.00789977\n",
      " 0.00778095 0.00716296 0.00704152 0.00688491 0.00678166 0.00668323\n",
      " 0.00680581 0.00655169 0.0065554  0.00642836 0.0064928  0.00630064\n",
      " 0.00606536 0.00584409 0.00498801 0.00469499 0.0043945  0.00412371\n",
      " 0.00387352 0.00365588 0.003437   0.00308641 0.00277085 0.00241615\n",
      " 0.00216491 0.00194862 0.00186881 0.0018918  0.00149398 0.00189412\n",
      " 0.00147139 0.0012275  0.00115366 0.0010923  0.0010579  0.00100016\n",
      " 0.00095815 0.00092018 0.00088604 0.00086331 0.00093744 0.00079805\n",
      " 0.00091175 0.00077456 0.00073734 0.01694409 0.01014334 0.00812761\n",
      " 0.00692084 0.00636567 0.00592421 0.00558514 0.00538386 0.005254\n",
      " 0.00510871 0.00556997 0.00500505 0.00537148 0.0053342  0.00563143\n",
      " 0.00495309 0.00473575 0.00460537 0.00470807 0.00455101 0.00451235\n",
      " 0.00443398 0.00437437 0.00433435 0.00440229 0.00447926 0.00420404\n",
      " 0.00415748 0.00416437 0.00421016 0.00400532 0.00404413 0.00382648\n",
      " 0.00372584 0.00377661 0.00352822 0.00361495 0.00370825 0.00369878\n",
      " 0.00321206 0.00319679 0.00312215 0.0031245  0.00298504 0.00300038\n",
      " 0.00293333 0.00280759 0.00302362 0.00268957 0.00267613]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for fold in range(len(data.data)):\n",
    "    # summarize history for loss\n",
    "    \n",
    "    train_loss_arr = np.load(model_path + '/' + f\"train_loss_arr_{fold}.npz\")\n",
    "    train_loss_arr = train_loss_arr.f.arr_0\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(train_loss_arr, color='blue')\n",
    "    plt.title('model train loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper left')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(model_path + '/' + f'train_loss_{fold}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8018a1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 200, 12000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"start_time_processing = time.time()\n",
    "\n",
    "loss_file = open(model_path + '/' + \"loss_file.txt\", \"w\")\n",
    "\n",
    "best_loss = 1\n",
    "first_epoch = True\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data.data)):\n",
    "    \n",
    "    print(f'Fold: {fold}')\n",
    "\n",
    "    X_train = data.data[train_ids]\n",
    "    Y_train = data.targets[train_ids]\n",
    "    X_valid = data.data[test_ids]\n",
    "    Y_valid = data.targets[test_ids]\n",
    "    \n",
    "    X_train = padSequence(X_train)\n",
    "    X_valid = padSequence(X_valid)\n",
    "    \n",
    "    X_train_padded_shape = X_train.shape\n",
    "    X_train_seq_len = data.seq_len[train_ids]\n",
    "    X_train = packPaddedSequence(X_train, X_train_seq_len)\n",
    "    \n",
    "    X_valid_padded_shape = X_valid.shape\n",
    "    X_valid_seq_len = data.seq_len[test_ids]\n",
    "    X_valid = packPaddedSequence(X_valid, X_valid_seq_len)\n",
    "    \n",
    "    if data_info['device'].type == 'cuda':\n",
    "        mymodel = model.cuda()\n",
    "        X_train = X_train.cuda() \n",
    "        Y_train = Y_train.cuda()\n",
    "        X_valid = X_valid.cuda() \n",
    "        Y_valid = Y_valid.cuda()\n",
    "    \n",
    "    for epoch in range(1, model_info['n_epochs'] + 1):\n",
    "\n",
    "        mymodel.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = mymodel(X_train)\n",
    "\n",
    "        loss = criterion(output, Y_train.view(-1,model_info['output_size']).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "\n",
    "            train_loss_arr = np.append(train_loss_arr, loss.item())\n",
    "            train_acc_arr  = np.append(train_acc_arr, get_acc(output, Y_train.reshape(-1, len(data.available_targets))))\n",
    "            \n",
    "            mymodel.eval()\n",
    "            \n",
    "            output = mymodel(X_valid)\n",
    "            valid_acc_arr  = np.append(valid_acc_arr, get_acc(output, Y_valid.reshape(-1, len(data.available_targets))))\n",
    "                        \n",
    "            epoch_info, train_info, valid_info = create_info_string(epoch, \n",
    "                                                                    model_info['n_epochs'], \n",
    "                                                                    train_loss_arr[-1], \n",
    "                                                                    train_acc_arr[-1],\n",
    "                                                                    valid_acc_arr[-1])\n",
    "            loss_file.write(epoch_info)\n",
    "            loss_file.write(train_info)\n",
    "            loss_file.write(valid_info)\n",
    "            print(epoch_info)\n",
    "            print(train_info)\n",
    "            print(valid_info)\n",
    "\n",
    "            if train_loss_arr[-1] < best_loss:\n",
    "                state = {'epoch': epoch, \n",
    "                         'state_dict': mymodel.state_dict(),\n",
    "                         'optimizer': optimizer.state_dict(), \n",
    "                         'losslogger': loss.item(), \n",
    "                        }\n",
    "                torch.save(state, model_path + '/' + f'model_fold_{fold}')\n",
    "                best_loss = loss.item()\n",
    "            else:\n",
    "                print(\"model not saved\")\n",
    "                \n",
    "time_info = \"--- %s seconds ---\" % (time.time() - start_time_processing)\n",
    "loss_file.write(time_info)\n",
    "print(time_info)\n",
    "\n",
    "loss_file.close()\n",
    "np.savez(model_path + '/' + \"train_loss_arr\", train_loss_arr)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ae108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"start_time_processing = time.time()\n",
    "\n",
    "loss_file = open(model_path + '/' + \"loss_file.txt\", \"w\")\n",
    "\n",
    "best_loss = 1\n",
    "first_epoch = True\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(data.data)):\n",
    "    \n",
    "    print(f'Fold: {fold}')\n",
    "\n",
    "    X_train = data.data[train_ids]\n",
    "    Y_train = data.targets[train_ids]\n",
    "    X_valid = data.data[test_ids]\n",
    "    Y_valid = data.targets[test_ids]\n",
    "    \n",
    "    X_train = padSequence(X_train)\n",
    "    X_valid = padSequence(X_valid)\n",
    "    \n",
    "    X_valid_padded_shape = X_valid.shape\n",
    "    X_valid_seq_len = data.seq_len[test_ids]\n",
    "    X_valid = packPaddedSequence(X_valid, X_valid_seq_len)\n",
    "    \n",
    "    if data_info['device'].type == 'cuda':\n",
    "        mymodel = model.cuda()\n",
    "        X_train = X_train.cuda() \n",
    "        Y_train = Y_train.cuda()\n",
    "        X_valid = X_valid.cuda() \n",
    "        Y_valid = Y_valid.cuda()\n",
    "    \n",
    "    for epoch in range(1, model_info['n_epochs'] + 1):\n",
    "        \n",
    "        print(\"epoch:\", epoch)\n",
    "        \n",
    "        mymodel.train()\n",
    "            \n",
    "        for sequence, targets, seq_len2 in zip(X_train, Y_train, data.seq_len[train_ids]):\n",
    "            \n",
    "            print(sequence.shape)\n",
    "            print(targets.shape)\n",
    "            \n",
    "            sequence = sequence.view(1, sequence.shape[0], sequence.shape[1])\n",
    "            X_train_padded_shape = sequence.shape\n",
    "            X_train_seq_len = torch.tensor([seq_len2])\n",
    "            sequence = packPaddedSequence(sequence, X_train_seq_len)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = mymodel(sequence)\n",
    "\n",
    "            loss = criterion(output, targets.view(-1,model_info['output_size']).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "\n",
    "            train_loss_arr = np.append(train_loss_arr, loss.item())\n",
    "            train_acc_arr  = np.append(train_acc_arr, get_acc(output, sequence.reshape(-1, len(data.available_targets))))\n",
    "            \n",
    "            mymodel.eval()\n",
    "            \n",
    "            output = mymodel(X_valid)\n",
    "            valid_acc_arr  = np.append(valid_acc_arr, get_acc(output, Y_valid.reshape(-1, len(data.available_targets))))\n",
    "                        \n",
    "            epoch_info, train_info, valid_info = create_info_string(epoch, \n",
    "                                                                    model_info['n_epochs'], \n",
    "                                                                    train_loss_arr[-1], \n",
    "                                                                    train_acc_arr[-1],\n",
    "                                                                    valid_acc_arr[-1])\n",
    "            loss_file.write(epoch_info)\n",
    "            loss_file.write(train_info)\n",
    "            loss_file.write(valid_info)\n",
    "            print(epoch_info)\n",
    "            print(train_info)\n",
    "            print(valid_info)\n",
    "\n",
    "            if train_loss_arr[-1] < best_loss:\n",
    "                state = {'epoch': epoch, \n",
    "                         'state_dict': mymodel.state_dict(),\n",
    "                         'optimizer': optimizer.state_dict(), \n",
    "                         'losslogger': loss.item(), \n",
    "                        }\n",
    "                torch.save(state, model_path + '/' + f'model_fold_{fold}')\n",
    "                best_loss = loss.item()\n",
    "            else:\n",
    "                print(\"model not saved\")\n",
    "                \n",
    "time_info = \"--- %s seconds ---\" % (time.time() - start_time_processing)\n",
    "loss_file.write(time_info)\n",
    "print(time_info)\n",
    "\n",
    "loss_file.close()\n",
    "np.savez(model_path + '/' + \"train_loss_arr\", train_loss_arr)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
