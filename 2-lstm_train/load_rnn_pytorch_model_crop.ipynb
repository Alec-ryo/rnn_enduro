{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02c05ab",
   "metadata": {},
   "source": [
    "# Load and test trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429f7996",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef0db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[  0, 52, 62, 80, 106, 117, 137, 142, 156, 159, 166, 185, 215, 226, 235, 242, 252, 259, 279, 281, 292, 296, 299, \n",
    "                303, 308, 315, 318, 321, 329, 333, 335, 354, 360, 374, 377, 382, 386, 390, 393, 402, 414, 420, 444, 447, \n",
    "                465, 469, 487, 491, 504, 506, 510, 513, 525, 528, 538, 552, 558, 570, 576, 581, 584, 588, 595, 598, 604, \n",
    "                607, 610, 618, 619, 622, 631, 641, 645, 662, 672, 685, 693, 697, 704, 718, 724, 726, 735, 739, 745, 754, \n",
    "                755, 770, 773, 789, 790, 799, 805, 809, 823, 834, 850, 854, 857, 868, 874, 875, 877, 883, 885, 904, 906, \n",
    "                911, 919, 923, 926, 932, 943, 962, 965, 984, 991, 999, 1007, 1010, 1015, 1017, 1018],\n",
    "           [   0, 31, 45, 47, 56, 63, 69, 85, 88, 92, 96, 112, 118, 124, 130, 137, 143, 151, 158, 170, 184, 202, 223, 243, 249,\n",
    "             255,260,269,272,275,276,282,285,295,296,297,306,308,318,322,331,334,337,338,341,343,354,357,381,387,400,402,408,\n",
    "             420,423,426,429,441,443,445,448,454,463,465,474,481,502,506,524,533,538,548,556,562,566,570,581,588,603,604,609,\n",
    "             652,668,681,698,710,714,725,729,736,739,743,748,749,752,766,770,774,778,781,792,795,803,804,806,814,818,821,828,\n",
    "             834,837,843,849,855,862,868,874,884,888,895,896,919,935,942,945,957,958,963,964,965,977,980,984,989,997,1000],\n",
    "           [   0,37,53,81,94,99,119,123,124,142,144,146,162,193,211,213,222,230,232,235,238,240,252,255,258,267,270,275,\n",
    "                278,284,287,289,300,307,313,331,352,359,371,379,386,389,392,409,412,432,435,440,442,446,462,467,472,\n",
    "                506,527,531,535,553,557,561,571,579,589,602,607,609,612,616,621,631,634,638,640,644,645,661,669,673,676,\n",
    "                692,695,698,701,711,717,720,721,734,744,747,750,755,759,774,785,793,807,859,891,895,912,927,948,958,969,\n",
    "                980,997,998,1004],\n",
    "           [   0,33,58,75,86,100,118,120,139,142,147,159,162,165,167,174,179,180,183,192,197,199,209,214,217,222,227,231,\n",
    "                232,239,244,251,262,266,271,275,277,282,287,291,294,297,308,311,316,318,322,327,339,342,348,352,362,372,\n",
    "                383,397,399,402,405,417,420, 425,428,454,457,464,470,477,481,485,488,494,495,503,507,517,535,537,540,553,\n",
    "                556,558,577,588,598,601,609,620,634,638,647,650,656,659,660,663,669,672,681,684,696,702,705,708,716,719,726,\n",
    "                730,739,743,746,758,765,766,777,783,785,786,790,792,800,802,808,809,810,816,819,823,827,835,837,842,845,853,\n",
    "                865,868,873,885,889,891,897,904,906,918,941,949,956,961,969,973,976,981,984,991,996,999,1002],\n",
    "           [   0,59,68,73,76,86,94,97,101,104,109,118,120,123,128,134,136,139,143,145,148,154,160,162,177,190,195,199,204,\n",
    "                208,212,220,221,222,232,234,246,251,253,256,263,270,273,287,302,314,322,355,357,368,396,397,401,416,428,433,\n",
    "                437,442,446,452,456,469,475,490,500,506,525,526,538,545,551,554,558,562,571,579,582,586,587,600,612,664,823,\n",
    "                824,832,850,858,870,879,881,889,898,901,913,916,924,932,936,943,952,955,975,985,992,997,1001],\n",
    "           [   0,36,56,94,114,121,136,140,143,153,159,162,171,174,182,190,197,201,215,219,237,239,249,251,254,265,269,297,322,\n",
    "                335,340,343,348,352,355,363,368,371,375,384,388,395,405,411,439,461,464,468,477,483,485,487,494,497,501,503,\n",
    "                514,519,521,526,529,532,538,547,551,555,560,579,584,597,600,602,607,609,617,623,626,634,638,644,649,652,663,\n",
    "                671,672,675,678,685,688,699,700,712,719,724,726,735,744,753,756,775,797,806,812,818,826,829,832,848,852,856,\n",
    "                866,869,872,875,881,886,891,893,895,901,910,930,936,940,953,958,989,997,1004,1006] \n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5114873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from enduro_rnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c87a302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected CPU\n"
     ]
    }
   ],
   "source": [
    "device = conf_cuda(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea85b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec63db4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dadaf8",
   "metadata": {},
   "source": [
    "## Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63fd55ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_file.txt\n",
      "teste_com_rnn_m35to35_f1to120_epoch10000_H200\n",
      "train_loss_arr.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir_path = \"best_models/chuncked_sequence/elman/tanh_softmax/elman_tanh_softmax_m35to35_f1to120_H200_epoch10000\" + \"/\"\n",
    "arr = os.listdir(f'./{dir_path}')\n",
    "for i in range(len(arr)):\n",
    "    print(arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71fea567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = dir_path + \"teste_com_rnn_m35to35_f1to120_epoch10000_H200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21042a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_match = 45\n",
    "end_match = 50\n",
    "\n",
    "hidden_neurons = 200\n",
    "zigzag = False\n",
    "is_softmax = True\n",
    "\n",
    "start_frame = 1\n",
    "end_frame = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea9dc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"../1-generate/data/\"\n",
    "\n",
    "use_cuda = False\n",
    "load_checkpoint = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf3c89",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64e7209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if zigzag:\n",
    "    output_size = 2\n",
    "else:\n",
    "    output_size = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde9ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, filename='checkpoint.pth.tar'):\n",
    "    \n",
    "    print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "    checkpoint = torch.load(filename, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    return model, checkpoint['optimizer']['state'][0]['step'], checkpoint['losslogger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e43baa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'best_models/chuncked_sequence/elman/tanh_softmax/elman_tanh_softmax_m35to35_f1to120_H200_epoch10000/teste_com_rnn_m35to35_f1to120_epoch10000_H200'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model1(\n",
       "  (rnn): RNN(12000, 200, batch_first=True)\n",
       "  (fc): Linear(in_features=200, out_features=2, bias=True)\n",
       "  (out): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if load_checkpoint:\n",
    "    model = Model1(device=device, input_size=12000, output_size=output_size, hidden_dim=hidden_neurons, n_layers=1, is_softmax=is_softmax)\n",
    "    model, last_epoch, last_logger = load_checkpoint(model, model_path)\n",
    "else:\n",
    "    model = Model(device=device, input_size=12000, output_size=output_size, hidden_dim=hidden_neurons, n_layers=1, is_softmax=is_softmax)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1970185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_LIST = get_actions_list(zigzag=zigzag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49a8c300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n"
     ]
    }
   ],
   "source": [
    "num_of_frames_arr = []\n",
    "frames_arr = []\n",
    "actions_arr = []\n",
    "\n",
    "for m in range(start_match, end_match + 1):\n",
    "    \n",
    "    num_of_frames, frames, actions, rewards, lifes = load_npz(data_path, m)\n",
    "    frames = frames[start_frame - 1:end_frame]\n",
    "    frames = frames.reshape(end_frame - start_frame + 1, 170, 120)\n",
    "    frames = frames[:, 30:130, :]\n",
    "    frames = frames.reshape(end_frame - start_frame + 1, 12000)\n",
    "    actions = actions[start_frame - 1:end_frame]\n",
    "    \n",
    "    action_one_hot = [prepare_action_data(i, ACTIONS_LIST) for i in actions]\n",
    "    actions = np.array(action_one_hot)\n",
    "    actions = actions.reshape(len(actions), -1)\n",
    "    \n",
    "    frames_arr.append(frames)\n",
    "    actions_arr.append(actions)\n",
    "    num_of_frames_arr.append(end_frame - start_frame + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc343996",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunked = []\n",
    "target_chunked = []\n",
    "for i in range(len(frames_arr)):\n",
    "    for j in range(len(indices[i]) - 1):\n",
    "        data_chunked.append(frames_arr[i][indices[i][j]:indices[i][j+1]])\n",
    "        target_chunked.append(actions_arr[i][indices[i][j]:indices[i][j+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c72054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alece\\miniconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\alece\\miniconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(data_chunked)/255\n",
    "Y_train = np.array(target_chunked)\n",
    "num_of_frames_arr = np.array(num_of_frames_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d83ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtrado = []\n",
    "Y_train_filtrado = []\n",
    "for i in range(len(X_train)):\n",
    "    if len(X_train[i]) > 100:\n",
    "        pass\n",
    "    else:\n",
    "        X_train_filtrado.append(X_train[i])\n",
    "        Y_train_filtrado.append(Y_train[i])\n",
    "X_train = X_train_filtrado\n",
    "Y_train = Y_train_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e695be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30268e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if zigzag:\n",
    "    X_train = np.array(frames_arr)/255\n",
    "    Y_train = actions_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8033bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(map(lambda x: torch.tensor(x), X_train))\n",
    "Y_train = list(map(lambda x: torch.tensor(x), Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59a7ce57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([120.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = torch.FloatTensor(list(map(len,X_train)))\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e515da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequence(X_train, batch_first=True).float()\n",
    "Y_train = pad_sequence(Y_train, batch_first=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2ce7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pack_padded_sequence(X_train, seq_len, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d2f6322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alece\\Desktop\\UnB\\tcc\\rnn_enduro\\2-lstm_train\\enduro_rnn.py:111: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.out(out)\n"
     ]
    }
   ],
   "source": [
    "out = model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "816678f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4758, 0.5242], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out[45])\n",
    "torch.argmax(out[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f581fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(predicted, target):\n",
    "    \n",
    "    predicted = torch.argmax(predicted, axis=1)\n",
    "    target = torch.argmax(target, axis=1)\n",
    "    \n",
    "    correct = torch.sum(predicted == target)\n",
    "    \n",
    "    acc = correct/predicted.shape[0]\n",
    "    return float(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e413907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc(out, Y_train.reshape(-1, len(ACTIONS_LIST)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d55682",
   "metadata": {},
   "source": [
    "## Prepare cell with trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2147390",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnncell = nn.RNNCell(12000, hidden_neurons)\n",
    "linear = nn.Linear(hidden_neurons, output_size)\n",
    "if is_softmax:\n",
    "    output = nn.Softmax()\n",
    "else:\n",
    "    output = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "935d5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnncell.weight_ih = model.rnn.weight_ih_l0\n",
    "rnncell.weight_hh = model.rnn.weight_hh_l0\n",
    "rnncell.bias_hh = model.rnn.bias_hh_l0\n",
    "rnncell.bias_ih = model.rnn.bias_ih_l0\n",
    "linear.weight = model.fc.weight\n",
    "linear.bias = model.fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99940fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hx = torch.zeros(1, hidden_neurons)\n",
    "cx = torch.zeros(1, hidden_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "659f1274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 12000])\n",
      "torch.Size([200, 200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([2, 200])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(model.rnn.weight_ih_l0.shape)\n",
    "print(model.rnn.weight_hh_l0.shape)\n",
    "print(model.rnn.bias_ih_l0.shape)\n",
    "print(model.rnn.bias_hh_l0.shape)\n",
    "print(model.fc.weight.shape)\n",
    "print(model.fc.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a9085",
   "metadata": {},
   "source": [
    "## Plot graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a8f0a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded NPZ\n"
     ]
    }
   ],
   "source": [
    "train_loss_arr = np.load(dir_path + 'train_loss_arr.npz')\n",
    "train_loss_arr = train_loss_arr.f.arr_0\n",
    "\n",
    "print(\"Successfully loaded NPZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b63b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graph(data, train_or_valid):\n",
    "    # summarize history for loss\n",
    "    plt.clf()\n",
    "    plt.plot(data, color='blue')\n",
    "    plt.title('model ' + train_or_valid + ' loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend([train_or_valid], loc='upper left')\n",
    "    plt.yscale('log')\n",
    "    # plt.savefig(newpath + '/' + 'train_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fbfb2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(train_loss_arr, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45fa5e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9030"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca5cdadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24999135732650757"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6048149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acc(out, Y_train.reshape(-1, len(ACTIONS_LIST)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac739f7",
   "metadata": {},
   "source": [
    "## Testing outputs of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d988171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alece\\miniconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "hx = torch.zeros(1, hidden_neurons)\n",
    "cx = torch.zeros(1, hidden_neurons)\n",
    "out_arr = []\n",
    "for i in range(end_frame - start_frame + 1):\n",
    "    step_input = X_train[0][i]\n",
    "    step_input = step_input.reshape(1, -1)\n",
    "    hx = rnncell(step_input, hx)\n",
    "    out = linear(hx)\n",
    "    out = output(out)\n",
    "    out_arr.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ab01242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(Y_train[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0d14e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(end_frame - start_frame + 1):\n",
    "    if torch.argmax(out_arr[i]) == torch.argmax(Y_train[i]):\n",
    "        count += 1\n",
    "count/(end_frame - start_frame + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71facede",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape(-1, len(ACTIONS_LIST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4844170d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acertou = 0\n",
    "errou = 0\n",
    "for i in range(end_frame - start_frame + 1):\n",
    "    if torch.argmax(Y_train[i]) == torch.argmax(out_arr[i]):\n",
    "        acertou += 1\n",
    "    else:\n",
    "        errou += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "516ac001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acertou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5df94d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3af7d308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acertou/(acertou + errou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed625364",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PackedSequence' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-d2ba684acd0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'PackedSequence' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308ded2",
   "metadata": {},
   "source": [
    "## Play Gym Enduro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fcd5989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-afd18e2eacbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64a6b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if zigzag:\n",
    "        \n",
    "    ACTIONS = {\n",
    "        \"right\": 2,\n",
    "        \"left\": 3,\n",
    "    }\n",
    "\n",
    "else:\n",
    "\n",
    "    ACTIONS = {\n",
    "        \"noop\": 0,\n",
    "        \"accelerate\": 1,\n",
    "        \"right\": 2,\n",
    "        \"left\": 3,\n",
    "        \"break\": 4,\n",
    "        \"right_break\": 5,\n",
    "        \"left_break\": 6,\n",
    "        \"right_accelerate\": 7,\n",
    "        \"left_accelerate\": 8,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec251108",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_min, y_max, x_min, x_max = 25+30, 195-40, 20, 140\n",
    "shape_of_single_frame = (1, (y_max-y_min),(x_max-x_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39688ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_time = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ece84",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Enduro-v0\")\n",
    "frame = env.reset()\n",
    "reward, action, done, info = 0, 0, False, {'ale.lives': 0}\n",
    "\n",
    "hx = torch.zeros(1, hidden_neurons)\n",
    "cx = torch.zeros(1, hidden_neurons)\n",
    "\n",
    "env.render()\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    time.sleep(sleep_time)\n",
    "    env.render()\n",
    "    \n",
    "    frame = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    frame = Image.fromarray(frame)\n",
    "    frame = frame.convert(\"L\")\n",
    "    \n",
    "    frame = np.asarray(frame)\n",
    "    frame = frame.reshape(1, -1)\n",
    "    frame = torch.tensor(frame)/255\n",
    "    \n",
    "    hx = rnncell(frame, hx)\n",
    "    out = linear(hx)\n",
    "    action = output(out)\n",
    "    \n",
    "    action = list(ACTIONS.values())[torch.argmax(action, axis=1)]\n",
    "    print(action)\n",
    "    frame, reward, done, info = env.step(action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
