{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e5d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from enduro_lstm import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a00118dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU (y/n) y\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "use_gpu = input(\"Use GPU (y/n) \")\n",
    "if use_gpu == 'y':\n",
    "    use_gpu = True\n",
    "else:\n",
    "    use_gpu = False\n",
    "\n",
    "device = conf_cuda(use_gpu)\n",
    "\n",
    "if use_gpu:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7309ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"models/continue_m45to50_f1to1000_epoch10001to20000_H200/\"\n",
    "model_path = path + \"continue_m45to50_f1to1000_epoch10001to20000_H200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99b7d5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_match = 45\n",
    "end_match = 50\n",
    "\n",
    "start_frame = 1\n",
    "end_frame = 1000\n",
    "\n",
    "output_size = 9\n",
    "hidden_neurons = 200\n",
    "\n",
    "n_epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65efc5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"../1-generate/data/\"\n",
    "obs = \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df747c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if obs == 'zigzag':\n",
    "    zigzag = True\n",
    "else:\n",
    "    zigzag = False\n",
    "zigzag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6306e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded NPZ.\n"
     ]
    }
   ],
   "source": [
    "train_loss_arr = np.load(path + 'train_loss_arr.npz')\n",
    "valid_loss_arr = np.load(path + 'valid_loss_arr.npz')\n",
    "valid_loss_mean_arr = np.load(path + 'valid_loss_mean_arr.npz')\n",
    "\n",
    "train_loss_arr = train_loss_arr.f.arr_0\n",
    "valid_loss_arr = valid_loss_arr.f.arr_0\n",
    "valid_loss_mean_arr = valid_loss_mean_arr.f.arr_0\n",
    "\n",
    "print(\"Successfully loaded NPZ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a37f4ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename):\n",
    "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        losslogger = checkpoint['losslogger']\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model, optimizer, start_epoch, losslogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5ef4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(device=device, input_size=20400, output_size=output_size, hidden_dim=hidden_neurons, n_layers=1)\n",
    "min_loss = 1e-05\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "486ed693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'models/continue_m45to50_f1to1000_epoch10001to20000_H200/continue_m45to50_f1to1000_epoch10001to20000_H200'\n",
      "=> loaded checkpoint 'models/continue_m45to50_f1to1000_epoch10001to20000_H200/continue_m45to50_f1to1000_epoch10001to20000_H200' (epoch 20001)\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, start_epoch, losslogger = load_checkpoint(model, optimizer, filename=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c0677b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0836f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    optimizer_to(optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91df1416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/continue_m45to50_f1to1000_epoch20001to30000_H200\n",
      "ATTENTION! folder not created. Training informations will overwrite the existing one\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{obs}_m{start_match}to{end_match}_f{start_frame}to{end_frame}_epoch{start_epoch}to{start_epoch + n_epochs - 1}_H{hidden_neurons}\"\n",
    "newpath = f\"models/\" + model_name\n",
    "if not os.path.exists(newpath):\n",
    "    print(f\"models/\" + model_name + \" created\")\n",
    "    os.makedirs(newpath)\n",
    "else:\n",
    "    print(f\"models/\" + model_name)\n",
    "    print(\"ATTENTION! folder not created. Training informations will overwrite the existing one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e93684",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebf90450",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_LIST = get_actions_list(zigzag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf34272",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_frames_arr = []\n",
    "frames_arr = []\n",
    "actions_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d1479c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n"
     ]
    }
   ],
   "source": [
    "for m in range(start_match, end_match + 1):\n",
    "    \n",
    "    num_of_frames, frames, actions, rewards, lifes = load_npz(data_path, m)\n",
    "    frames = frames[start_frame - 1:end_frame]\n",
    "    actions = actions[start_frame - 1:end_frame]\n",
    "    \n",
    "    action_one_hot = [prepare_action_data(i, ACTIONS_LIST) for i in actions]\n",
    "    actions = np.array(action_one_hot)\n",
    "    actions = actions.reshape(len(actions), -1)\n",
    "    \n",
    "    frames_arr.append(frames)\n",
    "    actions_arr.append(actions)\n",
    "    num_of_frames_arr.append(end_frame - start_frame + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd05155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(frames_arr)/255\n",
    "Y_train = np.array(actions_arr)\n",
    "num_of_frames_arr = np.array(num_of_frames_arr)\n",
    "\n",
    "X_train = torch.tensor(X_train).float()\n",
    "Y_train = torch.tensor(Y_train).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cea881e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU\n"
     ]
    }
   ],
   "source": [
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "if use_gpu:\n",
    "    print(\"Use GPU\")\n",
    "    model.cuda()\n",
    "    X_train = X_train.cuda() \n",
    "    Y_train = Y_train.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4a53d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Run\n",
    "loss_file = open(newpath + '/' + \"loss_file.txt\", \"w\")\n",
    "first_epoch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1db6e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = losslogger\n",
    "train_acc_arr = np.array([])\n",
    "valid_acc_arr = np.array([])\n",
    "valid_acc_mean_arr = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e9edd3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20010/30000-------------------------------------------\n",
      "Train -> Loss: 0.029002876952291 Acc: 0.809333324432373\n",
      "Valid -> Loss: 0.060422154764334 Acc: 0.587166696786880\n",
      "Epoch: 20020/30000-------------------------------------------\n",
      "Train -> Loss: 0.028994610533118 Acc: 0.809333324432373\n",
      "Valid -> Loss: 0.060581749926011 Acc: 0.586000025272369\n",
      "Epoch: 20030/30000-------------------------------------------\n",
      "Train -> Loss: 0.028988655656576 Acc: 0.809499979019165\n",
      "Valid -> Loss: 0.060583709428708 Acc: 0.586000025272369\n",
      "Epoch: 20040/30000-------------------------------------------\n",
      "Train -> Loss: 0.028983246535063 Acc: 0.809666633605957\n",
      "Valid -> Loss: 0.060609330112735 Acc: 0.586166689793269\n",
      "Epoch: 20050/30000-------------------------------------------\n",
      "Train -> Loss: 0.028978085145354 Acc: 0.810000002384186\n",
      "Valid -> Loss: 0.060618019352357 Acc: 0.585833360751470\n",
      "Epoch: 20060/30000-------------------------------------------\n",
      "Train -> Loss: 0.028973164036870 Acc: 0.810000002384186\n",
      "Valid -> Loss: 0.060626037418842 Acc: 0.585666696230570\n",
      "Epoch: 20070/30000-------------------------------------------\n",
      "Train -> Loss: 0.028968425467610 Acc: 0.810333311557770\n",
      "Valid -> Loss: 0.060642674565315 Acc: 0.585666696230570\n",
      "Epoch: 20080/30000-------------------------------------------\n",
      "Train -> Loss: 0.028963819146156 Acc: 0.810333311557770\n",
      "Valid -> Loss: 0.060652143632372 Acc: 0.585500031709671\n",
      "Epoch: 20090/30000-------------------------------------------\n",
      "Train -> Loss: 0.028959309682250 Acc: 0.810666680335999\n",
      "Valid -> Loss: 0.060666873430212 Acc: 0.585666696230570\n",
      "Epoch: 20100/30000-------------------------------------------\n",
      "Train -> Loss: 0.028954870998859 Acc: 0.810833334922791\n",
      "Valid -> Loss: 0.060680999731024 Acc: 0.585333357254664\n",
      "Epoch: 20110/30000-------------------------------------------\n",
      "Train -> Loss: 0.028950497508049 Acc: 0.810833334922791\n",
      "Valid -> Loss: 0.060697773471475 Acc: 0.585166692733765\n",
      "Epoch: 20120/30000-------------------------------------------\n",
      "Train -> Loss: 0.028946166858077 Acc: 0.810833334922791\n",
      "Valid -> Loss: 0.060710859795411 Acc: 0.585333357254664\n",
      "Epoch: 20130/30000-------------------------------------------\n",
      "Train -> Loss: 0.028941866010427 Acc: 0.810833334922791\n",
      "Valid -> Loss: 0.060724103823304 Acc: 0.585000028212865\n",
      "Epoch: 20140/30000-------------------------------------------\n",
      "Train -> Loss: 0.028937594965100 Acc: 0.810999989509583\n",
      "Valid -> Loss: 0.060738490273555 Acc: 0.585166692733765\n",
      "Epoch: 20150/30000-------------------------------------------\n",
      "Train -> Loss: 0.028933336958289 Acc: 0.810833334922791\n",
      "Valid -> Loss: 0.060751634960373 Acc: 0.584833363691966\n",
      "Epoch: 20160/30000-------------------------------------------\n",
      "Train -> Loss: 0.028929093852639 Acc: 0.811166644096375\n",
      "Valid -> Loss: 0.060764014720917 Acc: 0.584833363691966\n",
      "Epoch: 20170/30000-------------------------------------------\n",
      "Train -> Loss: 0.028924858197570 Acc: 0.811166644096375\n",
      "Valid -> Loss: 0.060776698713501 Acc: 0.584833363691966\n",
      "Epoch: 20180/30000-------------------------------------------\n",
      "Train -> Loss: 0.028920622542500 Acc: 0.811166644096375\n",
      "Valid -> Loss: 0.060791653270523 Acc: 0.584666699171066\n",
      "Epoch: 20190/30000-------------------------------------------\n",
      "Train -> Loss: 0.028916394338012 Acc: 0.811166644096375\n",
      "Valid -> Loss: 0.060811112324397 Acc: 0.584333360195160\n",
      "Epoch: 20200/30000-------------------------------------------\n",
      "Train -> Loss: 0.028912682086229 Acc: 0.810999989509583\n",
      "Valid -> Loss: 0.060889111210903 Acc: 0.583000034093857\n",
      "Epoch: 20210/30000-------------------------------------------\n",
      "Train -> Loss: 0.028981106355786 Acc: 0.809166669845581\n",
      "Valid -> Loss: 0.061724205190937 Acc: 0.574833353360494\n",
      "Epoch: 20220/30000-------------------------------------------\n",
      "Train -> Loss: 0.030873462557793 Acc: 0.797166645526886\n",
      "Valid -> Loss: 0.064727221305172 Acc: 0.547500014305115\n",
      "Epoch: 20230/30000-------------------------------------------\n",
      "Train -> Loss: 0.030224414542317 Acc: 0.802333295345306\n",
      "Valid -> Loss: 0.057505942881107 Acc: 0.612166692813238\n",
      "Epoch: 20240/30000-------------------------------------------\n",
      "Train -> Loss: 0.029193079099059 Acc: 0.809166669845581\n",
      "Valid -> Loss: 0.057644833500187 Acc: 0.610000024239222\n",
      "Epoch: 20250/30000-------------------------------------------\n",
      "Train -> Loss: 0.034406878054142 Acc: 0.777666687965393\n",
      "Valid -> Loss: 0.066908044119676 Acc: 0.528333360950152\n",
      "Epoch: 20260/30000-------------------------------------------\n",
      "Train -> Loss: 0.030522786080837 Acc: 0.797500014305115\n",
      "Valid -> Loss: 0.064289790888627 Acc: 0.548000027736028\n",
      "Epoch: 20270/30000-------------------------------------------\n",
      "Train -> Loss: 0.033190201967955 Acc: 0.784333348274231\n",
      "Valid -> Loss: 0.065690619250139 Acc: 0.537000035246213\n",
      "Epoch: 20280/30000-------------------------------------------\n",
      "Train -> Loss: 0.029520353302360 Acc: 0.809333324432373\n",
      "Valid -> Loss: 0.058335652574897 Acc: 0.602833370367686\n",
      "Epoch: 20290/30000-------------------------------------------\n",
      "Train -> Loss: 0.030277211219072 Acc: 0.806500017642975\n",
      "Valid -> Loss: 0.054132846494516 Acc: 0.640833377838135\n",
      "Epoch: 20300/30000-------------------------------------------\n",
      "Train -> Loss: 0.031888164579868 Acc: 0.795000016689301\n",
      "Valid -> Loss: 0.059234635283550 Acc: 0.593000014623006\n",
      "Epoch: 20310/30000-------------------------------------------\n",
      "Train -> Loss: 0.032057054340839 Acc: 0.790499985218048\n",
      "Valid -> Loss: 0.063067414487402 Acc: 0.556500037511190\n",
      "Epoch: 20320/30000-------------------------------------------\n",
      "Train -> Loss: 0.031624916940928 Acc: 0.793999969959259\n",
      "Valid -> Loss: 0.059743926549951 Acc: 0.589000026384989\n",
      "Epoch: 20330/30000-------------------------------------------\n",
      "Train -> Loss: 0.030383549630642 Acc: 0.805999994277954\n",
      "Valid -> Loss: 0.059234968076150 Acc: 0.594000031550725\n",
      "Epoch: 20340/30000-------------------------------------------\n",
      "Train -> Loss: 0.029268467798829 Acc: 0.806999981403351\n",
      "Valid -> Loss: 0.060341790939371 Acc: 0.584833353757858\n",
      "Epoch: 20350/30000-------------------------------------------\n",
      "Train -> Loss: 0.029116468504071 Acc: 0.807333350181580\n",
      "Valid -> Loss: 0.058885100608071 Acc: 0.600333352883657\n",
      "Epoch: 20360/30000-------------------------------------------\n",
      "Train -> Loss: 0.029043817892671 Acc: 0.810499966144562\n",
      "Valid -> Loss: 0.060421215991179 Acc: 0.586833367745082\n",
      "Epoch: 20370/30000-------------------------------------------\n",
      "Train -> Loss: 0.028936265036464 Acc: 0.810333311557770\n",
      "Valid -> Loss: 0.060418198506037 Acc: 0.587833364804586\n",
      "Epoch: 20380/30000-------------------------------------------\n",
      "Train -> Loss: 0.028922764584422 Acc: 0.810333311557770\n",
      "Valid -> Loss: 0.060547800113757 Acc: 0.585666696230570\n",
      "Epoch: 20390/30000-------------------------------------------\n",
      "Train -> Loss: 0.028908297419548 Acc: 0.810333311557770\n",
      "Valid -> Loss: 0.060449808835983 Acc: 0.587166706720988\n",
      "Epoch: 20400/30000-------------------------------------------\n",
      "Train -> Loss: 0.028889516368508 Acc: 0.810499966144562\n",
      "Valid -> Loss: 0.060717767104506 Acc: 0.584166685740153\n",
      "Epoch: 20410/30000-------------------------------------------\n",
      "Train -> Loss: 0.028877761214972 Acc: 0.810666680335999\n",
      "Valid -> Loss: 0.060670282070835 Acc: 0.584833363691966\n",
      "Epoch: 20420/30000-------------------------------------------\n",
      "Train -> Loss: 0.028869800269604 Acc: 0.810833334922791\n",
      "Valid -> Loss: 0.060653615742922 Acc: 0.585666696230570\n",
      "Epoch: 20430/30000-------------------------------------------\n",
      "Train -> Loss: 0.028862021863461 Acc: 0.811166644096375\n",
      "Valid -> Loss: 0.060688802351554 Acc: 0.585166692733765\n",
      "Epoch: 20440/30000-------------------------------------------\n",
      "Train -> Loss: 0.028855342417955 Acc: 0.811166644096375\n",
      "Valid -> Loss: 0.060726239035527 Acc: 0.584500024716059\n",
      "Epoch: 20450/30000-------------------------------------------\n",
      "Train -> Loss: 0.028849219903350 Acc: 0.811166644096375\n",
      "Valid -> Loss: 0.060725058118502 Acc: 0.584333360195160\n",
      "Epoch: 20460/30000-------------------------------------------\n",
      "Train -> Loss: 0.028843456879258 Acc: 0.810999989509583\n",
      "Valid -> Loss: 0.060740029439330 Acc: 0.583666692177455\n",
      "Epoch: 20470/30000-------------------------------------------\n",
      "Train -> Loss: 0.028837973251939 Acc: 0.811333298683167\n",
      "Valid -> Loss: 0.060758940254649 Acc: 0.583666692177455\n",
      "Epoch: 20480/30000-------------------------------------------\n",
      "Train -> Loss: 0.028832700103521 Acc: 0.811333298683167\n",
      "Valid -> Loss: 0.060771086563667 Acc: 0.583333363135656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20490/30000-------------------------------------------\n",
      "Train -> Loss: 0.028827587142587 Acc: 0.811333298683167\n",
      "Valid -> Loss: 0.060787774001559 Acc: 0.582833369572957\n",
      "Epoch: 20500/30000-------------------------------------------\n",
      "Train -> Loss: 0.028822598978877 Acc: 0.811666667461395\n",
      "Valid -> Loss: 0.060799886162082 Acc: 0.582166701555252\n",
      "Epoch: 20510/30000-------------------------------------------\n",
      "Train -> Loss: 0.028817707672715 Acc: 0.811666667461395\n",
      "Valid -> Loss: 0.060813358674447 Acc: 0.582166701555252\n",
      "Epoch: 20520/30000-------------------------------------------\n",
      "Train -> Loss: 0.028812894597650 Acc: 0.811666667461395\n",
      "Valid -> Loss: 0.060825451587637 Acc: 0.582000037034353\n",
      "Epoch: 20530/30000-------------------------------------------\n",
      "Train -> Loss: 0.028808141127229 Acc: 0.811999976634979\n",
      "Valid -> Loss: 0.060838688785831 Acc: 0.582000037034353\n",
      "Epoch: 20540/30000-------------------------------------------\n",
      "Train -> Loss: 0.028803424909711 Acc: 0.812166631221771\n",
      "Valid -> Loss: 0.060850093762080 Acc: 0.581333369016647\n",
      "Epoch: 20550/30000-------------------------------------------\n",
      "Train -> Loss: 0.028798745945096 Acc: 0.812166631221771\n",
      "Valid -> Loss: 0.060863117997845 Acc: 0.581333369016647\n",
      "Epoch: 20560/30000-------------------------------------------\n",
      "Train -> Loss: 0.028794085606933 Acc: 0.812333345413208\n",
      "Valid -> Loss: 0.060873866702120 Acc: 0.580833365519842\n",
      "Epoch: 20570/30000-------------------------------------------\n",
      "Train -> Loss: 0.028789428994060 Acc: 0.812500000000000\n",
      "Valid -> Loss: 0.060885422552625 Acc: 0.580833375453949\n",
      "Epoch: 20580/30000-------------------------------------------\n",
      "Train -> Loss: 0.028784774243832 Acc: 0.812500000000000\n",
      "Valid -> Loss: 0.060896624500553 Acc: 0.580666700998942\n",
      "Epoch: 20590/30000-------------------------------------------\n",
      "Train -> Loss: 0.028780113905668 Acc: 0.812500000000000\n",
      "Valid -> Loss: 0.060910923406482 Acc: 0.581000030040741\n",
      "Epoch: 20600/30000-------------------------------------------\n",
      "Train -> Loss: 0.028775464743376 Acc: 0.812500000000000\n",
      "Valid -> Loss: 0.060932905102770 Acc: 0.581000030040741\n",
      "Epoch: 20610/30000-------------------------------------------\n",
      "Train -> Loss: 0.028772279620171 Acc: 0.811833322048187\n",
      "Valid -> Loss: 0.061059464390079 Acc: 0.579500029484431\n",
      "Epoch: 20620/30000-------------------------------------------\n",
      "Train -> Loss: 0.029015149921179 Acc: 0.810999989509583\n",
      "Valid -> Loss: 0.062554633244872 Acc: 0.566500018040339\n",
      "Epoch: 20630/30000-------------------------------------------\n",
      "Train -> Loss: 0.035210080444813 Acc: 0.773833334445953\n",
      "Valid -> Loss: 0.067406599720319 Acc: 0.525000035762787\n",
      "Epoch: 20640/30000-------------------------------------------\n",
      "Train -> Loss: 0.029136387631297 Acc: 0.814999997615814\n",
      "Valid -> Loss: 0.062688731277982 Acc: 0.561000039180120\n",
      "Epoch: 20650/30000-------------------------------------------\n",
      "Train -> Loss: 0.029848523437977 Acc: 0.804166674613953\n",
      "Valid -> Loss: 0.061782354488969 Acc: 0.571666687726974\n",
      "Epoch: 20660/30000-------------------------------------------\n",
      "Train -> Loss: 0.029171241447330 Acc: 0.812500000000000\n",
      "Valid -> Loss: 0.059543513382475 Acc: 0.592500021060308\n",
      "Epoch: 20670/30000-------------------------------------------\n",
      "Train -> Loss: 0.028925294056535 Acc: 0.811999976634979\n",
      "Valid -> Loss: 0.057676990826925 Acc: 0.611500024795532\n",
      "Epoch: 20680/30000-------------------------------------------\n",
      "Train -> Loss: 0.029274825006723 Acc: 0.807666659355164\n",
      "Valid -> Loss: 0.059779595583677 Acc: 0.588500022888184\n",
      "Epoch: 20690/30000-------------------------------------------\n",
      "Train -> Loss: 0.028786810114980 Acc: 0.811666667461395\n",
      "Valid -> Loss: 0.061675520613790 Acc: 0.573500037193298\n",
      "Epoch: 20700/30000-------------------------------------------\n",
      "Train -> Loss: 0.028790967538953 Acc: 0.810666680335999\n",
      "Valid -> Loss: 0.061135261630019 Acc: 0.580833355585734\n",
      "Epoch: 20710/30000-------------------------------------------\n",
      "Train -> Loss: 0.028760705143213 Acc: 0.812166631221771\n",
      "Valid -> Loss: 0.060917420312762 Acc: 0.583333363135656\n",
      "Epoch: 20720/30000-------------------------------------------\n",
      "Train -> Loss: 0.028747042641044 Acc: 0.811666667461395\n",
      "Valid -> Loss: 0.060964750746886 Acc: 0.582333366076151\n",
      "Epoch: 20730/30000-------------------------------------------\n",
      "Train -> Loss: 0.028736917302012 Acc: 0.812166631221771\n",
      "Valid -> Loss: 0.060832223544518 Acc: 0.583500037590663\n",
      "Epoch: 20740/30000-------------------------------------------\n",
      "Train -> Loss: 0.028730332851410 Acc: 0.812833309173584\n",
      "Valid -> Loss: 0.060798443232973 Acc: 0.583500037590663\n",
      "Epoch: 20750/30000-------------------------------------------\n",
      "Train -> Loss: 0.028723284602165 Acc: 0.812500000000000\n",
      "Valid -> Loss: 0.060886372501651 Acc: 0.583166708548864\n",
      "Epoch: 20760/30000-------------------------------------------\n",
      "Train -> Loss: 0.028716729953885 Acc: 0.812500000000000\n",
      "Valid -> Loss: 0.060885641102990 Acc: 0.583000034093857\n",
      "Epoch: 20770/30000-------------------------------------------\n",
      "Train -> Loss: 0.028710415586829 Acc: 0.812833309173584\n",
      "Valid -> Loss: 0.060927742471298 Acc: 0.582666695117950\n",
      "Epoch: 20780/30000-------------------------------------------\n",
      "Train -> Loss: 0.028704175725579 Acc: 0.812999963760376\n",
      "Valid -> Loss: 0.060925726468364 Acc: 0.582500040531158\n",
      "Epoch: 20790/30000-------------------------------------------\n",
      "Train -> Loss: 0.028698146343231 Acc: 0.812999963760376\n",
      "Valid -> Loss: 0.060927148287495 Acc: 0.582500040531158\n",
      "Epoch: 20800/30000-------------------------------------------\n",
      "Train -> Loss: 0.028695954009891 Acc: 0.813666641712189\n",
      "Valid -> Loss: 0.060749545072516 Acc: 0.583666702111562\n",
      "Epoch: 20810/30000-------------------------------------------\n",
      "Train -> Loss: 0.029246475547552 Acc: 0.806833326816559\n",
      "Valid -> Loss: 0.058420601611336 Acc: 0.604500025510788\n",
      "Epoch: 20820/30000-------------------------------------------\n",
      "Train -> Loss: 0.029184300452471 Acc: 0.809166669845581\n",
      "Valid -> Loss: 0.059749131401380 Acc: 0.590500026941299\n",
      "Epoch: 20830/30000-------------------------------------------\n",
      "Train -> Loss: 0.028998512774706 Acc: 0.810666680335999\n",
      "Valid -> Loss: 0.057689479241769 Acc: 0.608500023682912\n",
      "Epoch: 20840/30000-------------------------------------------\n",
      "Train -> Loss: 0.030016863718629 Acc: 0.803666651248932\n",
      "Valid -> Loss: 0.058172117297848 Acc: 0.605666697025299\n",
      "Epoch: 20850/30000-------------------------------------------\n",
      "Train -> Loss: 0.030250148847699 Acc: 0.807666659355164\n",
      "Valid -> Loss: 0.058964688330889 Acc: 0.598166694243749\n",
      "Epoch: 20860/30000-------------------------------------------\n",
      "Train -> Loss: 0.029064312577248 Acc: 0.809499979019165\n",
      "Valid -> Loss: 0.059447167441249 Acc: 0.595000018676122\n",
      "Epoch: 20870/30000-------------------------------------------\n",
      "Train -> Loss: 0.028703670948744 Acc: 0.811999976634979\n",
      "Valid -> Loss: 0.060169578840335 Acc: 0.590666691462199\n",
      "Epoch: 20880/30000-------------------------------------------\n",
      "Train -> Loss: 0.028685584664345 Acc: 0.812833309173584\n",
      "Valid -> Loss: 0.060573851068815 Acc: 0.583833366632462\n",
      "Epoch: 20890/30000-------------------------------------------\n",
      "Train -> Loss: 0.028674134984612 Acc: 0.812833309173584\n",
      "Valid -> Loss: 0.060871811583638 Acc: 0.583500027656555\n",
      "Epoch: 20900/30000-------------------------------------------\n",
      "Train -> Loss: 0.028662096709013 Acc: 0.812999963760376\n",
      "Valid -> Loss: 0.061102697625756 Acc: 0.580833375453949\n",
      "Epoch: 20910/30000-------------------------------------------\n",
      "Train -> Loss: 0.028652813285589 Acc: 0.813833296298981\n",
      "Valid -> Loss: 0.060894081989924 Acc: 0.582833369572957\n",
      "Epoch: 20920/30000-------------------------------------------\n",
      "Train -> Loss: 0.028645787388086 Acc: 0.813666641712189\n",
      "Valid -> Loss: 0.061001423125466 Acc: 0.581500033537547\n",
      "Epoch: 20930/30000-------------------------------------------\n",
      "Train -> Loss: 0.028639642521739 Acc: 0.813666641712189\n",
      "Valid -> Loss: 0.061073477069537 Acc: 0.581166684627533\n",
      "Epoch: 20940/30000-------------------------------------------\n",
      "Train -> Loss: 0.028665797784925 Acc: 0.814166665077209\n",
      "Valid -> Loss: 0.061636002734303 Acc: 0.575500031312307\n",
      "Epoch: 20950/30000-------------------------------------------\n",
      "Train -> Loss: 0.030238239094615 Acc: 0.801833331584930\n",
      "Valid -> Loss: 0.064566671848297 Acc: 0.550000011920929\n",
      "Epoch: 20960/30000-------------------------------------------\n",
      "Train -> Loss: 0.032144747674465 Acc: 0.798999965190887\n",
      "Valid -> Loss: 0.058981332927942 Acc: 0.597000022729238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20970/30000-------------------------------------------\n",
      "Train -> Loss: 0.030422756448388 Acc: 0.802999973297119\n",
      "Valid -> Loss: 0.060169967512290 Acc: 0.585666696230570\n",
      "Epoch: 20980/30000-------------------------------------------\n",
      "Train -> Loss: 0.029966836795211 Acc: 0.806500017642975\n",
      "Valid -> Loss: 0.062142884979645 Acc: 0.572166691223780\n",
      "Epoch: 20990/30000-------------------------------------------\n",
      "Train -> Loss: 0.029161386191845 Acc: 0.815333306789398\n",
      "Valid -> Loss: 0.058607066671054 Acc: 0.599500030279160\n",
      "Epoch: 21000/30000-------------------------------------------\n",
      "Train -> Loss: 0.028701923787594 Acc: 0.812166631221771\n",
      "Valid -> Loss: 0.061034992337227 Acc: 0.580666691064835\n",
      "Epoch: 21010/30000-------------------------------------------\n",
      "Train -> Loss: 0.028717685490847 Acc: 0.812833309173584\n",
      "Valid -> Loss: 0.060801657537619 Acc: 0.583833346764247\n",
      "Epoch: 21020/30000-------------------------------------------\n",
      "Train -> Loss: 0.028649851679802 Acc: 0.813166677951813\n",
      "Valid -> Loss: 0.061118836825093 Acc: 0.582500030597051\n",
      "Epoch: 21030/30000-------------------------------------------\n",
      "Train -> Loss: 0.028623728081584 Acc: 0.813666641712189\n",
      "Valid -> Loss: 0.060942000399033 Acc: 0.582333356142044\n",
      "Epoch: 21040/30000-------------------------------------------\n",
      "Train -> Loss: 0.028611090034246 Acc: 0.813833296298981\n",
      "Valid -> Loss: 0.060649566352367 Acc: 0.585000028212865\n",
      "Epoch: 21050/30000-------------------------------------------\n",
      "Train -> Loss: 0.028606776148081 Acc: 0.813833296298981\n",
      "Valid -> Loss: 0.061176802963018 Acc: 0.580666691064835\n",
      "Epoch: 21060/30000-------------------------------------------\n",
      "Train -> Loss: 0.028596252202988 Acc: 0.814333319664001\n",
      "Valid -> Loss: 0.060832334682345 Acc: 0.583000034093857\n",
      "Epoch: 21070/30000-------------------------------------------\n",
      "Train -> Loss: 0.028588786721230 Acc: 0.814000010490417\n",
      "Valid -> Loss: 0.061039129272103 Acc: 0.582333366076151\n",
      "Epoch: 21080/30000-------------------------------------------\n",
      "Train -> Loss: 0.028585217893124 Acc: 0.814166665077209\n",
      "Valid -> Loss: 0.061141612629096 Acc: 0.580833355585734\n",
      "Epoch: 21090/30000-------------------------------------------\n",
      "Train -> Loss: 0.028669068589807 Acc: 0.815166652202606\n",
      "Valid -> Loss: 0.061978590364257 Acc: 0.571666697661082\n",
      "Epoch: 21100/30000-------------------------------------------\n",
      "Train -> Loss: 0.029409883543849 Acc: 0.807833313941956\n",
      "Valid -> Loss: 0.062818932036559 Acc: 0.564333359400431\n",
      "Epoch: 21110/30000-------------------------------------------\n",
      "Train -> Loss: 0.030077734962106 Acc: 0.804333329200745\n",
      "Valid -> Loss: 0.060341448212663 Acc: 0.582666695117950\n",
      "Epoch: 21120/30000-------------------------------------------\n",
      "Train -> Loss: 0.037074360996485 Acc: 0.758166670799255\n",
      "Valid -> Loss: 0.066877244661252 Acc: 0.520833363135656\n",
      "Epoch: 21130/30000-------------------------------------------\n",
      "Train -> Loss: 0.029017809778452 Acc: 0.806999981403351\n",
      "Valid -> Loss: 0.060420839736859 Acc: 0.585333367188772\n",
      "Epoch: 21140/30000-------------------------------------------\n",
      "Train -> Loss: 0.030044760555029 Acc: 0.805000007152557\n",
      "Valid -> Loss: 0.061174325644970 Acc: 0.574666678905487\n",
      "Epoch: 21150/30000-------------------------------------------\n",
      "Train -> Loss: 0.029588984325528 Acc: 0.810000002384186\n",
      "Valid -> Loss: 0.058257116625706 Acc: 0.604666699965795\n",
      "Epoch: 21160/30000-------------------------------------------\n",
      "Train -> Loss: 0.028903897851706 Acc: 0.809000015258789\n",
      "Valid -> Loss: 0.059236644456784 Acc: 0.598333368698756\n",
      "Epoch: 21170/30000-------------------------------------------\n",
      "Train -> Loss: 0.030376140028238 Acc: 0.800499975681305\n",
      "Valid -> Loss: 0.063196125750740 Acc: 0.564166684945424\n",
      "Epoch: 21180/30000-------------------------------------------\n",
      "Train -> Loss: 0.029748896136880 Acc: 0.809666633605957\n",
      "Valid -> Loss: 0.057506172607342 Acc: 0.611166685819626\n",
      "Epoch: 21190/30000-------------------------------------------\n",
      "Train -> Loss: 0.028859654441476 Acc: 0.815833330154419\n",
      "Valid -> Loss: 0.061111579338710 Acc: 0.581500023603439\n",
      "Epoch: 21200/30000-------------------------------------------\n",
      "Train -> Loss: 0.028740542009473 Acc: 0.813166677951813\n",
      "Valid -> Loss: 0.059732115517060 Acc: 0.592333356539408\n",
      "Epoch: 21210/30000-------------------------------------------\n",
      "Train -> Loss: 0.028624927625060 Acc: 0.816833317279816\n",
      "Valid -> Loss: 0.060986217111349 Acc: 0.582000017166138\n",
      "Epoch: 21220/30000-------------------------------------------\n",
      "Train -> Loss: 0.028588127344847 Acc: 0.813499987125397\n",
      "Valid -> Loss: 0.060568394760291 Acc: 0.585500031709671\n",
      "Epoch: 21230/30000-------------------------------------------\n",
      "Train -> Loss: 0.028580782935023 Acc: 0.814666628837585\n",
      "Valid -> Loss: 0.060656369353334 Acc: 0.584666709105174\n",
      "Epoch: 21240/30000-------------------------------------------\n",
      "Train -> Loss: 0.028568234294653 Acc: 0.813833296298981\n",
      "Valid -> Loss: 0.060772471129894 Acc: 0.583833366632462\n",
      "Epoch: 21250/30000-------------------------------------------\n",
      "Train -> Loss: 0.028559438884258 Acc: 0.814000010490417\n",
      "Valid -> Loss: 0.060748790080349 Acc: 0.584000031153361\n",
      "Epoch: 21260/30000-------------------------------------------\n",
      "Train -> Loss: 0.028550988063216 Acc: 0.814000010490417\n",
      "Valid -> Loss: 0.060755753889680 Acc: 0.584000041087469\n",
      "Epoch: 21270/30000-------------------------------------------\n",
      "Train -> Loss: 0.028543675318360 Acc: 0.814333319664001\n",
      "Valid -> Loss: 0.060763534158468 Acc: 0.584000041087469\n",
      "Epoch: 21280/30000-------------------------------------------\n",
      "Train -> Loss: 0.028536986559629 Acc: 0.814666628837585\n",
      "Valid -> Loss: 0.060781859482328 Acc: 0.584000041087469\n",
      "Epoch: 21290/30000-------------------------------------------\n",
      "Train -> Loss: 0.028530744835734 Acc: 0.814499974250793\n",
      "Valid -> Loss: 0.060812929645181 Acc: 0.583666702111562\n",
      "Epoch: 21300/30000-------------------------------------------\n",
      "Train -> Loss: 0.028524816036224 Acc: 0.814999997615814\n",
      "Valid -> Loss: 0.060831581552823 Acc: 0.583333363135656\n",
      "Epoch: 21310/30000-------------------------------------------\n",
      "Train -> Loss: 0.028519120067358 Acc: 0.815166652202606\n",
      "Valid -> Loss: 0.060853858167926 Acc: 0.583333373069763\n",
      "Epoch: 21320/30000-------------------------------------------\n",
      "Train -> Loss: 0.028513602912426 Acc: 0.814999997615814\n",
      "Valid -> Loss: 0.060870838661989 Acc: 0.583166708548864\n",
      "Epoch: 21330/30000-------------------------------------------\n",
      "Train -> Loss: 0.028508238494396 Acc: 0.815333306789398\n",
      "Valid -> Loss: 0.060886049643159 Acc: 0.583166708548864\n",
      "Epoch: 21340/30000-------------------------------------------\n",
      "Train -> Loss: 0.028502993285656 Acc: 0.815333306789398\n",
      "Valid -> Loss: 0.060903458545605 Acc: 0.583000044027964\n",
      "Epoch: 21350/30000-------------------------------------------\n",
      "Train -> Loss: 0.028497824445367 Acc: 0.815333306789398\n",
      "Valid -> Loss: 0.060919602711995 Acc: 0.582666705052058\n",
      "Epoch: 21360/30000-------------------------------------------\n",
      "Train -> Loss: 0.028492718935013 Acc: 0.815500020980835\n",
      "Valid -> Loss: 0.060935235892733 Acc: 0.581833372513453\n",
      "Epoch: 21370/30000-------------------------------------------\n",
      "Train -> Loss: 0.028487633913755 Acc: 0.815666675567627\n",
      "Valid -> Loss: 0.060952420035998 Acc: 0.581666707992554\n",
      "Epoch: 21380/30000-------------------------------------------\n",
      "Train -> Loss: 0.028482554480433 Acc: 0.815833330154419\n",
      "Valid -> Loss: 0.060967513670524 Acc: 0.581833372513453\n",
      "Epoch: 21390/30000-------------------------------------------\n",
      "Train -> Loss: 0.028477462008595 Acc: 0.815999984741211\n",
      "Valid -> Loss: 0.060981805746754 Acc: 0.581666707992554\n",
      "Epoch: 21400/30000-------------------------------------------\n",
      "Train -> Loss: 0.028472373262048 Acc: 0.815999984741211\n",
      "Valid -> Loss: 0.061007385452588 Acc: 0.581666707992554\n",
      "Epoch: 21410/30000-------------------------------------------\n",
      "Train -> Loss: 0.028470540419221 Acc: 0.816666662693024\n",
      "Valid -> Loss: 0.061214183146755 Acc: 0.580000032981237\n",
      "Epoch: 21420/30000-------------------------------------------\n",
      "Train -> Loss: 0.029577016830444 Acc: 0.807500004768372\n",
      "Valid -> Loss: 0.064472342530886 Acc: 0.551166693369547\n",
      "Epoch: 21430/30000-------------------------------------------\n",
      "Train -> Loss: 0.028744939714670 Acc: 0.811999976634979\n",
      "Valid -> Loss: 0.058698832367857 Acc: 0.602500031391780\n",
      "Epoch: 21440/30000-------------------------------------------\n",
      "Train -> Loss: 0.030866082757711 Acc: 0.811333298683167\n",
      "Valid -> Loss: 0.056202340871096 Acc: 0.624833355347315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21450/30000-------------------------------------------\n",
      "Train -> Loss: 0.029418736696243 Acc: 0.804833352565765\n",
      "Valid -> Loss: 0.060165576636791 Acc: 0.585833360751470\n",
      "Epoch: 21460/30000-------------------------------------------\n",
      "Train -> Loss: 0.029804183170199 Acc: 0.808666646480560\n",
      "Valid -> Loss: 0.061152133469780 Acc: 0.578500012556712\n",
      "Epoch: 21470/30000-------------------------------------------\n",
      "Train -> Loss: 0.028902908787131 Acc: 0.814000010490417\n",
      "Valid -> Loss: 0.058112341910601 Acc: 0.608500023682912\n",
      "Epoch: 21480/30000-------------------------------------------\n",
      "Train -> Loss: 0.028600472956896 Acc: 0.816166639328003\n",
      "Valid -> Loss: 0.062792939444383 Acc: 0.564833362897237\n",
      "Epoch: 21490/30000-------------------------------------------\n",
      "Train -> Loss: 0.029764154925942 Acc: 0.812999963760376\n",
      "Valid -> Loss: 0.057053677737713 Acc: 0.614666700363159\n",
      "Epoch: 21500/30000-------------------------------------------\n",
      "Train -> Loss: 0.029129263013601 Acc: 0.807999968528748\n",
      "Valid -> Loss: 0.061485622078180 Acc: 0.572833369175593\n",
      "Epoch: 21510/30000-------------------------------------------\n",
      "Train -> Loss: 0.034088082611561 Acc: 0.782999992370605\n",
      "Valid -> Loss: 0.065693574026227 Acc: 0.533666705091794\n",
      "Epoch: 21520/30000-------------------------------------------\n",
      "Train -> Loss: 0.032174617052078 Acc: 0.789499998092651\n",
      "Valid -> Loss: 0.059002997974555 Acc: 0.596166690190633\n",
      "Epoch: 21530/30000-------------------------------------------\n",
      "Train -> Loss: 0.030233705416322 Acc: 0.808166682720184\n",
      "Valid -> Loss: 0.061348671714465 Acc: 0.572333355744680\n",
      "Epoch: 21540/30000-------------------------------------------\n",
      "Train -> Loss: 0.029836822301149 Acc: 0.805000007152557\n",
      "Valid -> Loss: 0.061866864562035 Acc: 0.567666699488958\n",
      "Epoch: 21550/30000-------------------------------------------\n",
      "Train -> Loss: 0.030246239155531 Acc: 0.804499983787537\n",
      "Valid -> Loss: 0.060366043200095 Acc: 0.582500010728836\n",
      "Epoch: 21560/30000-------------------------------------------\n",
      "Train -> Loss: 0.030880745500326 Acc: 0.802166640758514\n",
      "Valid -> Loss: 0.062171022718151 Acc: 0.565500020980835\n",
      "Epoch: 21570/30000-------------------------------------------\n",
      "Train -> Loss: 0.030701948329806 Acc: 0.802833318710327\n",
      "Valid -> Loss: 0.061691101019581 Acc: 0.568333357572556\n",
      "Epoch: 21580/30000-------------------------------------------\n",
      "Train -> Loss: 0.029619641602039 Acc: 0.808833301067352\n",
      "Valid -> Loss: 0.062528929983576 Acc: 0.561333358287811\n",
      "Epoch: 21590/30000-------------------------------------------\n",
      "Train -> Loss: 0.028694272041321 Acc: 0.819333314895630\n",
      "Valid -> Loss: 0.061714715634783 Acc: 0.571000029643377\n",
      "Epoch: 21600/30000-------------------------------------------\n",
      "Train -> Loss: 0.028587916865945 Acc: 0.816833317279816\n",
      "Valid -> Loss: 0.060502087076505 Acc: 0.586833367745082\n",
      "Epoch: 21610/30000-------------------------------------------\n",
      "Train -> Loss: 0.028572356328368 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.060630351305008 Acc: 0.583833356698354\n",
      "Epoch: 21620/30000-------------------------------------------\n",
      "Train -> Loss: 0.028516527265310 Acc: 0.816833317279816\n",
      "Valid -> Loss: 0.060651895900567 Acc: 0.584166705608368\n",
      "Epoch: 21630/30000-------------------------------------------\n",
      "Train -> Loss: 0.028485581278801 Acc: 0.817499995231628\n",
      "Valid -> Loss: 0.060766889403264 Acc: 0.584833373626073\n",
      "Epoch: 21640/30000-------------------------------------------\n",
      "Train -> Loss: 0.028468057513237 Acc: 0.816666662693024\n",
      "Valid -> Loss: 0.060797696933150 Acc: 0.585166702667872\n",
      "Epoch: 21650/30000-------------------------------------------\n",
      "Train -> Loss: 0.028456449508667 Acc: 0.816166639328003\n",
      "Valid -> Loss: 0.060853119939566 Acc: 0.583833356698354\n",
      "Epoch: 21660/30000-------------------------------------------\n",
      "Train -> Loss: 0.028447793796659 Acc: 0.815833330154419\n",
      "Valid -> Loss: 0.060861849536498 Acc: 0.583500027656555\n",
      "Epoch: 21670/30000-------------------------------------------\n",
      "Train -> Loss: 0.028440002351999 Acc: 0.816333353519440\n",
      "Valid -> Loss: 0.060862818111976 Acc: 0.583500027656555\n",
      "Epoch: 21680/30000-------------------------------------------\n",
      "Train -> Loss: 0.028432548046112 Acc: 0.816999971866608\n",
      "Valid -> Loss: 0.060874893640478 Acc: 0.583666692177455\n",
      "Epoch: 21690/30000-------------------------------------------\n",
      "Train -> Loss: 0.028425537049770 Acc: 0.817333340644836\n",
      "Valid -> Loss: 0.060892005761464 Acc: 0.583000024159749\n",
      "Epoch: 21700/30000-------------------------------------------\n",
      "Train -> Loss: 0.028418786823750 Acc: 0.817666649818420\n",
      "Valid -> Loss: 0.060911804437637 Acc: 0.582500020662943\n",
      "Epoch: 21710/30000-------------------------------------------\n",
      "Train -> Loss: 0.028412204235792 Acc: 0.817499995231628\n",
      "Valid -> Loss: 0.060930212338765 Acc: 0.582500030597051\n",
      "Epoch: 21720/30000-------------------------------------------\n",
      "Train -> Loss: 0.028405738994479 Acc: 0.817666649818420\n",
      "Valid -> Loss: 0.060946316147844 Acc: 0.582166701555252\n",
      "Epoch: 21730/30000-------------------------------------------\n",
      "Train -> Loss: 0.028399327769876 Acc: 0.817833304405212\n",
      "Valid -> Loss: 0.060962402572234 Acc: 0.582166701555252\n",
      "Epoch: 21740/30000-------------------------------------------\n",
      "Train -> Loss: 0.028392920270562 Acc: 0.817833304405212\n",
      "Valid -> Loss: 0.060979236538212 Acc: 0.581833362579346\n",
      "Epoch: 21750/30000-------------------------------------------\n",
      "Train -> Loss: 0.028386486694217 Acc: 0.817666649818420\n",
      "Valid -> Loss: 0.060995696733395 Acc: 0.581500033537547\n",
      "Epoch: 21760/30000-------------------------------------------\n",
      "Train -> Loss: 0.028380069881678 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061010231574376 Acc: 0.580833375453949\n",
      "Epoch: 21770/30000-------------------------------------------\n",
      "Train -> Loss: 0.028373807668686 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061025052641829 Acc: 0.580166697502136\n",
      "Epoch: 21780/30000-------------------------------------------\n",
      "Train -> Loss: 0.028367888182402 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061039421707392 Acc: 0.580000032981237\n",
      "Epoch: 21790/30000-------------------------------------------\n",
      "Train -> Loss: 0.028362294659019 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061052681257327 Acc: 0.579833358526230\n",
      "Epoch: 21800/30000-------------------------------------------\n",
      "Train -> Loss: 0.028356928378344 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061066416402658 Acc: 0.580000032981237\n",
      "Epoch: 21810/30000-------------------------------------------\n",
      "Train -> Loss: 0.028351703658700 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061079115296404 Acc: 0.580000032981237\n",
      "Epoch: 21820/30000-------------------------------------------\n",
      "Train -> Loss: 0.028346581384540 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061090997109811 Acc: 0.580000032981237\n",
      "Epoch: 21830/30000-------------------------------------------\n",
      "Train -> Loss: 0.028341522440314 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061102014034986 Acc: 0.580000032981237\n",
      "Epoch: 21840/30000-------------------------------------------\n",
      "Train -> Loss: 0.028336511924863 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061112195253372 Acc: 0.579666694005330\n",
      "Epoch: 21850/30000-------------------------------------------\n",
      "Train -> Loss: 0.028331514447927 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061124052852392 Acc: 0.579833368460337\n",
      "Epoch: 21860/30000-------------------------------------------\n",
      "Train -> Loss: 0.028326541185379 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.061131161327163 Acc: 0.580166687568029\n",
      "Epoch: 21870/30000-------------------------------------------\n",
      "Train -> Loss: 0.028321821242571 Acc: 0.818333327770233\n",
      "Valid -> Loss: 0.061093102519711 Acc: 0.580166687568029\n",
      "Epoch: 21880/30000-------------------------------------------\n",
      "Train -> Loss: 0.028367459774017 Acc: 0.818333327770233\n",
      "Valid -> Loss: 0.060323196152846 Acc: 0.587000032265981\n",
      "Epoch: 21890/30000-------------------------------------------\n",
      "Train -> Loss: 0.042001347988844 Acc: 0.733666658401489\n",
      "Valid -> Loss: 0.050772244731585 Acc: 0.670166691144307\n",
      "Epoch: 21900/30000-------------------------------------------\n",
      "Train -> Loss: 0.075486391782761 Acc: 0.657499969005585\n",
      "Valid -> Loss: 0.068729311227798 Acc: 0.609000027179718\n",
      "Epoch: 21910/30000-------------------------------------------\n",
      "Train -> Loss: 0.052969526499510 Acc: 0.674333333969116\n",
      "Valid -> Loss: 0.063834574694435 Acc: 0.575333366791407\n",
      "Epoch: 21920/30000-------------------------------------------\n",
      "Train -> Loss: 0.034698840230703 Acc: 0.790499985218048\n",
      "Valid -> Loss: 0.060598088428378 Acc: 0.598833342393239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21930/30000-------------------------------------------\n",
      "Train -> Loss: 0.032487206161022 Acc: 0.790833353996277\n",
      "Valid -> Loss: 0.064153976738453 Acc: 0.575833360354106\n",
      "Epoch: 21940/30000-------------------------------------------\n",
      "Train -> Loss: 0.030033789575100 Acc: 0.812999963760376\n",
      "Valid -> Loss: 0.060031333938241 Acc: 0.595000028610229\n",
      "Epoch: 21950/30000-------------------------------------------\n",
      "Train -> Loss: 0.029039464890957 Acc: 0.821500003337860\n",
      "Valid -> Loss: 0.060890541722377 Acc: 0.582833369572957\n",
      "Epoch: 21960/30000-------------------------------------------\n",
      "Train -> Loss: 0.028684439137578 Acc: 0.814499974250793\n",
      "Valid -> Loss: 0.059746683885654 Acc: 0.592666695515315\n",
      "Epoch: 21970/30000-------------------------------------------\n",
      "Train -> Loss: 0.028480172157288 Acc: 0.813499987125397\n",
      "Valid -> Loss: 0.059609344229102 Acc: 0.594333360592524\n",
      "Epoch: 21980/30000-------------------------------------------\n",
      "Train -> Loss: 0.028422728180885 Acc: 0.819833338260651\n",
      "Valid -> Loss: 0.059674618765712 Acc: 0.594500025113424\n",
      "Epoch: 21990/30000-------------------------------------------\n",
      "Train -> Loss: 0.028401222079992 Acc: 0.815500020980835\n",
      "Valid -> Loss: 0.059891377886136 Acc: 0.592333376407623\n",
      "Epoch: 22000/30000-------------------------------------------\n",
      "Train -> Loss: 0.028379395604134 Acc: 0.817333340644836\n",
      "Valid -> Loss: 0.060111769164602 Acc: 0.590833355983098\n",
      "Epoch: 22010/30000-------------------------------------------\n",
      "Train -> Loss: 0.028358617797494 Acc: 0.817833304405212\n",
      "Valid -> Loss: 0.060212460656961 Acc: 0.589666704336802\n",
      "Epoch: 22020/30000-------------------------------------------\n",
      "Train -> Loss: 0.028341380879283 Acc: 0.817666649818420\n",
      "Valid -> Loss: 0.060282591109475 Acc: 0.588666687409083\n",
      "Epoch: 22030/30000-------------------------------------------\n",
      "Train -> Loss: 0.028328862041235 Acc: 0.818499982357025\n",
      "Valid -> Loss: 0.060366567224264 Acc: 0.588000019391378\n",
      "Epoch: 22040/30000-------------------------------------------\n",
      "Train -> Loss: 0.028319481760263 Acc: 0.818666636943817\n",
      "Valid -> Loss: 0.060437164579829 Acc: 0.587000022331874\n",
      "Epoch: 22050/30000-------------------------------------------\n",
      "Train -> Loss: 0.028311979025602 Acc: 0.818166673183441\n",
      "Valid -> Loss: 0.060464822376768 Acc: 0.586166699727376\n",
      "Epoch: 22060/30000-------------------------------------------\n",
      "Train -> Loss: 0.028305564075708 Acc: 0.818166673183441\n",
      "Valid -> Loss: 0.060493222127358 Acc: 0.586333374182383\n",
      "Epoch: 22070/30000-------------------------------------------\n",
      "Train -> Loss: 0.028299763798714 Acc: 0.818499982357025\n",
      "Valid -> Loss: 0.060516909385721 Acc: 0.585833370685577\n",
      "Epoch: 22080/30000-------------------------------------------\n",
      "Train -> Loss: 0.028294328600168 Acc: 0.818499982357025\n",
      "Valid -> Loss: 0.060535969212651 Acc: 0.585500041643778\n",
      "Epoch: 22090/30000-------------------------------------------\n",
      "Train -> Loss: 0.028289139270782 Acc: 0.818499982357025\n",
      "Valid -> Loss: 0.060557027657827 Acc: 0.585333367188772\n",
      "Epoch: 22100/30000-------------------------------------------\n",
      "Train -> Loss: 0.028284115716815 Acc: 0.818499982357025\n",
      "Valid -> Loss: 0.060578073685368 Acc: 0.585000028212865\n",
      "Epoch: 22110/30000-------------------------------------------\n",
      "Train -> Loss: 0.028279207646847 Acc: 0.818666636943817\n",
      "Valid -> Loss: 0.060600254684687 Acc: 0.584833363691966\n",
      "Epoch: 22120/30000-------------------------------------------\n",
      "Train -> Loss: 0.028274372220039 Acc: 0.818666636943817\n",
      "Valid -> Loss: 0.060619553551078 Acc: 0.584666689236959\n",
      "Epoch: 22130/30000-------------------------------------------\n",
      "Train -> Loss: 0.028269579634070 Acc: 0.818666636943817\n",
      "Valid -> Loss: 0.060640103494128 Acc: 0.584500024716059\n",
      "Epoch: 22140/30000-------------------------------------------\n",
      "Train -> Loss: 0.028264811262488 Acc: 0.818833351135254\n",
      "Valid -> Loss: 0.060661097367605 Acc: 0.584333360195160\n",
      "Epoch: 22150/30000-------------------------------------------\n",
      "Train -> Loss: 0.028260041028261 Acc: 0.818666636943817\n",
      "Valid -> Loss: 0.060680095727245 Acc: 0.584333350261052\n",
      "Epoch: 22160/30000-------------------------------------------\n",
      "Train -> Loss: 0.028255248442292 Acc: 0.818666636943817\n",
      "Valid -> Loss: 0.060697909444571 Acc: 0.584166695674260\n",
      "Epoch: 22170/30000-------------------------------------------\n",
      "Train -> Loss: 0.028250437229872 Acc: 0.818666636943817\n",
      "Valid -> Loss: 0.060717292750875 Acc: 0.583833366632462\n",
      "Epoch: 22180/30000-------------------------------------------\n",
      "Train -> Loss: 0.028245601803064 Acc: 0.818666636943817\n",
      "Valid -> Loss: 0.060729281355937 Acc: 0.583833376566569\n",
      "Epoch: 22190/30000-------------------------------------------\n",
      "Train -> Loss: 0.028241463005543 Acc: 0.819499969482422\n",
      "Valid -> Loss: 0.060661690309644 Acc: 0.584000031153361\n",
      "Epoch: 22200/30000-------------------------------------------\n",
      "Train -> Loss: 0.028404468670487 Acc: 0.817166686058044\n",
      "Valid -> Loss: 0.059239831442634 Acc: 0.597000042597453\n",
      "Epoch: 22210/30000-------------------------------------------\n",
      "Train -> Loss: 0.030866345390677 Acc: 0.799166679382324\n",
      "Valid -> Loss: 0.057454261928797 Acc: 0.613166689872742\n",
      "Epoch: 22220/30000-------------------------------------------\n",
      "Train -> Loss: 0.028684664517641 Acc: 0.819000005722046\n",
      "Valid -> Loss: 0.057571182027459 Acc: 0.612333357334137\n",
      "Epoch: 22230/30000-------------------------------------------\n",
      "Train -> Loss: 0.028330368921161 Acc: 0.815333306789398\n",
      "Valid -> Loss: 0.060087226952116 Acc: 0.587166696786880\n",
      "Epoch: 22240/30000-------------------------------------------\n",
      "Train -> Loss: 0.028246033936739 Acc: 0.821333348751068\n",
      "Valid -> Loss: 0.059937290226420 Acc: 0.594166696071625\n",
      "Epoch: 22250/30000-------------------------------------------\n",
      "Train -> Loss: 0.028803167864680 Acc: 0.817333340644836\n",
      "Valid -> Loss: 0.063169846311212 Acc: 0.559500028689702\n",
      "Epoch: 22260/30000-------------------------------------------\n",
      "Train -> Loss: 0.028898373246193 Acc: 0.814499974250793\n",
      "Valid -> Loss: 0.060411442071199 Acc: 0.588000019391378\n",
      "Epoch: 22270/30000-------------------------------------------\n",
      "Train -> Loss: 0.028329236432910 Acc: 0.822499990463257\n",
      "Valid -> Loss: 0.059697819873691 Acc: 0.591666688521703\n",
      "Epoch: 22280/30000-------------------------------------------\n",
      "Train -> Loss: 0.028376368805766 Acc: 0.814333319664001\n",
      "Valid -> Loss: 0.059899989515543 Acc: 0.592333376407623\n",
      "Epoch: 22290/30000-------------------------------------------\n",
      "Train -> Loss: 0.028259629383683 Acc: 0.821333348751068\n",
      "Valid -> Loss: 0.060358971978227 Acc: 0.586833367745082\n",
      "Epoch: 22300/30000-------------------------------------------\n",
      "Train -> Loss: 0.028220089152455 Acc: 0.819166660308838\n",
      "Valid -> Loss: 0.060840911542376 Acc: 0.584666699171066\n",
      "Epoch: 22310/30000-------------------------------------------\n",
      "Train -> Loss: 0.028211535885930 Acc: 0.819833338260651\n",
      "Valid -> Loss: 0.060624793171883 Acc: 0.585000028212865\n",
      "Epoch: 22320/30000-------------------------------------------\n",
      "Train -> Loss: 0.028198339045048 Acc: 0.819666683673859\n",
      "Valid -> Loss: 0.060819337144494 Acc: 0.584000031153361\n",
      "Epoch: 22330/30000-------------------------------------------\n",
      "Train -> Loss: 0.028192056342959 Acc: 0.819666683673859\n",
      "Valid -> Loss: 0.060916868348916 Acc: 0.583833366632462\n",
      "Epoch: 22340/30000-------------------------------------------\n",
      "Train -> Loss: 0.028187111020088 Acc: 0.819666683673859\n",
      "Valid -> Loss: 0.060945268099507 Acc: 0.584000031153361\n",
      "Epoch: 22350/30000-------------------------------------------\n",
      "Train -> Loss: 0.028217293322086 Acc: 0.820666670799255\n",
      "Valid -> Loss: 0.061587837214271 Acc: 0.578833371400833\n",
      "Epoch: 22360/30000-------------------------------------------\n",
      "Train -> Loss: 0.033746954053640 Acc: 0.781333327293396\n",
      "Valid -> Loss: 0.068093837549289 Acc: 0.522000019749006\n",
      "Epoch: 22370/30000-------------------------------------------\n",
      "Train -> Loss: 0.028343750163913 Acc: 0.821333348751068\n",
      "Valid -> Loss: 0.063616327941418 Acc: 0.554166694482168\n",
      "Epoch: 22380/30000-------------------------------------------\n",
      "Train -> Loss: 0.028495134785771 Acc: 0.818166673183441\n",
      "Valid -> Loss: 0.061854079986612 Acc: 0.571000019709269\n",
      "Epoch: 22390/30000-------------------------------------------\n",
      "Train -> Loss: 0.028591319918633 Acc: 0.817333340644836\n",
      "Valid -> Loss: 0.063137544319034 Acc: 0.559500018755595\n",
      "Epoch: 22400/30000-------------------------------------------\n",
      "Train -> Loss: 0.028383309021592 Acc: 0.819000005722046\n",
      "Valid -> Loss: 0.061404860888918 Acc: 0.577000021934509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22410/30000-------------------------------------------\n",
      "Train -> Loss: 0.029744949191809 Acc: 0.809166669845581\n",
      "Valid -> Loss: 0.066008307039738 Acc: 0.533833359678586\n",
      "Epoch: 22420/30000-------------------------------------------\n",
      "Train -> Loss: 0.028448905795813 Acc: 0.820333302021027\n",
      "Valid -> Loss: 0.060865012928843 Acc: 0.581333359082540\n",
      "Epoch: 22430/30000-------------------------------------------\n",
      "Train -> Loss: 0.028361849486828 Acc: 0.821333348751068\n",
      "Valid -> Loss: 0.060553851847847 Acc: 0.586000025272369\n",
      "Epoch: 22440/30000-------------------------------------------\n",
      "Train -> Loss: 0.028199579566717 Acc: 0.819499969482422\n",
      "Valid -> Loss: 0.061133178571860 Acc: 0.583000024159749\n",
      "Epoch: 22450/30000-------------------------------------------\n",
      "Train -> Loss: 0.028166422620416 Acc: 0.820500016212463\n",
      "Valid -> Loss: 0.060774857178330 Acc: 0.586500028769175\n",
      "Epoch: 22460/30000-------------------------------------------\n",
      "Train -> Loss: 0.028157226741314 Acc: 0.819833338260651\n",
      "Valid -> Loss: 0.060940035929283 Acc: 0.583833366632462\n",
      "Epoch: 22470/30000-------------------------------------------\n",
      "Train -> Loss: 0.028150975704193 Acc: 0.819833338260651\n",
      "Valid -> Loss: 0.060936079670986 Acc: 0.584333360195160\n",
      "Epoch: 22480/30000-------------------------------------------\n",
      "Train -> Loss: 0.028143908828497 Acc: 0.820666670799255\n",
      "Valid -> Loss: 0.061004595831037 Acc: 0.583833366632462\n",
      "Epoch: 22490/30000-------------------------------------------\n",
      "Train -> Loss: 0.028137957677245 Acc: 0.820166647434235\n",
      "Valid -> Loss: 0.060947389031450 Acc: 0.583833366632462\n",
      "Epoch: 22500/30000-------------------------------------------\n",
      "Train -> Loss: 0.028132829815149 Acc: 0.820500016212463\n",
      "Valid -> Loss: 0.061035800104340 Acc: 0.582833379507065\n",
      "Epoch: 22510/30000-------------------------------------------\n",
      "Train -> Loss: 0.028153514489532 Acc: 0.821999967098236\n",
      "Valid -> Loss: 0.061567424486081 Acc: 0.578333348035812\n",
      "Epoch: 22520/30000-------------------------------------------\n",
      "Train -> Loss: 0.034885935485363 Acc: 0.776333332061768\n",
      "Valid -> Loss: 0.070035897195339 Acc: 0.507333353161812\n",
      "Epoch: 22530/30000-------------------------------------------\n",
      "Train -> Loss: 0.073182456195354 Acc: 0.522166669368744\n",
      "Valid -> Loss: 0.071290990958611 Acc: 0.487500016887983\n",
      "Epoch: 22540/30000-------------------------------------------\n",
      "Train -> Loss: 0.053554039448500 Acc: 0.674166679382324\n",
      "Valid -> Loss: 0.078375473618507 Acc: 0.428166692455610\n",
      "Epoch: 22550/30000-------------------------------------------\n",
      "Train -> Loss: 0.043616209179163 Acc: 0.767000019550323\n",
      "Valid -> Loss: 0.058044524242481 Acc: 0.622500032186508\n",
      "Epoch: 22560/30000-------------------------------------------\n",
      "Train -> Loss: 0.034921601414680 Acc: 0.780499994754791\n",
      "Valid -> Loss: 0.054639194160700 Acc: 0.639333357413610\n",
      "Epoch: 22570/30000-------------------------------------------\n",
      "Train -> Loss: 0.033738769590855 Acc: 0.785166680812836\n",
      "Valid -> Loss: 0.057188535109162 Acc: 0.615666687488556\n",
      "Epoch: 22580/30000-------------------------------------------\n",
      "Train -> Loss: 0.029434502124786 Acc: 0.823333323001862\n",
      "Valid -> Loss: 0.059346366673708 Acc: 0.596166690190633\n",
      "Epoch: 22590/30000-------------------------------------------\n",
      "Train -> Loss: 0.028663847595453 Acc: 0.816999971866608\n",
      "Valid -> Loss: 0.060281511396170 Acc: 0.589166700839996\n",
      "Epoch: 22600/30000-------------------------------------------\n",
      "Train -> Loss: 0.028504000976682 Acc: 0.815833330154419\n",
      "Valid -> Loss: 0.059405926615000 Acc: 0.598500023285548\n",
      "Epoch: 22610/30000-------------------------------------------\n",
      "Train -> Loss: 0.028368653729558 Acc: 0.819666683673859\n",
      "Valid -> Loss: 0.059148740023375 Acc: 0.601166685422262\n",
      "Epoch: 22620/30000-------------------------------------------\n",
      "Train -> Loss: 0.028285626322031 Acc: 0.819499969482422\n",
      "Valid -> Loss: 0.059185874337951 Acc: 0.600666701793671\n",
      "Epoch: 22630/30000-------------------------------------------\n",
      "Train -> Loss: 0.028251903131604 Acc: 0.818166673183441\n",
      "Valid -> Loss: 0.059466831386089 Acc: 0.598166694243749\n",
      "Epoch: 22640/30000-------------------------------------------\n",
      "Train -> Loss: 0.028233891353011 Acc: 0.820500016212463\n",
      "Valid -> Loss: 0.059408678983649 Acc: 0.599500020345052\n",
      "Epoch: 22650/30000-------------------------------------------\n",
      "Train -> Loss: 0.028218446299434 Acc: 0.820166647434235\n",
      "Valid -> Loss: 0.059611080835263 Acc: 0.596500029166540\n",
      "Epoch: 22660/30000-------------------------------------------\n",
      "Train -> Loss: 0.028205908834934 Acc: 0.820500016212463\n",
      "Valid -> Loss: 0.059680730725328 Acc: 0.596166690190633\n",
      "Epoch: 22670/30000-------------------------------------------\n",
      "Train -> Loss: 0.028194572776556 Acc: 0.820666670799255\n",
      "Valid -> Loss: 0.059668115029732 Acc: 0.597000022729238\n",
      "Epoch: 22680/30000-------------------------------------------\n",
      "Train -> Loss: 0.028183611109853 Acc: 0.820999979972839\n",
      "Valid -> Loss: 0.059712985530496 Acc: 0.596333354711533\n",
      "Epoch: 22690/30000-------------------------------------------\n",
      "Train -> Loss: 0.028172403573990 Acc: 0.820666670799255\n",
      "Valid -> Loss: 0.059776789819201 Acc: 0.595333357652028\n",
      "Epoch: 22700/30000-------------------------------------------\n",
      "Train -> Loss: 0.028160186484456 Acc: 0.820666670799255\n",
      "Valid -> Loss: 0.059828028703729 Acc: 0.594500035047531\n",
      "Epoch: 22710/30000-------------------------------------------\n",
      "Train -> Loss: 0.028146144002676 Acc: 0.821500003337860\n",
      "Valid -> Loss: 0.059884892776608 Acc: 0.593833357095718\n",
      "Epoch: 22720/30000-------------------------------------------\n",
      "Train -> Loss: 0.028130620718002 Acc: 0.821500003337860\n",
      "Valid -> Loss: 0.059949166451891 Acc: 0.593500028053919\n",
      "Epoch: 22730/30000-------------------------------------------\n",
      "Train -> Loss: 0.028116535395384 Acc: 0.821833312511444\n",
      "Valid -> Loss: 0.060009075949589 Acc: 0.592666705449422\n",
      "Epoch: 22740/30000-------------------------------------------\n",
      "Train -> Loss: 0.028105814009905 Acc: 0.822166681289673\n",
      "Valid -> Loss: 0.060063036158681 Acc: 0.592333356539408\n",
      "Epoch: 22750/30000-------------------------------------------\n",
      "Train -> Loss: 0.028097569942474 Acc: 0.822166681289673\n",
      "Valid -> Loss: 0.060103502745430 Acc: 0.591500033934911\n",
      "Epoch: 22760/30000-------------------------------------------\n",
      "Train -> Loss: 0.028090670704842 Acc: 0.821666657924652\n",
      "Valid -> Loss: 0.060134813810388 Acc: 0.590833355983098\n",
      "Epoch: 22770/30000-------------------------------------------\n",
      "Train -> Loss: 0.028084531426430 Acc: 0.821500003337860\n",
      "Valid -> Loss: 0.060159266615907 Acc: 0.590333362420400\n",
      "Epoch: 22780/30000-------------------------------------------\n",
      "Train -> Loss: 0.028078893199563 Acc: 0.821666657924652\n",
      "Valid -> Loss: 0.060178699592749 Acc: 0.590166697899500\n",
      "Epoch: 22790/30000-------------------------------------------\n",
      "Train -> Loss: 0.028073621913791 Acc: 0.821833312511444\n",
      "Valid -> Loss: 0.060199249535799 Acc: 0.590333362420400\n",
      "Epoch: 22800/30000-------------------------------------------\n",
      "Train -> Loss: 0.028068641200662 Acc: 0.821999967098236\n",
      "Valid -> Loss: 0.060218141724666 Acc: 0.590333362420400\n",
      "Epoch: 22810/30000-------------------------------------------\n",
      "Train -> Loss: 0.028063889592886 Acc: 0.821999967098236\n",
      "Valid -> Loss: 0.060238091895978 Acc: 0.590500036875407\n",
      "Epoch: 22820/30000-------------------------------------------\n",
      "Train -> Loss: 0.028059322386980 Acc: 0.822333335876465\n",
      "Valid -> Loss: 0.060254992296298 Acc: 0.590500036875407\n",
      "Epoch: 22830/30000-------------------------------------------\n",
      "Train -> Loss: 0.028054906055331 Acc: 0.821999967098236\n",
      "Valid -> Loss: 0.060273361702760 Acc: 0.590000033378601\n",
      "Epoch: 22840/30000-------------------------------------------\n",
      "Train -> Loss: 0.028050610795617 Acc: 0.821999967098236\n",
      "Valid -> Loss: 0.060291197771827 Acc: 0.589833368857702\n",
      "Epoch: 22850/30000-------------------------------------------\n",
      "Train -> Loss: 0.028046416118741 Acc: 0.821999967098236\n",
      "Valid -> Loss: 0.060306543484330 Acc: 0.589666704336802\n",
      "Epoch: 22860/30000-------------------------------------------\n",
      "Train -> Loss: 0.028042303398252 Acc: 0.822166681289673\n",
      "Valid -> Loss: 0.060320548092326 Acc: 0.589500039815903\n",
      "Epoch: 22870/30000-------------------------------------------\n",
      "Train -> Loss: 0.028038283810019 Acc: 0.822166681289673\n",
      "Valid -> Loss: 0.060324455300967 Acc: 0.589166700839996\n",
      "Epoch: 22880/30000-------------------------------------------\n",
      "Train -> Loss: 0.028035806491971 Acc: 0.822499990463257\n",
      "Valid -> Loss: 0.060216611872117 Acc: 0.589166690905889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22890/30000-------------------------------------------\n",
      "Train -> Loss: 0.028302112594247 Acc: 0.818666636943817\n",
      "Valid -> Loss: 0.058483587577939 Acc: 0.606833368539810\n",
      "Epoch: 22900/30000-------------------------------------------\n",
      "Train -> Loss: 0.029381560161710 Acc: 0.807999968528748\n",
      "Valid -> Loss: 0.058145307625333 Acc: 0.606500029563904\n",
      "Epoch: 22910/30000-------------------------------------------\n",
      "Train -> Loss: 0.028064403682947 Acc: 0.825500011444092\n",
      "Valid -> Loss: 0.058770516887307 Acc: 0.605833361546198\n",
      "Epoch: 22920/30000-------------------------------------------\n",
      "Train -> Loss: 0.028641907498240 Acc: 0.816999971866608\n",
      "Valid -> Loss: 0.062934567530950 Acc: 0.562500019868215\n",
      "Epoch: 22930/30000-------------------------------------------\n",
      "Train -> Loss: 0.028077794238925 Acc: 0.824999988079071\n",
      "Valid -> Loss: 0.059587055817246 Acc: 0.598333368698756\n",
      "Epoch: 22940/30000-------------------------------------------\n",
      "Train -> Loss: 0.028126105666161 Acc: 0.819666683673859\n",
      "Valid -> Loss: 0.059441816061735 Acc: 0.596500019232432\n",
      "Epoch: 22950/30000-------------------------------------------\n",
      "Train -> Loss: 0.028067054226995 Acc: 0.820500016212463\n",
      "Valid -> Loss: 0.059991942097743 Acc: 0.591166694959005\n",
      "Epoch: 22960/30000-------------------------------------------\n",
      "Train -> Loss: 0.028030587360263 Acc: 0.823499977588654\n",
      "Valid -> Loss: 0.060297979662816 Acc: 0.588333358367284\n",
      "Epoch: 22970/30000-------------------------------------------\n",
      "Train -> Loss: 0.028018899261951 Acc: 0.820999979972839\n",
      "Valid -> Loss: 0.060222527633111 Acc: 0.589666684468587\n",
      "Epoch: 22980/30000-------------------------------------------\n",
      "Train -> Loss: 0.028010249137878 Acc: 0.822333335876465\n",
      "Valid -> Loss: 0.060278454174598 Acc: 0.588666697343191\n",
      "Epoch: 22990/30000-------------------------------------------\n",
      "Train -> Loss: 0.028004854917526 Acc: 0.822499990463257\n",
      "Valid -> Loss: 0.060269447043538 Acc: 0.588833361864090\n",
      "Epoch: 23000/30000-------------------------------------------\n",
      "Train -> Loss: 0.028041558340192 Acc: 0.821166634559631\n",
      "Valid -> Loss: 0.059743746494253 Acc: 0.592000027497609\n",
      "Epoch: 23010/30000-------------------------------------------\n",
      "Train -> Loss: 0.030312541872263 Acc: 0.802333295345306\n",
      "Valid -> Loss: 0.055900746956468 Acc: 0.629000037908554\n",
      "Epoch: 23020/30000-------------------------------------------\n",
      "Train -> Loss: 0.028887074440718 Acc: 0.815500020980835\n",
      "Valid -> Loss: 0.059694910421968 Acc: 0.596666703621546\n",
      "Epoch: 23030/30000-------------------------------------------\n",
      "Train -> Loss: 0.028815202414989 Acc: 0.815333306789398\n",
      "Valid -> Loss: 0.062002005055547 Acc: 0.567333350578944\n",
      "Epoch: 23040/30000-------------------------------------------\n",
      "Train -> Loss: 0.028610955923796 Acc: 0.814833343029022\n",
      "Valid -> Loss: 0.058301745603482 Acc: 0.606166690587997\n",
      "Epoch: 23050/30000-------------------------------------------\n",
      "Train -> Loss: 0.028280440717936 Acc: 0.819333314895630\n",
      "Valid -> Loss: 0.058820853630702 Acc: 0.601666698853175\n",
      "Epoch: 23060/30000-------------------------------------------\n",
      "Train -> Loss: 0.028024177998304 Acc: 0.822666645050049\n",
      "Valid -> Loss: 0.060323212295771 Acc: 0.587166696786880\n",
      "Epoch: 23070/30000-------------------------------------------\n",
      "Train -> Loss: 0.028008820489049 Acc: 0.823499977588654\n",
      "Valid -> Loss: 0.060402257988850 Acc: 0.588500032822291\n",
      "Epoch: 23080/30000-------------------------------------------\n",
      "Train -> Loss: 0.027985883876681 Acc: 0.823833346366882\n",
      "Valid -> Loss: 0.060642315074801 Acc: 0.585666696230570\n",
      "Epoch: 23090/30000-------------------------------------------\n",
      "Train -> Loss: 0.027978653088212 Acc: 0.823833346366882\n",
      "Valid -> Loss: 0.060411909595132 Acc: 0.587666700283686\n",
      "Epoch: 23100/30000-------------------------------------------\n",
      "Train -> Loss: 0.027973311021924 Acc: 0.823666632175446\n",
      "Valid -> Loss: 0.060449292262395 Acc: 0.586666703224182\n",
      "Epoch: 23110/30000-------------------------------------------\n",
      "Train -> Loss: 0.027968302369118 Acc: 0.823666632175446\n",
      "Valid -> Loss: 0.060430468370517 Acc: 0.587666690349579\n",
      "Epoch: 23120/30000-------------------------------------------\n",
      "Train -> Loss: 0.027964925393462 Acc: 0.823166668415070\n",
      "Valid -> Loss: 0.060395145788789 Acc: 0.587666700283686\n",
      "Epoch: 23130/30000-------------------------------------------\n",
      "Train -> Loss: 0.028115373104811 Acc: 0.822333335876465\n",
      "Valid -> Loss: 0.059055906410019 Acc: 0.599833369255066\n",
      "Epoch: 23140/30000-------------------------------------------\n",
      "Train -> Loss: 0.030853442847729 Acc: 0.798500001430511\n",
      "Valid -> Loss: 0.057488725831111 Acc: 0.609666685263316\n",
      "Epoch: 23150/30000-------------------------------------------\n",
      "Train -> Loss: 0.029937077313662 Acc: 0.808833301067352\n",
      "Valid -> Loss: 0.056108567242821 Acc: 0.623666703701019\n",
      "Epoch: 23160/30000-------------------------------------------\n",
      "Train -> Loss: 0.032639462500811 Acc: 0.786166667938232\n",
      "Valid -> Loss: 0.055235718066494 Acc: 0.631333361069361\n",
      "Epoch: 23170/30000-------------------------------------------\n",
      "Train -> Loss: 0.032379362732172 Acc: 0.789499998092651\n",
      "Valid -> Loss: 0.060296621794502 Acc: 0.589000026384989\n",
      "Epoch: 23180/30000-------------------------------------------\n",
      "Train -> Loss: 0.029898500069976 Acc: 0.811166644096375\n",
      "Valid -> Loss: 0.060331071416537 Acc: 0.586333364248276\n",
      "Epoch: 23190/30000-------------------------------------------\n",
      "Train -> Loss: 0.028369532898068 Acc: 0.812500000000000\n",
      "Valid -> Loss: 0.058589055513342 Acc: 0.608500023682912\n",
      "Epoch: 23200/30000-------------------------------------------\n",
      "Train -> Loss: 0.030782040208578 Acc: 0.797999978065491\n",
      "Valid -> Loss: 0.063150315855940 Acc: 0.564666698376338\n",
      "Epoch: 23210/30000-------------------------------------------\n",
      "Train -> Loss: 0.029473423957825 Acc: 0.814499974250793\n",
      "Valid -> Loss: 0.056803226470947 Acc: 0.617666701475779\n",
      "Epoch: 23220/30000-------------------------------------------\n",
      "Train -> Loss: 0.028322866186500 Acc: 0.820999979972839\n",
      "Valid -> Loss: 0.060475673526525 Acc: 0.587333351373672\n",
      "Epoch: 23230/30000-------------------------------------------\n",
      "Train -> Loss: 0.028160551562905 Acc: 0.819666683673859\n",
      "Valid -> Loss: 0.059447929263115 Acc: 0.596500039100647\n",
      "Epoch: 23240/30000-------------------------------------------\n",
      "Train -> Loss: 0.028035499155521 Acc: 0.823833346366882\n",
      "Valid -> Loss: 0.060765287528435 Acc: 0.584666689236959\n",
      "Epoch: 23250/30000-------------------------------------------\n",
      "Train -> Loss: 0.027985969558358 Acc: 0.822166681289673\n",
      "Valid -> Loss: 0.060189520940185 Acc: 0.588833361864090\n",
      "Epoch: 23260/30000-------------------------------------------\n",
      "Train -> Loss: 0.027974808588624 Acc: 0.821833312511444\n",
      "Valid -> Loss: 0.060223388175170 Acc: 0.589333355426788\n",
      "Epoch: 23270/30000-------------------------------------------\n",
      "Train -> Loss: 0.027957053855062 Acc: 0.823833346366882\n",
      "Valid -> Loss: 0.060410507023335 Acc: 0.588666687409083\n",
      "Epoch: 23280/30000-------------------------------------------\n",
      "Train -> Loss: 0.027949539944530 Acc: 0.823666632175446\n",
      "Valid -> Loss: 0.060499418526888 Acc: 0.587000022331874\n",
      "Epoch: 23290/30000-------------------------------------------\n",
      "Train -> Loss: 0.027942365035415 Acc: 0.823499977588654\n",
      "Valid -> Loss: 0.060461892435948 Acc: 0.587333351373672\n",
      "Epoch: 23300/30000-------------------------------------------\n",
      "Train -> Loss: 0.027935953810811 Acc: 0.824000000953674\n",
      "Valid -> Loss: 0.060449390982588 Acc: 0.587500015894572\n",
      "Epoch: 23310/30000-------------------------------------------\n",
      "Train -> Loss: 0.027930483222008 Acc: 0.823833346366882\n",
      "Valid -> Loss: 0.060475877175728 Acc: 0.587000022331874\n",
      "Epoch: 23320/30000-------------------------------------------\n",
      "Train -> Loss: 0.027925545349717 Acc: 0.823833346366882\n",
      "Valid -> Loss: 0.060468445221583 Acc: 0.586833357810974\n",
      "Epoch: 23330/30000-------------------------------------------\n",
      "Train -> Loss: 0.027920959517360 Acc: 0.823833346366882\n",
      "Valid -> Loss: 0.060479088996847 Acc: 0.586666693290075\n",
      "Epoch: 23340/30000-------------------------------------------\n",
      "Train -> Loss: 0.027916591614485 Acc: 0.823833346366882\n",
      "Valid -> Loss: 0.060489545265834 Acc: 0.586500028769175\n",
      "Epoch: 23350/30000-------------------------------------------\n",
      "Train -> Loss: 0.027912398800254 Acc: 0.824000000953674\n",
      "Valid -> Loss: 0.060511152570446 Acc: 0.586166699727376\n",
      "Epoch: 23360/30000-------------------------------------------\n",
      "Train -> Loss: 0.027908330783248 Acc: 0.824000000953674\n",
      "Valid -> Loss: 0.060519890238841 Acc: 0.586333354314168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23370/30000-------------------------------------------\n",
      "Train -> Loss: 0.027904363349080 Acc: 0.824000000953674\n",
      "Valid -> Loss: 0.060535978525877 Acc: 0.586333364248276\n",
      "Epoch: 23380/30000-------------------------------------------\n",
      "Train -> Loss: 0.027900479733944 Acc: 0.824166655540466\n",
      "Valid -> Loss: 0.060546151672800 Acc: 0.585500021775564\n",
      "Epoch: 23390/30000-------------------------------------------\n",
      "Train -> Loss: 0.027896657586098 Acc: 0.824000000953674\n",
      "Valid -> Loss: 0.060559422398607 Acc: 0.585500021775564\n",
      "Epoch: 23400/30000-------------------------------------------\n",
      "Train -> Loss: 0.027892889454961 Acc: 0.824499964714050\n",
      "Valid -> Loss: 0.060570346812407 Acc: 0.585333357254664\n",
      "Epoch: 23410/30000-------------------------------------------\n",
      "Train -> Loss: 0.027889164164662 Acc: 0.824666678905487\n",
      "Valid -> Loss: 0.060582137356202 Acc: 0.585666686296463\n",
      "Epoch: 23420/30000-------------------------------------------\n",
      "Train -> Loss: 0.027885474264622 Acc: 0.825166642665863\n",
      "Valid -> Loss: 0.060597602898876 Acc: 0.585500021775564\n",
      "Epoch: 23430/30000-------------------------------------------\n",
      "Train -> Loss: 0.027882030233741 Acc: 0.825166642665863\n",
      "Valid -> Loss: 0.060654699802399 Acc: 0.585000028212865\n",
      "Epoch: 23440/30000-------------------------------------------\n",
      "Train -> Loss: 0.027932764962316 Acc: 0.825500011444092\n",
      "Valid -> Loss: 0.061426180104415 Acc: 0.580166687568029\n",
      "Epoch: 23450/30000-------------------------------------------\n",
      "Train -> Loss: 0.031711082905531 Acc: 0.795833349227905\n",
      "Valid -> Loss: 0.065964149311185 Acc: 0.537666698296865\n",
      "Epoch: 23460/30000-------------------------------------------\n",
      "Train -> Loss: 0.028121169656515 Acc: 0.824666678905487\n",
      "Valid -> Loss: 0.059976992507776 Acc: 0.592000027497609\n",
      "Epoch: 23470/30000-------------------------------------------\n",
      "Train -> Loss: 0.027954593300819 Acc: 0.820166647434235\n",
      "Valid -> Loss: 0.059160795062780 Acc: 0.598833362261454\n",
      "Epoch: 23480/30000-------------------------------------------\n",
      "Train -> Loss: 0.028005985543132 Acc: 0.823833346366882\n",
      "Valid -> Loss: 0.061199077094595 Acc: 0.582666695117950\n",
      "Epoch: 23490/30000-------------------------------------------\n",
      "Train -> Loss: 0.027919258922338 Acc: 0.822499990463257\n",
      "Valid -> Loss: 0.059968387708068 Acc: 0.590833355983098\n",
      "Epoch: 23500/30000-------------------------------------------\n",
      "Train -> Loss: 0.027903368696570 Acc: 0.825500011444092\n",
      "Valid -> Loss: 0.061182827999194 Acc: 0.583000034093857\n",
      "Epoch: 23510/30000-------------------------------------------\n",
      "Train -> Loss: 0.028017692267895 Acc: 0.822833299636841\n",
      "Valid -> Loss: 0.061551203330358 Acc: 0.579333355029424\n",
      "Epoch: 23520/30000-------------------------------------------\n",
      "Train -> Loss: 0.028187599033117 Acc: 0.823333323001862\n",
      "Valid -> Loss: 0.061786367247502 Acc: 0.570833355188370\n",
      "Epoch: 23530/30000-------------------------------------------\n",
      "Train -> Loss: 0.033395223319530 Acc: 0.781666636466980\n",
      "Valid -> Loss: 0.065947083135446 Acc: 0.547500024239222\n",
      "Epoch: 23540/30000-------------------------------------------\n",
      "Train -> Loss: 0.032022949308157 Acc: 0.810833334922791\n",
      "Valid -> Loss: 0.060202699154615 Acc: 0.588500022888184\n",
      "Epoch: 23550/30000-------------------------------------------\n",
      "Train -> Loss: 0.030295716598630 Acc: 0.807999968528748\n",
      "Valid -> Loss: 0.064528855184714 Acc: 0.546500027179718\n",
      "Epoch: 23560/30000-------------------------------------------\n",
      "Train -> Loss: 0.028209675103426 Acc: 0.820500016212463\n",
      "Valid -> Loss: 0.058403721079230 Acc: 0.604333360989889\n",
      "Epoch: 23570/30000-------------------------------------------\n",
      "Train -> Loss: 0.027924528345466 Acc: 0.822333335876465\n",
      "Valid -> Loss: 0.058674133693178 Acc: 0.604500025510788\n",
      "Epoch: 23580/30000-------------------------------------------\n",
      "Train -> Loss: 0.027987809851766 Acc: 0.822666645050049\n",
      "Valid -> Loss: 0.058603548755248 Acc: 0.604333360989889\n",
      "Epoch: 23590/30000-------------------------------------------\n",
      "Train -> Loss: 0.028058653697371 Acc: 0.821999967098236\n",
      "Valid -> Loss: 0.059280309205254 Acc: 0.597500006357829\n",
      "Epoch: 23600/30000-------------------------------------------\n",
      "Train -> Loss: 0.027875248342752 Acc: 0.825666666030884\n",
      "Valid -> Loss: 0.059847551708420 Acc: 0.592333366473516\n",
      "Epoch: 23610/30000-------------------------------------------\n",
      "Train -> Loss: 0.027871556580067 Acc: 0.825333297252655\n",
      "Valid -> Loss: 0.060759985198577 Acc: 0.586333364248276\n",
      "Epoch: 23620/30000-------------------------------------------\n",
      "Train -> Loss: 0.027844704687595 Acc: 0.825333297252655\n",
      "Valid -> Loss: 0.060357588032881 Acc: 0.588500022888184\n",
      "Epoch: 23630/30000-------------------------------------------\n",
      "Train -> Loss: 0.027836944907904 Acc: 0.825666666030884\n",
      "Valid -> Loss: 0.060542126496633 Acc: 0.586833357810974\n",
      "Epoch: 23640/30000-------------------------------------------\n",
      "Train -> Loss: 0.027833249419928 Acc: 0.825333297252655\n",
      "Valid -> Loss: 0.060350550338626 Acc: 0.588333348433177\n",
      "Epoch: 23650/30000-------------------------------------------\n",
      "Train -> Loss: 0.027827356010675 Acc: 0.825500011444092\n",
      "Valid -> Loss: 0.060398053998748 Acc: 0.588333358367284\n",
      "Epoch: 23660/30000-------------------------------------------\n",
      "Train -> Loss: 0.027828533202410 Acc: 0.824999988079071\n",
      "Valid -> Loss: 0.060275804251432 Acc: 0.589166700839996\n",
      "Epoch: 23670/30000-------------------------------------------\n",
      "Train -> Loss: 0.028085367754102 Acc: 0.822333335876465\n",
      "Valid -> Loss: 0.058832472190261 Acc: 0.603333353996277\n",
      "Epoch: 23680/30000-------------------------------------------\n",
      "Train -> Loss: 0.029907280579209 Acc: 0.814666628837585\n",
      "Valid -> Loss: 0.057506550103426 Acc: 0.609666695197423\n",
      "Epoch: 23690/30000-------------------------------------------\n",
      "Train -> Loss: 0.028948225080967 Acc: 0.811999976634979\n",
      "Valid -> Loss: 0.058628614991903 Acc: 0.601666688919067\n",
      "Epoch: 23700/30000-------------------------------------------\n",
      "Train -> Loss: 0.028387889266014 Acc: 0.823666632175446\n",
      "Valid -> Loss: 0.058889921133717 Acc: 0.597000022729238\n",
      "Epoch: 23710/30000-------------------------------------------\n",
      "Train -> Loss: 0.030426735058427 Acc: 0.802500009536743\n",
      "Valid -> Loss: 0.057527851934234 Acc: 0.608833352724711\n",
      "Epoch: 23720/30000-------------------------------------------\n",
      "Train -> Loss: 0.028058940544724 Acc: 0.826499998569489\n",
      "Valid -> Loss: 0.059660082062085 Acc: 0.595500032107035\n",
      "Epoch: 23730/30000-------------------------------------------\n",
      "Train -> Loss: 0.027858553454280 Acc: 0.823833346366882\n",
      "Valid -> Loss: 0.061021236081918 Acc: 0.581166694561640\n",
      "Epoch: 23740/30000-------------------------------------------\n",
      "Train -> Loss: 0.027834117412567 Acc: 0.825833320617676\n",
      "Valid -> Loss: 0.060398713996013 Acc: 0.590833355983098\n",
      "Epoch: 23750/30000-------------------------------------------\n",
      "Train -> Loss: 0.027819441631436 Acc: 0.825666666030884\n",
      "Valid -> Loss: 0.060897826527556 Acc: 0.584666699171066\n",
      "Epoch: 23760/30000-------------------------------------------\n",
      "Train -> Loss: 0.027803856879473 Acc: 0.825666666030884\n",
      "Valid -> Loss: 0.060541530450185 Acc: 0.588166683912277\n",
      "Epoch: 23770/30000-------------------------------------------\n",
      "Train -> Loss: 0.027800429612398 Acc: 0.825833320617676\n",
      "Valid -> Loss: 0.060791330412030 Acc: 0.585333357254664\n",
      "Epoch: 23780/30000-------------------------------------------\n",
      "Train -> Loss: 0.027795884758234 Acc: 0.826333343982697\n",
      "Valid -> Loss: 0.060715039571126 Acc: 0.585500021775564\n",
      "Epoch: 23790/30000-------------------------------------------\n",
      "Train -> Loss: 0.027821911498904 Acc: 0.825666666030884\n",
      "Valid -> Loss: 0.061213854079445 Acc: 0.582333366076151\n",
      "Epoch: 23800/30000-------------------------------------------\n",
      "Train -> Loss: 0.028837943449616 Acc: 0.816333353519440\n",
      "Valid -> Loss: 0.063595303023855 Acc: 0.558666696151098\n",
      "Epoch: 23810/30000-------------------------------------------\n",
      "Train -> Loss: 0.028233369812369 Acc: 0.817333340644836\n",
      "Valid -> Loss: 0.061089301481843 Acc: 0.578166693449020\n",
      "Epoch: 23820/30000-------------------------------------------\n",
      "Train -> Loss: 0.028284192085266 Acc: 0.823666632175446\n",
      "Valid -> Loss: 0.059794778625170 Acc: 0.590333372354507\n",
      "Epoch: 23830/30000-------------------------------------------\n",
      "Train -> Loss: 0.028136849403381 Acc: 0.822833299636841\n",
      "Valid -> Loss: 0.060260230675340 Acc: 0.591833362976710\n",
      "Epoch: 23840/30000-------------------------------------------\n",
      "Train -> Loss: 0.027910014614463 Acc: 0.827333331108093\n",
      "Valid -> Loss: 0.060424010579785 Acc: 0.587333361307780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23850/30000-------------------------------------------\n",
      "Train -> Loss: 0.027880413457751 Acc: 0.822166681289673\n",
      "Valid -> Loss: 0.060096176962058 Acc: 0.590166697899500\n",
      "Epoch: 23860/30000-------------------------------------------\n",
      "Train -> Loss: 0.027831515297294 Acc: 0.826166629791260\n",
      "Valid -> Loss: 0.060162287826339 Acc: 0.589833358923594\n",
      "Epoch: 23870/30000-------------------------------------------\n",
      "Train -> Loss: 0.027799401432276 Acc: 0.824499964714050\n",
      "Valid -> Loss: 0.060161927094062 Acc: 0.590500017007192\n",
      "Epoch: 23880/30000-------------------------------------------\n",
      "Train -> Loss: 0.027776647359133 Acc: 0.826166629791260\n",
      "Valid -> Loss: 0.060495334366957 Acc: 0.588166693846385\n",
      "Epoch: 23890/30000-------------------------------------------\n",
      "Train -> Loss: 0.027768628671765 Acc: 0.826166629791260\n",
      "Valid -> Loss: 0.060366054996848 Acc: 0.589500029881795\n",
      "Epoch: 23900/30000-------------------------------------------\n",
      "Train -> Loss: 0.027761828154325 Acc: 0.825999975204468\n",
      "Valid -> Loss: 0.060475563630462 Acc: 0.589000026384989\n",
      "Epoch: 23910/30000-------------------------------------------\n",
      "Train -> Loss: 0.027756523340940 Acc: 0.825999975204468\n",
      "Valid -> Loss: 0.060430098325014 Acc: 0.588833361864090\n",
      "Epoch: 23920/30000-------------------------------------------\n",
      "Train -> Loss: 0.027761500328779 Acc: 0.826499998569489\n",
      "Valid -> Loss: 0.060227882737915 Acc: 0.590166687965393\n",
      "Epoch: 23930/30000-------------------------------------------\n",
      "Train -> Loss: 0.028725506737828 Acc: 0.813666641712189\n",
      "Valid -> Loss: 0.057261434694131 Acc: 0.614333361387253\n",
      "Epoch: 23940/30000-------------------------------------------\n",
      "Train -> Loss: 0.029053701087832 Acc: 0.818000018596649\n",
      "Valid -> Loss: 0.062646101539334 Acc: 0.561166693766912\n",
      "Epoch: 23950/30000-------------------------------------------\n",
      "Train -> Loss: 0.028839578852057 Acc: 0.820333302021027\n",
      "Valid -> Loss: 0.061513785893718 Acc: 0.573333352804184\n",
      "Epoch: 23960/30000-------------------------------------------\n",
      "Train -> Loss: 0.028276845812798 Acc: 0.821166634559631\n",
      "Valid -> Loss: 0.059917245060205 Acc: 0.592166701952616\n",
      "Epoch: 23970/30000-------------------------------------------\n",
      "Train -> Loss: 0.027802413329482 Acc: 0.823333323001862\n",
      "Valid -> Loss: 0.060187337920070 Acc: 0.586833367745082\n",
      "Epoch: 23980/30000-------------------------------------------\n",
      "Train -> Loss: 0.027841571718454 Acc: 0.824499964714050\n",
      "Valid -> Loss: 0.059603216747443 Acc: 0.596166690190633\n",
      "Epoch: 23990/30000-------------------------------------------\n",
      "Train -> Loss: 0.027781667187810 Acc: 0.825500011444092\n",
      "Valid -> Loss: 0.059949003780882 Acc: 0.592333366473516\n",
      "Epoch: 24000/30000-------------------------------------------\n",
      "Train -> Loss: 0.027751397341490 Acc: 0.826833307743073\n",
      "Valid -> Loss: 0.060490389044086 Acc: 0.588166703780492\n",
      "Epoch: 24010/30000-------------------------------------------\n",
      "Train -> Loss: 0.027739433571696 Acc: 0.826666653156281\n",
      "Valid -> Loss: 0.060486541440090 Acc: 0.588166693846385\n",
      "Epoch: 24020/30000-------------------------------------------\n",
      "Train -> Loss: 0.027730630710721 Acc: 0.826166629791260\n",
      "Valid -> Loss: 0.060536316285531 Acc: 0.588166693846385\n",
      "Epoch: 24030/30000-------------------------------------------\n",
      "Train -> Loss: 0.027725866064429 Acc: 0.826333343982697\n",
      "Valid -> Loss: 0.060502313698332 Acc: 0.587666680415471\n",
      "Epoch: 24040/30000-------------------------------------------\n",
      "Train -> Loss: 0.027721464633942 Acc: 0.826333343982697\n",
      "Valid -> Loss: 0.060454236343503 Acc: 0.588166693846385\n",
      "Epoch: 24050/30000-------------------------------------------\n",
      "Train -> Loss: 0.027737807482481 Acc: 0.825833320617676\n",
      "Valid -> Loss: 0.060118406390150 Acc: 0.589833358923594\n",
      "Epoch: 24060/30000-------------------------------------------\n",
      "Train -> Loss: 0.028784003108740 Acc: 0.812833309173584\n",
      "Valid -> Loss: 0.057336964954933 Acc: 0.612000018358231\n",
      "Epoch: 24070/30000-------------------------------------------\n",
      "Train -> Loss: 0.030483275651932 Acc: 0.819499969482422\n",
      "Valid -> Loss: 0.059919960175951 Acc: 0.587666690349579\n",
      "Epoch: 24080/30000-------------------------------------------\n",
      "Train -> Loss: 0.027886589989066 Acc: 0.826999962329865\n",
      "Valid -> Loss: 0.061345466102163 Acc: 0.576666692892710\n",
      "Epoch: 24090/30000-------------------------------------------\n",
      "Train -> Loss: 0.027889026328921 Acc: 0.825999975204468\n",
      "Valid -> Loss: 0.061325008049607 Acc: 0.580333362023036\n",
      "Epoch: 24100/30000-------------------------------------------\n",
      "Train -> Loss: 0.028486218303442 Acc: 0.821833312511444\n",
      "Valid -> Loss: 0.063733914246162 Acc: 0.553333361943563\n",
      "Epoch: 24110/30000-------------------------------------------\n",
      "Train -> Loss: 0.028548583388329 Acc: 0.820999979972839\n",
      "Valid -> Loss: 0.061466039468845 Acc: 0.578666687011719\n",
      "Epoch: 24120/30000-------------------------------------------\n",
      "Train -> Loss: 0.027937531471252 Acc: 0.824666678905487\n",
      "Valid -> Loss: 0.061951120694478 Acc: 0.569833358128866\n",
      "Epoch: 24130/30000-------------------------------------------\n",
      "Train -> Loss: 0.027774052694440 Acc: 0.827333331108093\n",
      "Valid -> Loss: 0.060348798210422 Acc: 0.589500039815903\n",
      "Epoch: 24140/30000-------------------------------------------\n",
      "Train -> Loss: 0.027743034064770 Acc: 0.826499998569489\n",
      "Valid -> Loss: 0.060530938208103 Acc: 0.587666690349579\n",
      "Epoch: 24150/30000-------------------------------------------\n",
      "Train -> Loss: 0.027709145098925 Acc: 0.826499998569489\n",
      "Valid -> Loss: 0.060558951149384 Acc: 0.587166686852773\n",
      "Epoch: 24160/30000-------------------------------------------\n",
      "Train -> Loss: 0.027697727084160 Acc: 0.826833307743073\n",
      "Valid -> Loss: 0.060439143950740 Acc: 0.589166690905889\n",
      "Epoch: 24170/30000-------------------------------------------\n",
      "Train -> Loss: 0.027690447866917 Acc: 0.826999962329865\n",
      "Valid -> Loss: 0.060603411868215 Acc: 0.586666683355967\n",
      "Epoch: 24180/30000-------------------------------------------\n",
      "Train -> Loss: 0.027685469016433 Acc: 0.827166676521301\n",
      "Valid -> Loss: 0.060651772965988 Acc: 0.586500018835068\n",
      "Epoch: 24190/30000-------------------------------------------\n",
      "Train -> Loss: 0.027680749073625 Acc: 0.827333331108093\n",
      "Valid -> Loss: 0.060690583040317 Acc: 0.586500028769175\n",
      "Epoch: 24200/30000-------------------------------------------\n",
      "Train -> Loss: 0.027690952643752 Acc: 0.827166676521301\n",
      "Valid -> Loss: 0.061048390343785 Acc: 0.582666695117950\n",
      "Epoch: 24210/30000-------------------------------------------\n",
      "Train -> Loss: 0.029268346726894 Acc: 0.815666675567627\n",
      "Valid -> Loss: 0.065075548365712 Acc: 0.544500013192495\n",
      "Epoch: 24220/30000-------------------------------------------\n",
      "Train -> Loss: 0.029358822852373 Acc: 0.810000002384186\n",
      "Valid -> Loss: 0.054423493643602 Acc: 0.641500016053518\n",
      "Epoch: 24230/30000-------------------------------------------\n",
      "Train -> Loss: 0.030920188874006 Acc: 0.797166645526886\n",
      "Valid -> Loss: 0.056456381455064 Acc: 0.620166709025701\n",
      "Epoch: 24240/30000-------------------------------------------\n",
      "Train -> Loss: 0.028266040608287 Acc: 0.815666675567627\n",
      "Valid -> Loss: 0.061834003155430 Acc: 0.573333372672399\n",
      "Epoch: 24250/30000-------------------------------------------\n",
      "Train -> Loss: 0.031476087868214 Acc: 0.792666673660278\n",
      "Valid -> Loss: 0.063736387838920 Acc: 0.553000022967656\n",
      "Epoch: 24260/30000-------------------------------------------\n",
      "Train -> Loss: 0.027799991890788 Acc: 0.827166676521301\n",
      "Valid -> Loss: 0.057918675864736 Acc: 0.607000033060710\n",
      "Epoch: 24270/30000-------------------------------------------\n",
      "Train -> Loss: 0.027980787679553 Acc: 0.820166647434235\n",
      "Valid -> Loss: 0.059953423216939 Acc: 0.591833362976710\n",
      "Epoch: 24280/30000-------------------------------------------\n",
      "Train -> Loss: 0.027887735515833 Acc: 0.826833307743073\n",
      "Valid -> Loss: 0.060790425787369 Acc: 0.583166698614756\n",
      "Epoch: 24290/30000-------------------------------------------\n",
      "Train -> Loss: 0.027704844251275 Acc: 0.824666678905487\n",
      "Valid -> Loss: 0.059325223788619 Acc: 0.598666697740555\n",
      "Epoch: 24300/30000-------------------------------------------\n",
      "Train -> Loss: 0.027769941836596 Acc: 0.825999975204468\n",
      "Valid -> Loss: 0.059358260283868 Acc: 0.597666700681051\n",
      "Epoch: 24310/30000-------------------------------------------\n",
      "Train -> Loss: 0.027799315750599 Acc: 0.824833333492279\n",
      "Valid -> Loss: 0.059906445443630 Acc: 0.593000034491221\n",
      "Epoch: 24320/30000-------------------------------------------\n",
      "Train -> Loss: 0.027679542079568 Acc: 0.826666653156281\n",
      "Valid -> Loss: 0.060600634664297 Acc: 0.587833364804586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24330/30000-------------------------------------------\n",
      "Train -> Loss: 0.027677604928613 Acc: 0.827166676521301\n",
      "Valid -> Loss: 0.061055640379588 Acc: 0.583166698614756\n",
      "Epoch: 24340/30000-------------------------------------------\n",
      "Train -> Loss: 0.027661183848977 Acc: 0.826999962329865\n",
      "Valid -> Loss: 0.060691048701604 Acc: 0.586166699727376\n",
      "Epoch: 24350/30000-------------------------------------------\n",
      "Train -> Loss: 0.027654591947794 Acc: 0.827333331108093\n",
      "Valid -> Loss: 0.060479467734694 Acc: 0.588666697343191\n",
      "Epoch: 24360/30000-------------------------------------------\n",
      "Train -> Loss: 0.027650738134980 Acc: 0.827166676521301\n",
      "Valid -> Loss: 0.060328798989455 Acc: 0.589833368857702\n",
      "Epoch: 24370/30000-------------------------------------------\n",
      "Train -> Loss: 0.027642425149679 Acc: 0.827166676521301\n",
      "Valid -> Loss: 0.060482396433751 Acc: 0.588833351929983\n",
      "Epoch: 24380/30000-------------------------------------------\n",
      "Train -> Loss: 0.027638241648674 Acc: 0.827166676521301\n",
      "Valid -> Loss: 0.060562344888846 Acc: 0.587500025828679\n",
      "Epoch: 24390/30000-------------------------------------------\n",
      "Train -> Loss: 0.027634082362056 Acc: 0.827499985694885\n",
      "Valid -> Loss: 0.060504224772255 Acc: 0.588666687409083\n",
      "Epoch: 24400/30000-------------------------------------------\n",
      "Train -> Loss: 0.027630027383566 Acc: 0.828000009059906\n",
      "Valid -> Loss: 0.060574406137069 Acc: 0.587500025828679\n",
      "Epoch: 24410/30000-------------------------------------------\n",
      "Train -> Loss: 0.027626112103462 Acc: 0.827833294868469\n",
      "Valid -> Loss: 0.060565720622738 Acc: 0.587000022331874\n",
      "Epoch: 24420/30000-------------------------------------------\n",
      "Train -> Loss: 0.027622396126390 Acc: 0.827666640281677\n",
      "Valid -> Loss: 0.060567427426577 Acc: 0.587166696786880\n",
      "Epoch: 24430/30000-------------------------------------------\n",
      "Train -> Loss: 0.027618771418929 Acc: 0.827499985694885\n",
      "Valid -> Loss: 0.060566898435354 Acc: 0.587333361307780\n",
      "Epoch: 24440/30000-------------------------------------------\n",
      "Train -> Loss: 0.027617296203971 Acc: 0.827666640281677\n",
      "Valid -> Loss: 0.060461906716228 Acc: 0.588333358367284\n",
      "Epoch: 24450/30000-------------------------------------------\n",
      "Train -> Loss: 0.027763631194830 Acc: 0.825333297252655\n",
      "Valid -> Loss: 0.059333795060714 Acc: 0.597500016291936\n",
      "Epoch: 24460/30000-------------------------------------------\n",
      "Train -> Loss: 0.029056580737233 Acc: 0.810499966144562\n",
      "Valid -> Loss: 0.057440120105942 Acc: 0.611333360274633\n",
      "Epoch: 24470/30000-------------------------------------------\n",
      "Train -> Loss: 0.027982061728835 Acc: 0.825333297252655\n",
      "Valid -> Loss: 0.061495119705796 Acc: 0.578833351532618\n",
      "Epoch: 24480/30000-------------------------------------------\n",
      "Train -> Loss: 0.027643535286188 Acc: 0.824999988079071\n",
      "Valid -> Loss: 0.060733283559481 Acc: 0.584333370129267\n",
      "Epoch: 24490/30000-------------------------------------------\n",
      "Train -> Loss: 0.027721829712391 Acc: 0.828833341598511\n",
      "Valid -> Loss: 0.059886008501053 Acc: 0.594500025113424\n",
      "Epoch: 24500/30000-------------------------------------------\n",
      "Train -> Loss: 0.027618760243058 Acc: 0.828666687011719\n",
      "Valid -> Loss: 0.060926794384917 Acc: 0.583833346764247\n",
      "Epoch: 24510/30000-------------------------------------------\n",
      "Train -> Loss: 0.027621531859040 Acc: 0.827499985694885\n",
      "Valid -> Loss: 0.060375606641173 Acc: 0.589166690905889\n",
      "Epoch: 24520/30000-------------------------------------------\n",
      "Train -> Loss: 0.029100405052304 Acc: 0.809833347797394\n",
      "Valid -> Loss: 0.057378606870770 Acc: 0.615166693925858\n",
      "Epoch: 24530/30000-------------------------------------------\n",
      "Train -> Loss: 0.031270563602448 Acc: 0.796666681766510\n",
      "Valid -> Loss: 0.080017102261384 Acc: 0.466500024000804\n",
      "Epoch: 24540/30000-------------------------------------------\n",
      "Train -> Loss: 0.030869055539370 Acc: 0.820166647434235\n",
      "Valid -> Loss: 0.068954411894083 Acc: 0.522666687766711\n",
      "Epoch: 24550/30000-------------------------------------------\n",
      "Train -> Loss: 0.035392537713051 Acc: 0.764833331108093\n",
      "Valid -> Loss: 0.055138054614266 Acc: 0.635666698217392\n",
      "Epoch: 24560/30000-------------------------------------------\n",
      "Train -> Loss: 0.028748702257872 Acc: 0.821333348751068\n",
      "Valid -> Loss: 0.055639620870352 Acc: 0.631500015656153\n",
      "Epoch: 24570/30000-------------------------------------------\n",
      "Train -> Loss: 0.028587460517883 Acc: 0.824499964714050\n",
      "Valid -> Loss: 0.060412523026268 Acc: 0.587333371241887\n",
      "Epoch: 24580/30000-------------------------------------------\n",
      "Train -> Loss: 0.028053605929017 Acc: 0.820999979972839\n",
      "Valid -> Loss: 0.058382486303647 Acc: 0.608166694641113\n",
      "Epoch: 24590/30000-------------------------------------------\n",
      "Train -> Loss: 0.028080483898520 Acc: 0.825166642665863\n",
      "Valid -> Loss: 0.058135505765676 Acc: 0.609500030676524\n",
      "Epoch: 24600/30000-------------------------------------------\n",
      "Train -> Loss: 0.027879863977432 Acc: 0.827499985694885\n",
      "Valid -> Loss: 0.060136727988720 Acc: 0.589166700839996\n",
      "Epoch: 24610/30000-------------------------------------------\n",
      "Train -> Loss: 0.028236743062735 Acc: 0.826499998569489\n",
      "Valid -> Loss: 0.060425592586398 Acc: 0.586000025272369\n",
      "Epoch: 24620/30000-------------------------------------------\n",
      "Train -> Loss: 0.029003312811255 Acc: 0.816999971866608\n",
      "Valid -> Loss: 0.061267768343290 Acc: 0.578333367904027\n",
      "Epoch: 24630/30000-------------------------------------------\n",
      "Train -> Loss: 0.027892077341676 Acc: 0.825166642665863\n",
      "Valid -> Loss: 0.056611717368166 Acc: 0.627333352963130\n",
      "Epoch: 24640/30000-------------------------------------------\n",
      "Train -> Loss: 0.028084533289075 Acc: 0.825333297252655\n",
      "Valid -> Loss: 0.062646394595504 Acc: 0.567666689554850\n",
      "Epoch: 24650/30000-------------------------------------------\n",
      "Train -> Loss: 0.028414893895388 Acc: 0.827666640281677\n",
      "Valid -> Loss: 0.057663863524795 Acc: 0.614833364884059\n",
      "Epoch: 24660/30000-------------------------------------------\n",
      "Train -> Loss: 0.027732728049159 Acc: 0.828000009059906\n",
      "Valid -> Loss: 0.060714730992913 Acc: 0.585000038146973\n",
      "Epoch: 24670/30000-------------------------------------------\n",
      "Train -> Loss: 0.027707623317838 Acc: 0.826833307743073\n",
      "Valid -> Loss: 0.058831525966525 Acc: 0.601000020901362\n",
      "Epoch: 24680/30000-------------------------------------------\n",
      "Train -> Loss: 0.027625782415271 Acc: 0.828166663646698\n",
      "Valid -> Loss: 0.060422870640953 Acc: 0.586833367745082\n",
      "Epoch: 24690/30000-------------------------------------------\n",
      "Train -> Loss: 0.027606181800365 Acc: 0.828000009059906\n",
      "Valid -> Loss: 0.059891087934375 Acc: 0.591500033934911\n",
      "Epoch: 24700/30000-------------------------------------------\n",
      "Train -> Loss: 0.027599364519119 Acc: 0.828166663646698\n",
      "Valid -> Loss: 0.060000471149882 Acc: 0.592000017563502\n",
      "Epoch: 24710/30000-------------------------------------------\n",
      "Train -> Loss: 0.027587402611971 Acc: 0.828000009059906\n",
      "Valid -> Loss: 0.060161763802171 Acc: 0.591000030438105\n",
      "Epoch: 24720/30000-------------------------------------------\n",
      "Train -> Loss: 0.027580251917243 Acc: 0.828333318233490\n",
      "Valid -> Loss: 0.060123353575667 Acc: 0.591166694959005\n",
      "Epoch: 24730/30000-------------------------------------------\n",
      "Train -> Loss: 0.027574609965086 Acc: 0.828666687011719\n",
      "Valid -> Loss: 0.060110797484716 Acc: 0.591333359479904\n",
      "Epoch: 24740/30000-------------------------------------------\n",
      "Train -> Loss: 0.027569670230150 Acc: 0.828833341598511\n",
      "Valid -> Loss: 0.060143051669002 Acc: 0.591166685024897\n",
      "Epoch: 24750/30000-------------------------------------------\n",
      "Train -> Loss: 0.027565153315663 Acc: 0.828833341598511\n",
      "Valid -> Loss: 0.060191705822945 Acc: 0.591333349545797\n",
      "Epoch: 24760/30000-------------------------------------------\n",
      "Train -> Loss: 0.027560951188207 Acc: 0.828666687011719\n",
      "Valid -> Loss: 0.060209477941195 Acc: 0.590833355983098\n",
      "Epoch: 24770/30000-------------------------------------------\n",
      "Train -> Loss: 0.027556948363781 Acc: 0.828999996185303\n",
      "Valid -> Loss: 0.060227588439981 Acc: 0.590500026941299\n",
      "Epoch: 24780/30000-------------------------------------------\n",
      "Train -> Loss: 0.027553090825677 Acc: 0.828833341598511\n",
      "Valid -> Loss: 0.060245042045911 Acc: 0.590333352486292\n",
      "Epoch: 24790/30000-------------------------------------------\n",
      "Train -> Loss: 0.027549356222153 Acc: 0.829166650772095\n",
      "Valid -> Loss: 0.060259156549970 Acc: 0.590166678031286\n",
      "Epoch: 24800/30000-------------------------------------------\n",
      "Train -> Loss: 0.027545711025596 Acc: 0.829333305358887\n",
      "Valid -> Loss: 0.060276143252850 Acc: 0.589666684468587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24810/30000-------------------------------------------\n",
      "Train -> Loss: 0.027542140334845 Acc: 0.829333305358887\n",
      "Valid -> Loss: 0.060291859010855 Acc: 0.589500019947688\n",
      "Epoch: 24820/30000-------------------------------------------\n",
      "Train -> Loss: 0.027538627386093 Acc: 0.829500019550323\n",
      "Valid -> Loss: 0.060307403405507 Acc: 0.589333345492681\n",
      "Epoch: 24830/30000-------------------------------------------\n",
      "Train -> Loss: 0.027535164728761 Acc: 0.829666674137115\n",
      "Valid -> Loss: 0.060323078806202 Acc: 0.589166680971781\n",
      "Epoch: 24840/30000-------------------------------------------\n",
      "Train -> Loss: 0.027531746774912 Acc: 0.829833328723907\n",
      "Valid -> Loss: 0.060338467359543 Acc: 0.589333345492681\n",
      "Epoch: 24850/30000-------------------------------------------\n",
      "Train -> Loss: 0.027528360486031 Acc: 0.829833328723907\n",
      "Valid -> Loss: 0.060352097575863 Acc: 0.589166680971781\n",
      "Epoch: 24860/30000-------------------------------------------\n",
      "Train -> Loss: 0.027525007724762 Acc: 0.829833328723907\n",
      "Valid -> Loss: 0.060365528489153 Acc: 0.589166680971781\n",
      "Epoch: 24870/30000-------------------------------------------\n",
      "Train -> Loss: 0.027521677315235 Acc: 0.829999983310699\n",
      "Valid -> Loss: 0.060380461315314 Acc: 0.588666687409083\n",
      "Epoch: 24880/30000-------------------------------------------\n",
      "Train -> Loss: 0.027518369257450 Acc: 0.829833328723907\n",
      "Valid -> Loss: 0.060393442089359 Acc: 0.588500022888184\n",
      "Epoch: 24890/30000-------------------------------------------\n",
      "Train -> Loss: 0.027515077963471 Acc: 0.829999983310699\n",
      "Valid -> Loss: 0.060406733925144 Acc: 0.588500022888184\n",
      "Epoch: 24900/30000-------------------------------------------\n",
      "Train -> Loss: 0.027511801570654 Acc: 0.830166637897491\n",
      "Valid -> Loss: 0.060420499493678 Acc: 0.588166693846385\n",
      "Epoch: 24910/30000-------------------------------------------\n",
      "Train -> Loss: 0.027508534491062 Acc: 0.830166637897491\n",
      "Valid -> Loss: 0.060432299350699 Acc: 0.588000019391378\n",
      "Epoch: 24920/30000-------------------------------------------\n",
      "Train -> Loss: 0.027505284175277 Acc: 0.830166637897491\n",
      "Valid -> Loss: 0.060443879415592 Acc: 0.587833354870478\n",
      "Epoch: 24930/30000-------------------------------------------\n",
      "Train -> Loss: 0.027502037584782 Acc: 0.830333352088928\n",
      "Valid -> Loss: 0.060453516741594 Acc: 0.587833354870478\n",
      "Epoch: 24940/30000-------------------------------------------\n",
      "Train -> Loss: 0.027498887851834 Acc: 0.830333352088928\n",
      "Valid -> Loss: 0.060436230773727 Acc: 0.587833354870478\n",
      "Epoch: 24950/30000-------------------------------------------\n",
      "Train -> Loss: 0.027522858232260 Acc: 0.828666687011719\n",
      "Valid -> Loss: 0.059885420526067 Acc: 0.593500018119812\n",
      "Epoch: 24960/30000-------------------------------------------\n",
      "Train -> Loss: 0.032480783760548 Acc: 0.786499977111816\n",
      "Valid -> Loss: 0.054238175973296 Acc: 0.643833369016647\n",
      "Epoch: 24970/30000-------------------------------------------\n",
      "Train -> Loss: 0.028548907488585 Acc: 0.821666657924652\n",
      "Valid -> Loss: 0.057704802602530 Acc: 0.616833368937174\n",
      "Epoch: 24980/30000-------------------------------------------\n",
      "Train -> Loss: 0.027863131836057 Acc: 0.819499969482422\n",
      "Valid -> Loss: 0.059609643494089 Acc: 0.592000037431717\n",
      "Epoch: 24990/30000-------------------------------------------\n",
      "Train -> Loss: 0.028879841789603 Acc: 0.815333306789398\n",
      "Valid -> Loss: 0.059615496546030 Acc: 0.597833375136057\n",
      "Epoch: 25000/30000-------------------------------------------\n",
      "Train -> Loss: 0.028130989521742 Acc: 0.824000000953674\n",
      "Valid -> Loss: 0.062434567759434 Acc: 0.568000018596649\n",
      "Epoch: 25010/30000-------------------------------------------\n",
      "Train -> Loss: 0.028141688555479 Acc: 0.824833333492279\n",
      "Valid -> Loss: 0.061121983453631 Acc: 0.578000028928121\n",
      "Epoch: 25020/30000-------------------------------------------\n",
      "Train -> Loss: 0.028624637052417 Acc: 0.814499974250793\n",
      "Valid -> Loss: 0.058038575574756 Acc: 0.607166687647502\n",
      "Epoch: 25030/30000-------------------------------------------\n",
      "Train -> Loss: 0.027526857331395 Acc: 0.829166650772095\n",
      "Valid -> Loss: 0.060185316950083 Acc: 0.591333359479904\n",
      "Epoch: 25040/30000-------------------------------------------\n",
      "Train -> Loss: 0.027544813230634 Acc: 0.829999983310699\n",
      "Valid -> Loss: 0.061084306488434 Acc: 0.581666698058446\n",
      "Epoch: 25050/30000-------------------------------------------\n",
      "Train -> Loss: 0.027512965723872 Acc: 0.830166637897491\n",
      "Valid -> Loss: 0.060409485672911 Acc: 0.589833358923594\n",
      "Epoch: 25060/30000-------------------------------------------\n",
      "Train -> Loss: 0.027493095025420 Acc: 0.829999983310699\n",
      "Valid -> Loss: 0.060481349627177 Acc: 0.588333368301392\n",
      "Epoch: 25070/30000-------------------------------------------\n",
      "Train -> Loss: 0.027483899146318 Acc: 0.829500019550323\n",
      "Valid -> Loss: 0.060330356160800 Acc: 0.589666684468587\n",
      "Epoch: 25080/30000-------------------------------------------\n",
      "Train -> Loss: 0.027476510033011 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.060366141920288 Acc: 0.589166690905889\n",
      "Epoch: 25090/30000-------------------------------------------\n",
      "Train -> Loss: 0.027471460402012 Acc: 0.830833315849304\n",
      "Valid -> Loss: 0.060453725978732 Acc: 0.588666697343191\n",
      "Epoch: 25100/30000-------------------------------------------\n",
      "Train -> Loss: 0.027467068284750 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.060432912160953 Acc: 0.588666697343191\n",
      "Epoch: 25110/30000-------------------------------------------\n",
      "Train -> Loss: 0.027463089674711 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.060458341613412 Acc: 0.588500022888184\n",
      "Epoch: 25120/30000-------------------------------------------\n",
      "Train -> Loss: 0.027459422126412 Acc: 0.830999970436096\n",
      "Valid -> Loss: 0.060495690753063 Acc: 0.588333358367284\n",
      "Epoch: 25130/30000-------------------------------------------\n",
      "Train -> Loss: 0.027455896139145 Acc: 0.830833315849304\n",
      "Valid -> Loss: 0.060516485323509 Acc: 0.588000029325485\n",
      "Epoch: 25140/30000-------------------------------------------\n",
      "Train -> Loss: 0.027454946190119 Acc: 0.831166684627533\n",
      "Valid -> Loss: 0.060664171352983 Acc: 0.586833357810974\n",
      "Epoch: 25150/30000-------------------------------------------\n",
      "Train -> Loss: 0.027689551934600 Acc: 0.828000009059906\n",
      "Valid -> Loss: 0.062097311019897 Acc: 0.573166688283285\n",
      "Epoch: 25160/30000-------------------------------------------\n",
      "Train -> Loss: 0.031572196632624 Acc: 0.798666656017303\n",
      "Valid -> Loss: 0.065447329233090 Acc: 0.541500031948090\n",
      "Epoch: 25170/30000-------------------------------------------\n",
      "Train -> Loss: 0.027858410030603 Acc: 0.834999978542328\n",
      "Valid -> Loss: 0.060939061144988 Acc: 0.579166690508525\n",
      "Epoch: 25180/30000-------------------------------------------\n",
      "Train -> Loss: 0.029603354632854 Acc: 0.805999994277954\n",
      "Valid -> Loss: 0.059431852151950 Acc: 0.594333350658417\n",
      "Epoch: 25190/30000-------------------------------------------\n",
      "Train -> Loss: 0.027814861387014 Acc: 0.832166671752930\n",
      "Valid -> Loss: 0.060362939412395 Acc: 0.585333357254664\n",
      "Epoch: 25200/30000-------------------------------------------\n",
      "Train -> Loss: 0.027611248195171 Acc: 0.827166676521301\n",
      "Valid -> Loss: 0.060030083482464 Acc: 0.592833360036214\n",
      "Epoch: 25210/30000-------------------------------------------\n",
      "Train -> Loss: 0.027980307117105 Acc: 0.829999983310699\n",
      "Valid -> Loss: 0.059309205040336 Acc: 0.595833371082942\n",
      "Epoch: 25220/30000-------------------------------------------\n",
      "Train -> Loss: 0.030352747067809 Acc: 0.804833352565765\n",
      "Valid -> Loss: 0.058157939463854 Acc: 0.604666690031687\n",
      "Epoch: 25230/30000-------------------------------------------\n",
      "Train -> Loss: 0.027533628046513 Acc: 0.833000004291534\n",
      "Valid -> Loss: 0.060313840086261 Acc: 0.590000033378601\n",
      "Epoch: 25240/30000-------------------------------------------\n",
      "Train -> Loss: 0.027512872591615 Acc: 0.828999996185303\n",
      "Valid -> Loss: 0.061278921862443 Acc: 0.580166687568029\n",
      "Epoch: 25250/30000-------------------------------------------\n",
      "Train -> Loss: 0.027453621849418 Acc: 0.831833302974701\n",
      "Valid -> Loss: 0.060398032267888 Acc: 0.589333365360896\n",
      "Epoch: 25260/30000-------------------------------------------\n",
      "Train -> Loss: 0.027448883280158 Acc: 0.830833315849304\n",
      "Valid -> Loss: 0.060795378560821 Acc: 0.584666699171066\n",
      "Epoch: 25270/30000-------------------------------------------\n",
      "Train -> Loss: 0.027452984824777 Acc: 0.831333339214325\n",
      "Valid -> Loss: 0.060407785077890 Acc: 0.589500019947688\n",
      "Epoch: 25280/30000-------------------------------------------\n",
      "Train -> Loss: 0.027447350323200 Acc: 0.830999970436096\n",
      "Valid -> Loss: 0.060796264559031 Acc: 0.585500041643778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25290/30000-------------------------------------------\n",
      "Train -> Loss: 0.027433685958385 Acc: 0.831166684627533\n",
      "Valid -> Loss: 0.060295890395840 Acc: 0.591333349545797\n",
      "Epoch: 25300/30000-------------------------------------------\n",
      "Train -> Loss: 0.027470901608467 Acc: 0.829166650772095\n",
      "Valid -> Loss: 0.059832215930025 Acc: 0.594666699568431\n",
      "Epoch: 25310/30000-------------------------------------------\n",
      "Train -> Loss: 0.027660122141242 Acc: 0.828499972820282\n",
      "Valid -> Loss: 0.059297167385618 Acc: 0.597000032663345\n",
      "Epoch: 25320/30000-------------------------------------------\n",
      "Train -> Loss: 0.036185827106237 Acc: 0.762666642665863\n",
      "Valid -> Loss: 0.053232266878088 Acc: 0.652500043312708\n",
      "Epoch: 25330/30000-------------------------------------------\n",
      "Train -> Loss: 0.028440397232771 Acc: 0.820833325386047\n",
      "Valid -> Loss: 0.059864179541667 Acc: 0.607166687647502\n",
      "Epoch: 25340/30000-------------------------------------------\n",
      "Train -> Loss: 0.028616653755307 Acc: 0.823166668415070\n",
      "Valid -> Loss: 0.059996317451199 Acc: 0.599833369255066\n",
      "Epoch: 25350/30000-------------------------------------------\n",
      "Train -> Loss: 0.027790909633040 Acc: 0.827833294868469\n",
      "Valid -> Loss: 0.061606449385484 Acc: 0.578833361466726\n",
      "Epoch: 25360/30000-------------------------------------------\n",
      "Train -> Loss: 0.029540572315454 Acc: 0.821500003337860\n",
      "Valid -> Loss: 0.058376522113880 Acc: 0.605666697025299\n",
      "Epoch: 25370/30000-------------------------------------------\n",
      "Train -> Loss: 0.030371258035302 Acc: 0.810333311557770\n",
      "Valid -> Loss: 0.054798536623518 Acc: 0.638333370288213\n",
      "Epoch: 25380/30000-------------------------------------------\n",
      "Train -> Loss: 0.028105767443776 Acc: 0.825666666030884\n",
      "Valid -> Loss: 0.063118953257799 Acc: 0.558333367109299\n",
      "Epoch: 25390/30000-------------------------------------------\n",
      "Train -> Loss: 0.031538061797619 Acc: 0.800833344459534\n",
      "Valid -> Loss: 0.063346199070414 Acc: 0.556500017642975\n",
      "Epoch: 25400/30000-------------------------------------------\n",
      "Train -> Loss: 0.028752597048879 Acc: 0.815999984741211\n",
      "Valid -> Loss: 0.059906412536899 Acc: 0.586333354314168\n",
      "Epoch: 25410/30000-------------------------------------------\n",
      "Train -> Loss: 0.027706068009138 Acc: 0.830833315849304\n",
      "Valid -> Loss: 0.062016624336441 Acc: 0.570333361625671\n",
      "Epoch: 25420/30000-------------------------------------------\n",
      "Train -> Loss: 0.027599573135376 Acc: 0.829333305358887\n",
      "Valid -> Loss: 0.058861472954353 Acc: 0.600333362817764\n",
      "Epoch: 25430/30000-------------------------------------------\n",
      "Train -> Loss: 0.027514068409801 Acc: 0.828999996185303\n",
      "Valid -> Loss: 0.060422457754612 Acc: 0.586833357810974\n",
      "Epoch: 25440/30000-------------------------------------------\n",
      "Train -> Loss: 0.027492217719555 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.060016874844829 Acc: 0.592166692018509\n",
      "Epoch: 25450/30000-------------------------------------------\n",
      "Train -> Loss: 0.027446098625660 Acc: 0.830333352088928\n",
      "Valid -> Loss: 0.059636173769832 Acc: 0.595500032107035\n",
      "Epoch: 25460/30000-------------------------------------------\n",
      "Train -> Loss: 0.027433484792709 Acc: 0.830833315849304\n",
      "Valid -> Loss: 0.059982887779673 Acc: 0.593000014623006\n",
      "Epoch: 25470/30000-------------------------------------------\n",
      "Train -> Loss: 0.027417752891779 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.060211061810454 Acc: 0.590166697899500\n",
      "Epoch: 25480/30000-------------------------------------------\n",
      "Train -> Loss: 0.027409382164478 Acc: 0.830833315849304\n",
      "Valid -> Loss: 0.060236575702826 Acc: 0.590333362420400\n",
      "Epoch: 25490/30000-------------------------------------------\n",
      "Train -> Loss: 0.027402261272073 Acc: 0.830999970436096\n",
      "Valid -> Loss: 0.060239534204205 Acc: 0.590333362420400\n",
      "Epoch: 25500/30000-------------------------------------------\n",
      "Train -> Loss: 0.027396256104112 Acc: 0.831166684627533\n",
      "Valid -> Loss: 0.060262013847629 Acc: 0.589833358923594\n",
      "Epoch: 25510/30000-------------------------------------------\n",
      "Train -> Loss: 0.027390917763114 Acc: 0.831166684627533\n",
      "Valid -> Loss: 0.060263734310865 Acc: 0.590166687965393\n",
      "Epoch: 25520/30000-------------------------------------------\n",
      "Train -> Loss: 0.027386024594307 Acc: 0.831499993801117\n",
      "Valid -> Loss: 0.060276805112759 Acc: 0.590000023444494\n",
      "Epoch: 25530/30000-------------------------------------------\n",
      "Train -> Loss: 0.027381446212530 Acc: 0.831833302974701\n",
      "Valid -> Loss: 0.060300593574842 Acc: 0.589666694402695\n",
      "Epoch: 25540/30000-------------------------------------------\n",
      "Train -> Loss: 0.027377119287848 Acc: 0.831666648387909\n",
      "Valid -> Loss: 0.060323498522242 Acc: 0.589833368857702\n",
      "Epoch: 25550/30000-------------------------------------------\n",
      "Train -> Loss: 0.027372973039746 Acc: 0.831166684627533\n",
      "Valid -> Loss: 0.060341402267416 Acc: 0.589666704336802\n",
      "Epoch: 25560/30000-------------------------------------------\n",
      "Train -> Loss: 0.027368970215321 Acc: 0.831166684627533\n",
      "Valid -> Loss: 0.060356526946028 Acc: 0.589500029881795\n",
      "Epoch: 25570/30000-------------------------------------------\n",
      "Train -> Loss: 0.027365079149604 Acc: 0.831333339214325\n",
      "Valid -> Loss: 0.060373947645227 Acc: 0.589000026384989\n",
      "Epoch: 25580/30000-------------------------------------------\n",
      "Train -> Loss: 0.027361277490854 Acc: 0.831666648387909\n",
      "Valid -> Loss: 0.060388976087173 Acc: 0.589000036319097\n",
      "Epoch: 25590/30000-------------------------------------------\n",
      "Train -> Loss: 0.027357552200556 Acc: 0.831499993801117\n",
      "Valid -> Loss: 0.060405360534787 Acc: 0.589166700839996\n",
      "Epoch: 25600/30000-------------------------------------------\n",
      "Train -> Loss: 0.027353888377547 Acc: 0.831499993801117\n",
      "Valid -> Loss: 0.060419635226329 Acc: 0.588666697343191\n",
      "Epoch: 25610/30000-------------------------------------------\n",
      "Train -> Loss: 0.027350272983313 Acc: 0.831666648387909\n",
      "Valid -> Loss: 0.060433919231097 Acc: 0.588500032822291\n",
      "Epoch: 25620/30000-------------------------------------------\n",
      "Train -> Loss: 0.027346711605787 Acc: 0.831666648387909\n",
      "Valid -> Loss: 0.060453902930021 Acc: 0.588333368301392\n",
      "Epoch: 25630/30000-------------------------------------------\n",
      "Train -> Loss: 0.027343677356839 Acc: 0.831833302974701\n",
      "Valid -> Loss: 0.060538636520505 Acc: 0.587333371241887\n",
      "Epoch: 25640/30000-------------------------------------------\n",
      "Train -> Loss: 0.027486357837915 Acc: 0.831833302974701\n",
      "Valid -> Loss: 0.061845346043507 Acc: 0.575500021378199\n",
      "Epoch: 25650/30000-------------------------------------------\n",
      "Train -> Loss: 0.031098188832402 Acc: 0.802666664123535\n",
      "Valid -> Loss: 0.063553816949328 Acc: 0.553666700919469\n",
      "Epoch: 25660/30000-------------------------------------------\n",
      "Train -> Loss: 0.031443886458874 Acc: 0.805666685104370\n",
      "Valid -> Loss: 0.061821324129899 Acc: 0.571666687726974\n",
      "Epoch: 25670/30000-------------------------------------------\n",
      "Train -> Loss: 0.027986416593194 Acc: 0.823000013828278\n",
      "Valid -> Loss: 0.054859913264712 Acc: 0.639500031868617\n",
      "Epoch: 25680/30000-------------------------------------------\n",
      "Train -> Loss: 0.027634443715215 Acc: 0.828499972820282\n",
      "Valid -> Loss: 0.060247844705979 Acc: 0.591500033934911\n",
      "Epoch: 25690/30000-------------------------------------------\n",
      "Train -> Loss: 0.029306704178452 Acc: 0.819000005722046\n",
      "Valid -> Loss: 0.058696115389466 Acc: 0.600833356380463\n",
      "Epoch: 25700/30000-------------------------------------------\n",
      "Train -> Loss: 0.028584219515324 Acc: 0.819000005722046\n",
      "Valid -> Loss: 0.057862151414156 Acc: 0.607000042994817\n",
      "Epoch: 25710/30000-------------------------------------------\n",
      "Train -> Loss: 0.032227970659733 Acc: 0.797999978065491\n",
      "Valid -> Loss: 0.066757967074712 Acc: 0.528166691462199\n",
      "Epoch: 25720/30000-------------------------------------------\n",
      "Train -> Loss: 0.030178325250745 Acc: 0.804166674613953\n",
      "Valid -> Loss: 0.057142908995350 Acc: 0.613666703303655\n",
      "Epoch: 25730/30000-------------------------------------------\n",
      "Train -> Loss: 0.039416290819645 Acc: 0.747999966144562\n",
      "Valid -> Loss: 0.062402941907446 Acc: 0.566000024477641\n",
      "Epoch: 25740/30000-------------------------------------------\n",
      "Train -> Loss: 0.032915703952312 Acc: 0.785166680812836\n",
      "Valid -> Loss: 0.056921575839321 Acc: 0.617666701475779\n",
      "Epoch: 25750/30000-------------------------------------------\n",
      "Train -> Loss: 0.028551381081343 Acc: 0.823000013828278\n",
      "Valid -> Loss: 0.058519780014952 Acc: 0.602166702349981\n",
      "Epoch: 25760/30000-------------------------------------------\n",
      "Train -> Loss: 0.028093021363020 Acc: 0.828166663646698\n",
      "Valid -> Loss: 0.060711997250716 Acc: 0.583833366632462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25770/30000-------------------------------------------\n",
      "Train -> Loss: 0.027506340295076 Acc: 0.828000009059906\n",
      "Valid -> Loss: 0.059862270951271 Acc: 0.592333376407623\n",
      "Epoch: 25780/30000-------------------------------------------\n",
      "Train -> Loss: 0.027433451265097 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.059156262005369 Acc: 0.600666691859563\n",
      "Epoch: 25790/30000-------------------------------------------\n",
      "Train -> Loss: 0.027403863146901 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.060138615469138 Acc: 0.590833355983098\n",
      "Epoch: 25800/30000-------------------------------------------\n",
      "Train -> Loss: 0.027383072301745 Acc: 0.831333339214325\n",
      "Valid -> Loss: 0.059632475798329 Acc: 0.596666703621546\n",
      "Epoch: 25810/30000-------------------------------------------\n",
      "Train -> Loss: 0.027364602312446 Acc: 0.830833315849304\n",
      "Valid -> Loss: 0.059976035108169 Acc: 0.591500024000804\n",
      "Epoch: 25820/30000-------------------------------------------\n",
      "Train -> Loss: 0.027353713288903 Acc: 0.831333339214325\n",
      "Valid -> Loss: 0.059966009110212 Acc: 0.592333366473516\n",
      "Epoch: 25830/30000-------------------------------------------\n",
      "Train -> Loss: 0.027344293892384 Acc: 0.832000017166138\n",
      "Valid -> Loss: 0.059965264673034 Acc: 0.592166692018509\n",
      "Epoch: 25840/30000-------------------------------------------\n",
      "Train -> Loss: 0.027336375787854 Acc: 0.832000017166138\n",
      "Valid -> Loss: 0.060052507246534 Acc: 0.591500024000804\n",
      "Epoch: 25850/30000-------------------------------------------\n",
      "Train -> Loss: 0.027329878881574 Acc: 0.832499980926514\n",
      "Valid -> Loss: 0.060074236243963 Acc: 0.591000030438105\n",
      "Epoch: 25860/30000-------------------------------------------\n",
      "Train -> Loss: 0.027324166148901 Acc: 0.832499980926514\n",
      "Valid -> Loss: 0.060087553535899 Acc: 0.591166694959005\n",
      "Epoch: 25870/30000-------------------------------------------\n",
      "Train -> Loss: 0.027318963780999 Acc: 0.832666635513306\n",
      "Valid -> Loss: 0.060106152047714 Acc: 0.591000020503998\n",
      "Epoch: 25880/30000-------------------------------------------\n",
      "Train -> Loss: 0.027314152568579 Acc: 0.832499980926514\n",
      "Valid -> Loss: 0.060123238091667 Acc: 0.590666691462199\n",
      "Epoch: 25890/30000-------------------------------------------\n",
      "Train -> Loss: 0.027309613302350 Acc: 0.832499980926514\n",
      "Valid -> Loss: 0.060145732636253 Acc: 0.590666691462199\n",
      "Epoch: 25900/30000-------------------------------------------\n",
      "Train -> Loss: 0.027305278927088 Acc: 0.832666635513306\n",
      "Valid -> Loss: 0.060166765625278 Acc: 0.590833365917206\n",
      "Epoch: 25910/30000-------------------------------------------\n",
      "Train -> Loss: 0.027301101014018 Acc: 0.832833349704742\n",
      "Valid -> Loss: 0.060185584550103 Acc: 0.590833365917206\n",
      "Epoch: 25920/30000-------------------------------------------\n",
      "Train -> Loss: 0.027297051623464 Acc: 0.833000004291534\n",
      "Valid -> Loss: 0.060203944643339 Acc: 0.591000030438105\n",
      "Epoch: 25930/30000-------------------------------------------\n",
      "Train -> Loss: 0.027293099090457 Acc: 0.833333313465118\n",
      "Valid -> Loss: 0.060221830382943 Acc: 0.591000030438105\n",
      "Epoch: 25940/30000-------------------------------------------\n",
      "Train -> Loss: 0.027289226651192 Acc: 0.833166658878326\n",
      "Valid -> Loss: 0.060239370912313 Acc: 0.590833365917206\n",
      "Epoch: 25950/30000-------------------------------------------\n",
      "Train -> Loss: 0.027285417541862 Acc: 0.833333313465118\n",
      "Valid -> Loss: 0.060257098947962 Acc: 0.590500026941299\n",
      "Epoch: 25960/30000-------------------------------------------\n",
      "Train -> Loss: 0.027281660586596 Acc: 0.833166658878326\n",
      "Valid -> Loss: 0.060271612058083 Acc: 0.590666691462199\n",
      "Epoch: 25970/30000-------------------------------------------\n",
      "Train -> Loss: 0.027277948334813 Acc: 0.833000004291534\n",
      "Valid -> Loss: 0.060288039346536 Acc: 0.590500026941299\n",
      "Epoch: 25980/30000-------------------------------------------\n",
      "Train -> Loss: 0.027274264022708 Acc: 0.833333313465118\n",
      "Valid -> Loss: 0.060304248705506 Acc: 0.590166687965393\n",
      "Epoch: 25990/30000-------------------------------------------\n",
      "Train -> Loss: 0.027270605787635 Acc: 0.833333313465118\n",
      "Valid -> Loss: 0.060320212195317 Acc: 0.590166687965393\n",
      "Epoch: 26000/30000-------------------------------------------\n",
      "Train -> Loss: 0.027266969904304 Acc: 0.833499968051910\n",
      "Valid -> Loss: 0.060334581881762 Acc: 0.589666694402695\n",
      "Epoch: 26010/30000-------------------------------------------\n",
      "Train -> Loss: 0.027263341471553 Acc: 0.833833336830139\n",
      "Valid -> Loss: 0.060349234069387 Acc: 0.589666694402695\n",
      "Epoch: 26020/30000-------------------------------------------\n",
      "Train -> Loss: 0.027259720489383 Acc: 0.833833336830139\n",
      "Valid -> Loss: 0.060366614411275 Acc: 0.589166690905889\n",
      "Epoch: 26030/30000-------------------------------------------\n",
      "Train -> Loss: 0.027256106957793 Acc: 0.833833336830139\n",
      "Valid -> Loss: 0.060385728254914 Acc: 0.588833361864090\n",
      "Epoch: 26040/30000-------------------------------------------\n",
      "Train -> Loss: 0.027252566069365 Acc: 0.834500014781952\n",
      "Valid -> Loss: 0.060422711074352 Acc: 0.588833361864090\n",
      "Epoch: 26050/30000-------------------------------------------\n",
      "Train -> Loss: 0.027254534885287 Acc: 0.835500001907349\n",
      "Valid -> Loss: 0.060660849635800 Acc: 0.586833357810974\n",
      "Epoch: 26060/30000-------------------------------------------\n",
      "Train -> Loss: 0.027984773740172 Acc: 0.827666640281677\n",
      "Valid -> Loss: 0.063326129689813 Acc: 0.562500019868215\n",
      "Epoch: 26070/30000-------------------------------------------\n",
      "Train -> Loss: 0.027319425716996 Acc: 0.833833336830139\n",
      "Valid -> Loss: 0.058117493366202 Acc: 0.610833356777827\n",
      "Epoch: 26080/30000-------------------------------------------\n",
      "Train -> Loss: 0.029589576646686 Acc: 0.831166684627533\n",
      "Valid -> Loss: 0.055578290174405 Acc: 0.633333365122477\n",
      "Epoch: 26090/30000-------------------------------------------\n",
      "Train -> Loss: 0.028516080230474 Acc: 0.814333319664001\n",
      "Valid -> Loss: 0.057433540001512 Acc: 0.613000025351842\n",
      "Epoch: 26100/30000-------------------------------------------\n",
      "Train -> Loss: 0.027282074093819 Acc: 0.831833302974701\n",
      "Valid -> Loss: 0.059919230639935 Acc: 0.595166693131129\n",
      "Epoch: 26110/30000-------------------------------------------\n",
      "Train -> Loss: 0.027265680953860 Acc: 0.833333313465118\n",
      "Valid -> Loss: 0.060738559191426 Acc: 0.583166688680649\n",
      "Epoch: 26120/30000-------------------------------------------\n",
      "Train -> Loss: 0.027246667072177 Acc: 0.834166646003723\n",
      "Valid -> Loss: 0.060042639573415 Acc: 0.592833360036214\n",
      "Epoch: 26130/30000-------------------------------------------\n",
      "Train -> Loss: 0.027270399034023 Acc: 0.834666669368744\n",
      "Valid -> Loss: 0.060768219952782 Acc: 0.583500027656555\n",
      "Epoch: 26140/30000-------------------------------------------\n",
      "Train -> Loss: 0.027285955846310 Acc: 0.835333347320557\n",
      "Valid -> Loss: 0.060385446995497 Acc: 0.590500036875407\n",
      "Epoch: 26150/30000-------------------------------------------\n",
      "Train -> Loss: 0.029273439198732 Acc: 0.822666645050049\n",
      "Valid -> Loss: 0.066569395363331 Acc: 0.533166681726774\n",
      "Epoch: 26160/30000-------------------------------------------\n",
      "Train -> Loss: 0.027775315567851 Acc: 0.829833328723907\n",
      "Valid -> Loss: 0.059796045844754 Acc: 0.596666693687439\n",
      "Epoch: 26170/30000-------------------------------------------\n",
      "Train -> Loss: 0.028220772743225 Acc: 0.833666682243347\n",
      "Valid -> Loss: 0.059455670416355 Acc: 0.596666683753332\n",
      "Epoch: 26180/30000-------------------------------------------\n",
      "Train -> Loss: 0.027570113539696 Acc: 0.834333300590515\n",
      "Valid -> Loss: 0.061258506650726 Acc: 0.577500025431315\n",
      "Epoch: 26190/30000-------------------------------------------\n",
      "Train -> Loss: 0.027486266568303 Acc: 0.831166684627533\n",
      "Valid -> Loss: 0.060222213466962 Acc: 0.593333363533020\n",
      "Epoch: 26200/30000-------------------------------------------\n",
      "Train -> Loss: 0.027280407026410 Acc: 0.836333334445953\n",
      "Valid -> Loss: 0.060828282187382 Acc: 0.583666702111562\n",
      "Epoch: 26210/30000-------------------------------------------\n",
      "Train -> Loss: 0.027238642796874 Acc: 0.834166646003723\n",
      "Valid -> Loss: 0.060396131748954 Acc: 0.589833348989487\n",
      "Epoch: 26220/30000-------------------------------------------\n",
      "Train -> Loss: 0.027217786759138 Acc: 0.834166646003723\n",
      "Valid -> Loss: 0.060240139563878 Acc: 0.591666698455811\n",
      "Epoch: 26230/30000-------------------------------------------\n",
      "Train -> Loss: 0.027209509164095 Acc: 0.834833323955536\n",
      "Valid -> Loss: 0.060360673815012 Acc: 0.591000030438105\n",
      "Epoch: 26240/30000-------------------------------------------\n",
      "Train -> Loss: 0.027203630656004 Acc: 0.834666669368744\n",
      "Valid -> Loss: 0.060303855687380 Acc: 0.591333359479904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26250/30000-------------------------------------------\n",
      "Train -> Loss: 0.027197834104300 Acc: 0.834833323955536\n",
      "Valid -> Loss: 0.060369987040758 Acc: 0.590000043312708\n",
      "Epoch: 26260/30000-------------------------------------------\n",
      "Train -> Loss: 0.027193965390325 Acc: 0.835666656494141\n",
      "Valid -> Loss: 0.060487665235996 Acc: 0.589333365360896\n",
      "Epoch: 26270/30000-------------------------------------------\n",
      "Train -> Loss: 0.027217686176300 Acc: 0.836166679859161\n",
      "Valid -> Loss: 0.060972279558579 Acc: 0.583833356698354\n",
      "Epoch: 26280/30000-------------------------------------------\n",
      "Train -> Loss: 0.029655426740646 Acc: 0.813333332538605\n",
      "Valid -> Loss: 0.065897212053339 Acc: 0.540500019987424\n",
      "Epoch: 26290/30000-------------------------------------------\n",
      "Train -> Loss: 0.027467293664813 Acc: 0.831166684627533\n",
      "Valid -> Loss: 0.059364695101976 Acc: 0.606166700522105\n",
      "Epoch: 26300/30000-------------------------------------------\n",
      "Train -> Loss: 0.027470741420984 Acc: 0.834666669368744\n",
      "Valid -> Loss: 0.059501983225346 Acc: 0.594833364089330\n",
      "Epoch: 26310/30000-------------------------------------------\n",
      "Train -> Loss: 0.027500545606017 Acc: 0.826333343982697\n",
      "Valid -> Loss: 0.059167265271147 Acc: 0.600500017404556\n",
      "Epoch: 26320/30000-------------------------------------------\n",
      "Train -> Loss: 0.027542956173420 Acc: 0.833166658878326\n",
      "Valid -> Loss: 0.059080027664701 Acc: 0.598000019788742\n",
      "Epoch: 26330/30000-------------------------------------------\n",
      "Train -> Loss: 0.030914720147848 Acc: 0.798500001430511\n",
      "Valid -> Loss: 0.056724883615971 Acc: 0.621166706085205\n",
      "Epoch: 26340/30000-------------------------------------------\n",
      "Train -> Loss: 0.027377530932426 Acc: 0.837333321571350\n",
      "Valid -> Loss: 0.059460473557313 Acc: 0.600333372751872\n",
      "Epoch: 26350/30000-------------------------------------------\n",
      "Train -> Loss: 0.027252539992332 Acc: 0.833833336830139\n",
      "Valid -> Loss: 0.060861694936951 Acc: 0.582000027100245\n",
      "Epoch: 26360/30000-------------------------------------------\n",
      "Train -> Loss: 0.027317360043526 Acc: 0.834166646003723\n",
      "Valid -> Loss: 0.060542101040483 Acc: 0.592000027497609\n",
      "Epoch: 26370/30000-------------------------------------------\n",
      "Train -> Loss: 0.028621248900890 Acc: 0.824333310127258\n",
      "Valid -> Loss: 0.064639767631888 Acc: 0.548833360274633\n",
      "Epoch: 26380/30000-------------------------------------------\n",
      "Train -> Loss: 0.027362706139684 Acc: 0.837166666984558\n",
      "Valid -> Loss: 0.060040370250742 Acc: 0.596166700124741\n",
      "Epoch: 26390/30000-------------------------------------------\n",
      "Train -> Loss: 0.027490034699440 Acc: 0.830999970436096\n",
      "Valid -> Loss: 0.059283307443062 Acc: 0.599166681369146\n",
      "Epoch: 26400/30000-------------------------------------------\n",
      "Train -> Loss: 0.027304906398058 Acc: 0.833666682243347\n",
      "Valid -> Loss: 0.059847656016548 Acc: 0.595000028610229\n",
      "Epoch: 26410/30000-------------------------------------------\n",
      "Train -> Loss: 0.027178883552551 Acc: 0.835500001907349\n",
      "Valid -> Loss: 0.060263273616632 Acc: 0.592000027497609\n",
      "Epoch: 26420/30000-------------------------------------------\n",
      "Train -> Loss: 0.027165694162250 Acc: 0.835666656494141\n",
      "Valid -> Loss: 0.060600602378448 Acc: 0.586833367745082\n",
      "Epoch: 26430/30000-------------------------------------------\n",
      "Train -> Loss: 0.027157492935658 Acc: 0.835833311080933\n",
      "Valid -> Loss: 0.060417382046580 Acc: 0.589833358923594\n",
      "Epoch: 26440/30000-------------------------------------------\n",
      "Train -> Loss: 0.027150884270668 Acc: 0.836499989032745\n",
      "Valid -> Loss: 0.060539715612928 Acc: 0.588833371798197\n",
      "Epoch: 26450/30000-------------------------------------------\n",
      "Train -> Loss: 0.027146641165018 Acc: 0.836166679859161\n",
      "Valid -> Loss: 0.060534887636701 Acc: 0.588833361864090\n",
      "Epoch: 26460/30000-------------------------------------------\n",
      "Train -> Loss: 0.027156159281731 Acc: 0.835999965667725\n",
      "Valid -> Loss: 0.060881247743964 Acc: 0.585333357254664\n",
      "Epoch: 26470/30000-------------------------------------------\n",
      "Train -> Loss: 0.027809882536530 Acc: 0.828833341598511\n",
      "Valid -> Loss: 0.063206819817424 Acc: 0.564666698376338\n",
      "Epoch: 26480/30000-------------------------------------------\n",
      "Train -> Loss: 0.027887266129255 Acc: 0.819833338260651\n",
      "Valid -> Loss: 0.059852348019679 Acc: 0.589000026384989\n",
      "Epoch: 26490/30000-------------------------------------------\n",
      "Train -> Loss: 0.028019594028592 Acc: 0.824666678905487\n",
      "Valid -> Loss: 0.057760511214534 Acc: 0.613333364327749\n",
      "Epoch: 26500/30000-------------------------------------------\n",
      "Train -> Loss: 0.027235075831413 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.059616367643078 Acc: 0.596000035603841\n",
      "Epoch: 26510/30000-------------------------------------------\n",
      "Train -> Loss: 0.027193665504456 Acc: 0.831666648387909\n",
      "Valid -> Loss: 0.059484180683891 Acc: 0.598166694243749\n",
      "Epoch: 26520/30000-------------------------------------------\n",
      "Train -> Loss: 0.027146227657795 Acc: 0.833833336830139\n",
      "Valid -> Loss: 0.059678109983603 Acc: 0.596500009298325\n",
      "Epoch: 26530/30000-------------------------------------------\n",
      "Train -> Loss: 0.027142528444529 Acc: 0.836166679859161\n",
      "Valid -> Loss: 0.060439191137751 Acc: 0.589500029881795\n",
      "Epoch: 26540/30000-------------------------------------------\n",
      "Train -> Loss: 0.027130564674735 Acc: 0.835500001907349\n",
      "Valid -> Loss: 0.060060002530615 Acc: 0.593666702508926\n",
      "Epoch: 26550/30000-------------------------------------------\n",
      "Train -> Loss: 0.027122490108013 Acc: 0.836666643619537\n",
      "Valid -> Loss: 0.060374508301417 Acc: 0.589833368857702\n",
      "Epoch: 26560/30000-------------------------------------------\n",
      "Train -> Loss: 0.027118746191263 Acc: 0.836833298206329\n",
      "Valid -> Loss: 0.060430942103267 Acc: 0.589000026384989\n",
      "Epoch: 26570/30000-------------------------------------------\n",
      "Train -> Loss: 0.027119265869260 Acc: 0.836666643619537\n",
      "Valid -> Loss: 0.060592086985707 Acc: 0.587500025828679\n",
      "Epoch: 26580/30000-------------------------------------------\n",
      "Train -> Loss: 0.027355046942830 Acc: 0.834166646003723\n",
      "Valid -> Loss: 0.061961729700367 Acc: 0.576833367347717\n",
      "Epoch: 26590/30000-------------------------------------------\n",
      "Train -> Loss: 0.031917046755552 Acc: 0.797333300113678\n",
      "Valid -> Loss: 0.066196209440629 Acc: 0.536500031749407\n",
      "Epoch: 26600/30000-------------------------------------------\n",
      "Train -> Loss: 0.028856683522463 Acc: 0.825500011444092\n",
      "Valid -> Loss: 0.062604320545991 Acc: 0.572000016768773\n",
      "Epoch: 26610/30000-------------------------------------------\n",
      "Train -> Loss: 0.027420544996858 Acc: 0.831333339214325\n",
      "Valid -> Loss: 0.061262970169385 Acc: 0.579166690508525\n",
      "Epoch: 26620/30000-------------------------------------------\n",
      "Train -> Loss: 0.027350507676601 Acc: 0.832833349704742\n",
      "Valid -> Loss: 0.059741364171108 Acc: 0.594833364089330\n",
      "Epoch: 26630/30000-------------------------------------------\n",
      "Train -> Loss: 0.028286661952734 Acc: 0.834333300590515\n",
      "Valid -> Loss: 0.058005972454945 Acc: 0.607833365599314\n",
      "Epoch: 26640/30000-------------------------------------------\n",
      "Train -> Loss: 0.028915803879499 Acc: 0.815166652202606\n",
      "Valid -> Loss: 0.058468042562405 Acc: 0.604666690031687\n",
      "Epoch: 26650/30000-------------------------------------------\n",
      "Train -> Loss: 0.027203390374780 Acc: 0.838333308696747\n",
      "Valid -> Loss: 0.060205463320017 Acc: 0.596833368142446\n",
      "Epoch: 26660/30000-------------------------------------------\n",
      "Train -> Loss: 0.027289576828480 Acc: 0.833833336830139\n",
      "Valid -> Loss: 0.061559412007531 Acc: 0.576833367347717\n",
      "Epoch: 26670/30000-------------------------------------------\n",
      "Train -> Loss: 0.027182182297111 Acc: 0.838499963283539\n",
      "Valid -> Loss: 0.060364291692773 Acc: 0.593333353598913\n",
      "Epoch: 26680/30000-------------------------------------------\n",
      "Train -> Loss: 0.027111282572150 Acc: 0.835999965667725\n",
      "Valid -> Loss: 0.060571277514100 Acc: 0.586500028769175\n",
      "Epoch: 26690/30000-------------------------------------------\n",
      "Train -> Loss: 0.027102850377560 Acc: 0.834166646003723\n",
      "Valid -> Loss: 0.060236834610502 Acc: 0.592666705449422\n",
      "Epoch: 26700/30000-------------------------------------------\n",
      "Train -> Loss: 0.027092121541500 Acc: 0.836166679859161\n",
      "Valid -> Loss: 0.060340404510498 Acc: 0.590166707833608\n",
      "Epoch: 26710/30000-------------------------------------------\n",
      "Train -> Loss: 0.027083992958069 Acc: 0.835333347320557\n",
      "Valid -> Loss: 0.060332950825493 Acc: 0.591000020503998\n",
      "Epoch: 26720/30000-------------------------------------------\n",
      "Train -> Loss: 0.027077514678240 Acc: 0.835999965667725\n",
      "Valid -> Loss: 0.060398605341713 Acc: 0.589666684468587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26730/30000-------------------------------------------\n",
      "Train -> Loss: 0.027078822255135 Acc: 0.835333347320557\n",
      "Valid -> Loss: 0.060187102605899 Acc: 0.591666688521703\n",
      "Epoch: 26740/30000-------------------------------------------\n",
      "Train -> Loss: 0.027430860325694 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.058412780364354 Acc: 0.606166690587997\n",
      "Epoch: 26750/30000-------------------------------------------\n",
      "Train -> Loss: 0.059535905718803 Acc: 0.656833350658417\n",
      "Valid -> Loss: 0.056939472133915 Acc: 0.618500034014384\n",
      "Epoch: 26760/30000-------------------------------------------\n",
      "Train -> Loss: 0.053637459874153 Acc: 0.670333325862885\n",
      "Valid -> Loss: 0.064076213166118 Acc: 0.554000020027161\n",
      "Epoch: 26770/30000-------------------------------------------\n",
      "Train -> Loss: 0.036839302629232 Acc: 0.812333345413208\n",
      "Valid -> Loss: 0.050121271361907 Acc: 0.667833377917608\n",
      "Epoch: 26780/30000-------------------------------------------\n",
      "Train -> Loss: 0.030275546014309 Acc: 0.798166632652283\n",
      "Valid -> Loss: 0.052394457161427 Acc: 0.663166701793671\n",
      "Epoch: 26790/30000-------------------------------------------\n",
      "Train -> Loss: 0.028468078002334 Acc: 0.826833307743073\n",
      "Valid -> Loss: 0.057652714351813 Acc: 0.620333353678385\n",
      "Epoch: 26800/30000-------------------------------------------\n",
      "Train -> Loss: 0.027475811541080 Acc: 0.834833323955536\n",
      "Valid -> Loss: 0.059782608101765 Acc: 0.597500026226044\n",
      "Epoch: 26810/30000-------------------------------------------\n",
      "Train -> Loss: 0.027604198083282 Acc: 0.834166646003723\n",
      "Valid -> Loss: 0.057286601513624 Acc: 0.618500024080276\n",
      "Epoch: 26820/30000-------------------------------------------\n",
      "Train -> Loss: 0.027432292699814 Acc: 0.832166671752930\n",
      "Valid -> Loss: 0.060609408964713 Acc: 0.587000022331874\n",
      "Epoch: 26830/30000-------------------------------------------\n",
      "Train -> Loss: 0.027632858604193 Acc: 0.826833307743073\n",
      "Valid -> Loss: 0.058450801298022 Acc: 0.606833358605703\n",
      "Epoch: 26840/30000-------------------------------------------\n",
      "Train -> Loss: 0.027517409995198 Acc: 0.835500001907349\n",
      "Valid -> Loss: 0.059323217719793 Acc: 0.599500040213267\n",
      "Epoch: 26850/30000-------------------------------------------\n",
      "Train -> Loss: 0.027285680174828 Acc: 0.832166671752930\n",
      "Valid -> Loss: 0.058639528229833 Acc: 0.610500027736028\n",
      "Epoch: 26860/30000-------------------------------------------\n",
      "Train -> Loss: 0.029393782839179 Acc: 0.819833338260651\n",
      "Valid -> Loss: 0.060584982236226 Acc: 0.590000033378601\n",
      "Epoch: 26870/30000-------------------------------------------\n",
      "Train -> Loss: 0.032283153384924 Acc: 0.797666668891907\n",
      "Valid -> Loss: 0.054694872970382 Acc: 0.641500025987625\n",
      "Epoch: 26880/30000-------------------------------------------\n",
      "Train -> Loss: 0.028763495385647 Acc: 0.820666670799255\n",
      "Valid -> Loss: 0.063082018246253 Acc: 0.560500025749207\n",
      "Epoch: 26890/30000-------------------------------------------\n",
      "Train -> Loss: 0.027793487533927 Acc: 0.826666653156281\n",
      "Valid -> Loss: 0.057457248369853 Acc: 0.613666693369547\n",
      "Epoch: 26900/30000-------------------------------------------\n",
      "Train -> Loss: 0.027393180876970 Acc: 0.832166671752930\n",
      "Valid -> Loss: 0.059547218804558 Acc: 0.596000035603841\n",
      "Epoch: 26910/30000-------------------------------------------\n",
      "Train -> Loss: 0.027160149067640 Acc: 0.833166658878326\n",
      "Valid -> Loss: 0.059508637214700 Acc: 0.598666687806447\n",
      "Epoch: 26920/30000-------------------------------------------\n",
      "Train -> Loss: 0.027119327336550 Acc: 0.835833311080933\n",
      "Valid -> Loss: 0.059607623144984 Acc: 0.598833352327347\n",
      "Epoch: 26930/30000-------------------------------------------\n",
      "Train -> Loss: 0.027092656120658 Acc: 0.834666669368744\n",
      "Valid -> Loss: 0.059405716756980 Acc: 0.600166698296865\n",
      "Epoch: 26940/30000-------------------------------------------\n",
      "Train -> Loss: 0.027073809877038 Acc: 0.836833298206329\n",
      "Valid -> Loss: 0.059812221055230 Acc: 0.596500029166540\n",
      "Epoch: 26950/30000-------------------------------------------\n",
      "Train -> Loss: 0.027066266164184 Acc: 0.836833298206329\n",
      "Valid -> Loss: 0.059738701209426 Acc: 0.597000032663345\n",
      "Epoch: 26960/30000-------------------------------------------\n",
      "Train -> Loss: 0.027059610933065 Acc: 0.835999965667725\n",
      "Valid -> Loss: 0.059730103860299 Acc: 0.597000012795130\n",
      "Epoch: 26970/30000-------------------------------------------\n",
      "Train -> Loss: 0.027053982019424 Acc: 0.835999965667725\n",
      "Valid -> Loss: 0.059800206373135 Acc: 0.596166690190633\n",
      "Epoch: 26980/30000-------------------------------------------\n",
      "Train -> Loss: 0.027048891410232 Acc: 0.836499989032745\n",
      "Valid -> Loss: 0.059852303316196 Acc: 0.595666696627935\n",
      "Epoch: 26990/30000-------------------------------------------\n",
      "Train -> Loss: 0.027044229209423 Acc: 0.836833298206329\n",
      "Valid -> Loss: 0.059872642159462 Acc: 0.594833374023438\n",
      "Epoch: 27000/30000-------------------------------------------\n",
      "Train -> Loss: 0.027039803564548 Acc: 0.836833298206329\n",
      "Valid -> Loss: 0.059884088113904 Acc: 0.594833374023438\n",
      "Epoch: 27010/30000-------------------------------------------\n",
      "Train -> Loss: 0.027035571634769 Acc: 0.837000012397766\n",
      "Valid -> Loss: 0.059902694697181 Acc: 0.594000021616618\n",
      "Epoch: 27020/30000-------------------------------------------\n",
      "Train -> Loss: 0.027031484991312 Acc: 0.837166666984558\n",
      "Valid -> Loss: 0.059920849899451 Acc: 0.594166696071625\n",
      "Epoch: 27030/30000-------------------------------------------\n",
      "Train -> Loss: 0.027027519419789 Acc: 0.837166666984558\n",
      "Valid -> Loss: 0.059940110271176 Acc: 0.593666702508926\n",
      "Epoch: 27040/30000-------------------------------------------\n",
      "Train -> Loss: 0.027023645117879 Acc: 0.837166666984558\n",
      "Valid -> Loss: 0.059958567221959 Acc: 0.593666702508926\n",
      "Epoch: 27050/30000-------------------------------------------\n",
      "Train -> Loss: 0.027019850909710 Acc: 0.837166666984558\n",
      "Valid -> Loss: 0.059976379697522 Acc: 0.593666702508926\n",
      "Epoch: 27060/30000-------------------------------------------\n",
      "Train -> Loss: 0.027016121894121 Acc: 0.837166666984558\n",
      "Valid -> Loss: 0.059994488954544 Acc: 0.593166689078013\n",
      "Epoch: 27070/30000-------------------------------------------\n",
      "Train -> Loss: 0.027012443169951 Acc: 0.837166666984558\n",
      "Valid -> Loss: 0.060012366622686 Acc: 0.593166689078013\n",
      "Epoch: 27080/30000-------------------------------------------\n",
      "Train -> Loss: 0.027008809149265 Acc: 0.837333321571350\n",
      "Valid -> Loss: 0.060031079376737 Acc: 0.593166689078013\n",
      "Epoch: 27090/30000-------------------------------------------\n",
      "Train -> Loss: 0.027005210518837 Acc: 0.837333321571350\n",
      "Valid -> Loss: 0.060048109541337 Acc: 0.593000024557114\n",
      "Epoch: 27100/30000-------------------------------------------\n",
      "Train -> Loss: 0.027001639828086 Acc: 0.837499976158142\n",
      "Valid -> Loss: 0.060065087551872 Acc: 0.593000024557114\n",
      "Epoch: 27110/30000-------------------------------------------\n",
      "Train -> Loss: 0.026998095214367 Acc: 0.837499976158142\n",
      "Valid -> Loss: 0.060082324470083 Acc: 0.593000024557114\n",
      "Epoch: 27120/30000-------------------------------------------\n",
      "Train -> Loss: 0.026994569227099 Acc: 0.837666630744934\n",
      "Valid -> Loss: 0.060097433626652 Acc: 0.593000024557114\n",
      "Epoch: 27130/30000-------------------------------------------\n",
      "Train -> Loss: 0.026991061866283 Acc: 0.837999999523163\n",
      "Valid -> Loss: 0.060114355757833 Acc: 0.592666695515315\n",
      "Epoch: 27140/30000-------------------------------------------\n",
      "Train -> Loss: 0.026987565681338 Acc: 0.837999999523163\n",
      "Valid -> Loss: 0.060131838545203 Acc: 0.592500030994415\n",
      "Epoch: 27150/30000-------------------------------------------\n",
      "Train -> Loss: 0.026984076946974 Acc: 0.838333308696747\n",
      "Valid -> Loss: 0.060147020965815 Acc: 0.592166692018509\n",
      "Epoch: 27160/30000-------------------------------------------\n",
      "Train -> Loss: 0.026980595663190 Acc: 0.838499963283539\n",
      "Valid -> Loss: 0.060158137852947 Acc: 0.591500033934911\n",
      "Epoch: 27170/30000-------------------------------------------\n",
      "Train -> Loss: 0.026977222412825 Acc: 0.838333308696747\n",
      "Valid -> Loss: 0.060144285981854 Acc: 0.591666698455811\n",
      "Epoch: 27180/30000-------------------------------------------\n",
      "Train -> Loss: 0.026986695826054 Acc: 0.836666643619537\n",
      "Valid -> Loss: 0.059800211340189 Acc: 0.595166703065236\n",
      "Epoch: 27190/30000-------------------------------------------\n",
      "Train -> Loss: 0.029185255989432 Acc: 0.809166669845581\n",
      "Valid -> Loss: 0.055745830759406 Acc: 0.631833354632060\n",
      "Epoch: 27200/30000-------------------------------------------\n",
      "Train -> Loss: 0.030122969299555 Acc: 0.813666641712189\n",
      "Valid -> Loss: 0.064371336251497 Acc: 0.551000028848648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27210/30000-------------------------------------------\n",
      "Train -> Loss: 0.030020508915186 Acc: 0.808333337306976\n",
      "Valid -> Loss: 0.061004146933556 Acc: 0.588166693846385\n",
      "Epoch: 27220/30000-------------------------------------------\n",
      "Train -> Loss: 0.027316885069013 Acc: 0.832499980926514\n",
      "Valid -> Loss: 0.057154451807340 Acc: 0.616333345572154\n",
      "Epoch: 27230/30000-------------------------------------------\n",
      "Train -> Loss: 0.028420114889741 Acc: 0.814833343029022\n",
      "Valid -> Loss: 0.058251703158021 Acc: 0.607166697581609\n",
      "Epoch: 27240/30000-------------------------------------------\n",
      "Train -> Loss: 0.027167592197657 Acc: 0.834333300590515\n",
      "Valid -> Loss: 0.060993662104011 Acc: 0.586333354314168\n",
      "Epoch: 27250/30000-------------------------------------------\n",
      "Train -> Loss: 0.027379792183638 Acc: 0.835833311080933\n",
      "Valid -> Loss: 0.061106274525325 Acc: 0.580833365519842\n",
      "Epoch: 27260/30000-------------------------------------------\n",
      "Train -> Loss: 0.027714377269149 Acc: 0.834500014781952\n",
      "Valid -> Loss: 0.061015829443932 Acc: 0.580833365519842\n",
      "Epoch: 27270/30000-------------------------------------------\n",
      "Train -> Loss: 0.027756579220295 Acc: 0.829833328723907\n",
      "Valid -> Loss: 0.059221886719267 Acc: 0.600500017404556\n",
      "Epoch: 27280/30000-------------------------------------------\n",
      "Train -> Loss: 0.029288899153471 Acc: 0.829833328723907\n",
      "Valid -> Loss: 0.055315742269158 Acc: 0.636166691780090\n",
      "Epoch: 27290/30000-------------------------------------------\n",
      "Train -> Loss: 0.028182897716761 Acc: 0.818499982357025\n",
      "Valid -> Loss: 0.059048925836881 Acc: 0.598333358764648\n",
      "Epoch: 27300/30000-------------------------------------------\n",
      "Train -> Loss: 0.027966896072030 Acc: 0.828333318233490\n",
      "Valid -> Loss: 0.060925224175056 Acc: 0.582500020662943\n",
      "Epoch: 27310/30000-------------------------------------------\n",
      "Train -> Loss: 0.027137966826558 Acc: 0.838166654109955\n",
      "Valid -> Loss: 0.058285592123866 Acc: 0.614833374818166\n",
      "Epoch: 27320/30000-------------------------------------------\n",
      "Train -> Loss: 0.027098681777716 Acc: 0.837499976158142\n",
      "Valid -> Loss: 0.060222359374166 Acc: 0.594666689634323\n",
      "Epoch: 27330/30000-------------------------------------------\n",
      "Train -> Loss: 0.027156168594956 Acc: 0.835666656494141\n",
      "Valid -> Loss: 0.060658005376657 Acc: 0.586833357810974\n",
      "Epoch: 27340/30000-------------------------------------------\n",
      "Train -> Loss: 0.027102768421173 Acc: 0.838833332061768\n",
      "Valid -> Loss: 0.060251985987027 Acc: 0.590000033378601\n",
      "Epoch: 27350/30000-------------------------------------------\n",
      "Train -> Loss: 0.026994926854968 Acc: 0.839666664600372\n",
      "Valid -> Loss: 0.059432823210955 Acc: 0.601166695356369\n",
      "Epoch: 27360/30000-------------------------------------------\n",
      "Train -> Loss: 0.027076149359345 Acc: 0.835500001907349\n",
      "Valid -> Loss: 0.058360269914071 Acc: 0.606833358605703\n",
      "Epoch: 27370/30000-------------------------------------------\n",
      "Train -> Loss: 0.027080552652478 Acc: 0.834166646003723\n",
      "Valid -> Loss: 0.059260509908199 Acc: 0.600666691859563\n",
      "Epoch: 27380/30000-------------------------------------------\n",
      "Train -> Loss: 0.026981865987182 Acc: 0.834999978542328\n",
      "Valid -> Loss: 0.059523484980067 Acc: 0.598500023285548\n",
      "Epoch: 27390/30000-------------------------------------------\n",
      "Train -> Loss: 0.026935297995806 Acc: 0.837333321571350\n",
      "Valid -> Loss: 0.059952874978383 Acc: 0.593333363533020\n",
      "Epoch: 27400/30000-------------------------------------------\n",
      "Train -> Loss: 0.026935359463096 Acc: 0.839666664600372\n",
      "Valid -> Loss: 0.060330986355742 Acc: 0.590500017007192\n",
      "Epoch: 27410/30000-------------------------------------------\n",
      "Train -> Loss: 0.026924073696136 Acc: 0.838166654109955\n",
      "Valid -> Loss: 0.060383095095555 Acc: 0.590000023444494\n",
      "Epoch: 27420/30000-------------------------------------------\n",
      "Train -> Loss: 0.026920089498162 Acc: 0.837999999523163\n",
      "Valid -> Loss: 0.060186790923278 Acc: 0.591833372910818\n",
      "Epoch: 27430/30000-------------------------------------------\n",
      "Train -> Loss: 0.026915092021227 Acc: 0.839666664600372\n",
      "Valid -> Loss: 0.060380366941293 Acc: 0.590000033378601\n",
      "Epoch: 27440/30000-------------------------------------------\n",
      "Train -> Loss: 0.026910327374935 Acc: 0.838666677474976\n",
      "Valid -> Loss: 0.060291777675351 Acc: 0.591166694959005\n",
      "Epoch: 27450/30000-------------------------------------------\n",
      "Train -> Loss: 0.026905883103609 Acc: 0.838833332061768\n",
      "Valid -> Loss: 0.060346065089107 Acc: 0.590666701396306\n",
      "Epoch: 27460/30000-------------------------------------------\n",
      "Train -> Loss: 0.026901684701443 Acc: 0.839333295822144\n",
      "Valid -> Loss: 0.060390594104926 Acc: 0.590333362420400\n",
      "Epoch: 27470/30000-------------------------------------------\n",
      "Train -> Loss: 0.026898164302111 Acc: 0.839666664600372\n",
      "Valid -> Loss: 0.060469077279170 Acc: 0.590166687965393\n",
      "Epoch: 27480/30000-------------------------------------------\n",
      "Train -> Loss: 0.026942668482661 Acc: 0.839333295822144\n",
      "Valid -> Loss: 0.061134702215592 Acc: 0.584500034650167\n",
      "Epoch: 27490/30000-------------------------------------------\n",
      "Train -> Loss: 0.032381124794483 Acc: 0.793166637420654\n",
      "Valid -> Loss: 0.067708523944020 Acc: 0.528333360950152\n",
      "Epoch: 27500/30000-------------------------------------------\n",
      "Train -> Loss: 0.028059322386980 Acc: 0.840833306312561\n",
      "Valid -> Loss: 0.061036091918747 Acc: 0.579333364963531\n",
      "Epoch: 27510/30000-------------------------------------------\n",
      "Train -> Loss: 0.027503740042448 Acc: 0.834999978542328\n",
      "Valid -> Loss: 0.059616268302004 Acc: 0.592666695515315\n",
      "Epoch: 27520/30000-------------------------------------------\n",
      "Train -> Loss: 0.027013914659619 Acc: 0.840666651725769\n",
      "Valid -> Loss: 0.058346704269449 Acc: 0.612833360830943\n",
      "Epoch: 27530/30000-------------------------------------------\n",
      "Train -> Loss: 0.027059355750680 Acc: 0.833499968051910\n",
      "Valid -> Loss: 0.059952792401115 Acc: 0.588666697343191\n",
      "Epoch: 27540/30000-------------------------------------------\n",
      "Train -> Loss: 0.027003850787878 Acc: 0.840333342552185\n",
      "Valid -> Loss: 0.060447951157888 Acc: 0.594833364089330\n",
      "Epoch: 27550/30000-------------------------------------------\n",
      "Train -> Loss: 0.027115702629089 Acc: 0.836666643619537\n",
      "Valid -> Loss: 0.061232371255755 Acc: 0.581833352645238\n",
      "Epoch: 27560/30000-------------------------------------------\n",
      "Train -> Loss: 0.027078155428171 Acc: 0.837000012397766\n",
      "Valid -> Loss: 0.060359536359708 Acc: 0.590000033378601\n",
      "Epoch: 27570/30000-------------------------------------------\n",
      "Train -> Loss: 0.027199909090996 Acc: 0.839666664600372\n",
      "Valid -> Loss: 0.059888141850630 Acc: 0.593000034491221\n",
      "Epoch: 27580/30000-------------------------------------------\n",
      "Train -> Loss: 0.030346019193530 Acc: 0.802999973297119\n",
      "Valid -> Loss: 0.057188630724947 Acc: 0.617500027020772\n",
      "Epoch: 27590/30000-------------------------------------------\n",
      "Train -> Loss: 0.027188276872039 Acc: 0.842333316802979\n",
      "Valid -> Loss: 0.059435896575451 Acc: 0.600000013907750\n",
      "Epoch: 27600/30000-------------------------------------------\n",
      "Train -> Loss: 0.026922393590212 Acc: 0.839166641235352\n",
      "Valid -> Loss: 0.060513429964582 Acc: 0.586666693290075\n",
      "Epoch: 27610/30000-------------------------------------------\n",
      "Train -> Loss: 0.026890298351645 Acc: 0.839166641235352\n",
      "Valid -> Loss: 0.060025937855244 Acc: 0.597666690746943\n",
      "Epoch: 27620/30000-------------------------------------------\n",
      "Train -> Loss: 0.026881495490670 Acc: 0.840166628360748\n",
      "Valid -> Loss: 0.060522355139256 Acc: 0.587666690349579\n",
      "Epoch: 27630/30000-------------------------------------------\n",
      "Train -> Loss: 0.026870222762227 Acc: 0.841499984264374\n",
      "Valid -> Loss: 0.060294320806861 Acc: 0.592500021060308\n",
      "Epoch: 27640/30000-------------------------------------------\n",
      "Train -> Loss: 0.026860477402806 Acc: 0.839666664600372\n",
      "Valid -> Loss: 0.060517947499951 Acc: 0.589500019947688\n",
      "Epoch: 27650/30000-------------------------------------------\n",
      "Train -> Loss: 0.026852723211050 Acc: 0.841166675090790\n",
      "Valid -> Loss: 0.060326598584652 Acc: 0.591500014066696\n",
      "Epoch: 27660/30000-------------------------------------------\n",
      "Train -> Loss: 0.026846321299672 Acc: 0.839333295822144\n",
      "Valid -> Loss: 0.060357846319675 Acc: 0.591166685024897\n",
      "Epoch: 27670/30000-------------------------------------------\n",
      "Train -> Loss: 0.026842731982470 Acc: 0.839500010013580\n",
      "Valid -> Loss: 0.060252176597714 Acc: 0.592166692018509\n",
      "Epoch: 27680/30000-------------------------------------------\n",
      "Train -> Loss: 0.026898561045527 Acc: 0.836166679859161\n",
      "Valid -> Loss: 0.059612219532331 Acc: 0.598000039656957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27690/30000-------------------------------------------\n",
      "Train -> Loss: 0.030332952737808 Acc: 0.806666672229767\n",
      "Valid -> Loss: 0.055050954843561 Acc: 0.636000027259191\n",
      "Epoch: 27700/30000-------------------------------------------\n",
      "Train -> Loss: 0.033885993063450 Acc: 0.773499965667725\n",
      "Valid -> Loss: 0.054756988460819 Acc: 0.640666693449020\n",
      "Epoch: 27710/30000-------------------------------------------\n",
      "Train -> Loss: 0.028579493984580 Acc: 0.819499969482422\n",
      "Valid -> Loss: 0.056989068165421 Acc: 0.618166695038478\n",
      "Epoch: 27720/30000-------------------------------------------\n",
      "Train -> Loss: 0.033008676022291 Acc: 0.781499981880188\n",
      "Valid -> Loss: 0.057172828043501 Acc: 0.621333360671997\n",
      "Epoch: 27730/30000-------------------------------------------\n",
      "Train -> Loss: 0.030737295746803 Acc: 0.798666656017303\n",
      "Valid -> Loss: 0.066851055870454 Acc: 0.540166690945625\n",
      "Epoch: 27740/30000-------------------------------------------\n",
      "Train -> Loss: 0.031166294589639 Acc: 0.793999969959259\n",
      "Valid -> Loss: 0.061307013034821 Acc: 0.582166701555252\n",
      "Epoch: 27750/30000-------------------------------------------\n",
      "Train -> Loss: 0.029379773885012 Acc: 0.821666657924652\n",
      "Valid -> Loss: 0.057382114852468 Acc: 0.610500027736028\n",
      "Epoch: 27760/30000-------------------------------------------\n",
      "Train -> Loss: 0.030967168509960 Acc: 0.807999968528748\n",
      "Valid -> Loss: 0.061463262264927 Acc: 0.574666698773702\n",
      "Epoch: 27770/30000-------------------------------------------\n",
      "Train -> Loss: 0.030618619173765 Acc: 0.799666643142700\n",
      "Valid -> Loss: 0.059423820426067 Acc: 0.592333366473516\n",
      "Epoch: 27780/30000-------------------------------------------\n",
      "Train -> Loss: 0.028128417208791 Acc: 0.834166646003723\n",
      "Valid -> Loss: 0.056356669714053 Acc: 0.623000025749207\n",
      "Epoch: 27790/30000-------------------------------------------\n",
      "Train -> Loss: 0.027320981025696 Acc: 0.839500010013580\n",
      "Valid -> Loss: 0.061419334883491 Acc: 0.579000035921733\n",
      "Epoch: 27800/30000-------------------------------------------\n",
      "Train -> Loss: 0.027178104966879 Acc: 0.830500006675720\n",
      "Valid -> Loss: 0.058839953194062 Acc: 0.602500031391780\n",
      "Epoch: 27810/30000-------------------------------------------\n",
      "Train -> Loss: 0.026978081092238 Acc: 0.839666664600372\n",
      "Valid -> Loss: 0.059634037936727 Acc: 0.598833362261454\n",
      "Epoch: 27820/30000-------------------------------------------\n",
      "Train -> Loss: 0.026895308867097 Acc: 0.836666643619537\n",
      "Valid -> Loss: 0.059548601508141 Acc: 0.600333362817764\n",
      "Epoch: 27830/30000-------------------------------------------\n",
      "Train -> Loss: 0.026880763471127 Acc: 0.840333342552185\n",
      "Valid -> Loss: 0.060173301647107 Acc: 0.593000024557114\n",
      "Epoch: 27840/30000-------------------------------------------\n",
      "Train -> Loss: 0.026841714978218 Acc: 0.838833332061768\n",
      "Valid -> Loss: 0.059877437228958 Acc: 0.593833347161611\n",
      "Epoch: 27850/30000-------------------------------------------\n",
      "Train -> Loss: 0.026833729818463 Acc: 0.838833332061768\n",
      "Valid -> Loss: 0.060044561202327 Acc: 0.593000014623006\n",
      "Epoch: 27860/30000-------------------------------------------\n",
      "Train -> Loss: 0.026824828237295 Acc: 0.839166641235352\n",
      "Valid -> Loss: 0.060177880028884 Acc: 0.592166692018509\n",
      "Epoch: 27870/30000-------------------------------------------\n",
      "Train -> Loss: 0.026817789301276 Acc: 0.839833319187164\n",
      "Valid -> Loss: 0.060182695587476 Acc: 0.591666698455811\n",
      "Epoch: 27880/30000-------------------------------------------\n",
      "Train -> Loss: 0.026811366900802 Acc: 0.839833319187164\n",
      "Valid -> Loss: 0.060157140096029 Acc: 0.592333356539408\n",
      "Epoch: 27890/30000-------------------------------------------\n",
      "Train -> Loss: 0.026805741712451 Acc: 0.839999973773956\n",
      "Valid -> Loss: 0.060179904724161 Acc: 0.591666688521703\n",
      "Epoch: 27900/30000-------------------------------------------\n",
      "Train -> Loss: 0.026800509542227 Acc: 0.840666651725769\n",
      "Valid -> Loss: 0.060205427308877 Acc: 0.591500014066696\n",
      "Epoch: 27910/30000-------------------------------------------\n",
      "Train -> Loss: 0.026795564219356 Acc: 0.841000020503998\n",
      "Valid -> Loss: 0.060228986665606 Acc: 0.590833346048991\n",
      "Epoch: 27920/30000-------------------------------------------\n",
      "Train -> Loss: 0.026790848001838 Acc: 0.840833306312561\n",
      "Valid -> Loss: 0.060254900405804 Acc: 0.590833346048991\n",
      "Epoch: 27930/30000-------------------------------------------\n",
      "Train -> Loss: 0.026786318048835 Acc: 0.841000020503998\n",
      "Valid -> Loss: 0.060275601843993 Acc: 0.591166685024897\n",
      "Epoch: 27940/30000-------------------------------------------\n",
      "Train -> Loss: 0.026781938970089 Acc: 0.841000020503998\n",
      "Valid -> Loss: 0.060297766700387 Acc: 0.591000020503998\n",
      "Epoch: 27950/30000-------------------------------------------\n",
      "Train -> Loss: 0.026777684688568 Acc: 0.841166675090790\n",
      "Valid -> Loss: 0.060315687830249 Acc: 0.591166685024897\n",
      "Epoch: 27960/30000-------------------------------------------\n",
      "Train -> Loss: 0.026773538440466 Acc: 0.841166675090790\n",
      "Valid -> Loss: 0.060330948481957 Acc: 0.591333349545797\n",
      "Epoch: 27970/30000-------------------------------------------\n",
      "Train -> Loss: 0.026769489049911 Acc: 0.841333329677582\n",
      "Valid -> Loss: 0.060348960881432 Acc: 0.591333359479904\n",
      "Epoch: 27980/30000-------------------------------------------\n",
      "Train -> Loss: 0.026765525341034 Acc: 0.841499984264374\n",
      "Valid -> Loss: 0.060364622001847 Acc: 0.591500033934911\n",
      "Epoch: 27990/30000-------------------------------------------\n",
      "Train -> Loss: 0.026761636137962 Acc: 0.841499984264374\n",
      "Valid -> Loss: 0.060379755993684 Acc: 0.591333359479904\n",
      "Epoch: 28000/30000-------------------------------------------\n",
      "Train -> Loss: 0.026757823303342 Acc: 0.841499984264374\n",
      "Valid -> Loss: 0.060393317292134 Acc: 0.590500026941299\n",
      "Epoch: 28010/30000-------------------------------------------\n",
      "Train -> Loss: 0.026754070073366 Acc: 0.841499984264374\n",
      "Valid -> Loss: 0.060406970481078 Acc: 0.590500026941299\n",
      "Epoch: 28020/30000-------------------------------------------\n",
      "Train -> Loss: 0.026750374585390 Acc: 0.841499984264374\n",
      "Valid -> Loss: 0.060418851673603 Acc: 0.590333372354507\n",
      "Epoch: 28030/30000-------------------------------------------\n",
      "Train -> Loss: 0.026746727526188 Acc: 0.841499984264374\n",
      "Valid -> Loss: 0.060431404660145 Acc: 0.590333372354507\n",
      "Epoch: 28040/30000-------------------------------------------\n",
      "Train -> Loss: 0.026743136346340 Acc: 0.841666638851166\n",
      "Valid -> Loss: 0.060450228552024 Acc: 0.590166697899500\n",
      "Epoch: 28050/30000-------------------------------------------\n",
      "Train -> Loss: 0.026740489527583 Acc: 0.842166662216187\n",
      "Valid -> Loss: 0.060551101341844 Acc: 0.588833361864090\n",
      "Epoch: 28060/30000-------------------------------------------\n",
      "Train -> Loss: 0.026953836902976 Acc: 0.839166641235352\n",
      "Valid -> Loss: 0.062056165809433 Acc: 0.576500028371811\n",
      "Epoch: 28070/30000-------------------------------------------\n",
      "Train -> Loss: 0.027959095314145 Acc: 0.826666653156281\n",
      "Valid -> Loss: 0.058892674744129 Acc: 0.600833356380463\n",
      "Epoch: 28080/30000-------------------------------------------\n",
      "Train -> Loss: 0.027838798239827 Acc: 0.843166649341583\n",
      "Valid -> Loss: 0.054367993647854 Acc: 0.645500024159749\n",
      "Epoch: 28090/30000-------------------------------------------\n",
      "Train -> Loss: 0.033671785145998 Acc: 0.780333340167999\n",
      "Valid -> Loss: 0.057639674594005 Acc: 0.609500040610631\n",
      "Epoch: 28100/30000-------------------------------------------\n",
      "Train -> Loss: 0.029674410820007 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.062317339703441 Acc: 0.572333355744680\n",
      "Epoch: 28110/30000-------------------------------------------\n",
      "Train -> Loss: 0.027883162721992 Acc: 0.819999992847443\n",
      "Valid -> Loss: 0.055674376587073 Acc: 0.637833356857300\n",
      "Epoch: 28120/30000-------------------------------------------\n",
      "Train -> Loss: 0.030000500380993 Acc: 0.805166661739349\n",
      "Valid -> Loss: 0.064960122108459 Acc: 0.559500018755595\n",
      "Epoch: 28130/30000-------------------------------------------\n",
      "Train -> Loss: 0.030205294489861 Acc: 0.825166642665863\n",
      "Valid -> Loss: 0.054959343746305 Acc: 0.641000032424927\n",
      "Epoch: 28140/30000-------------------------------------------\n",
      "Train -> Loss: 0.028148392215371 Acc: 0.837999999523163\n",
      "Valid -> Loss: 0.058247023572524 Acc: 0.605833351612091\n",
      "Epoch: 28150/30000-------------------------------------------\n",
      "Train -> Loss: 0.028614271432161 Acc: 0.833666682243347\n",
      "Valid -> Loss: 0.057378386457761 Acc: 0.611833373705546\n",
      "Epoch: 28160/30000-------------------------------------------\n",
      "Train -> Loss: 0.028267415240407 Acc: 0.839500010013580\n",
      "Valid -> Loss: 0.057312463099758 Acc: 0.612666686375936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28170/30000-------------------------------------------\n",
      "Train -> Loss: 0.029303999617696 Acc: 0.834999978542328\n",
      "Valid -> Loss: 0.057337629919251 Acc: 0.611500034729640\n",
      "Epoch: 28180/30000-------------------------------------------\n",
      "Train -> Loss: 0.028082713484764 Acc: 0.829500019550323\n",
      "Valid -> Loss: 0.063274560496211 Acc: 0.562166690826416\n",
      "Epoch: 28190/30000-------------------------------------------\n",
      "Train -> Loss: 0.027391342446208 Acc: 0.833499968051910\n",
      "Valid -> Loss: 0.057416362067064 Acc: 0.614833364884059\n",
      "Epoch: 28200/30000-------------------------------------------\n",
      "Train -> Loss: 0.027060428634286 Acc: 0.838499963283539\n",
      "Valid -> Loss: 0.060629789407055 Acc: 0.589666694402695\n",
      "Epoch: 28210/30000-------------------------------------------\n",
      "Train -> Loss: 0.026907661929727 Acc: 0.838166654109955\n",
      "Valid -> Loss: 0.059025397524238 Acc: 0.601666698853175\n",
      "Epoch: 28220/30000-------------------------------------------\n",
      "Train -> Loss: 0.026796638965607 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.060349391773343 Acc: 0.590666681528091\n",
      "Epoch: 28230/30000-------------------------------------------\n",
      "Train -> Loss: 0.026761597022414 Acc: 0.841333329677582\n",
      "Valid -> Loss: 0.059844787543019 Acc: 0.594333360592524\n",
      "Epoch: 28240/30000-------------------------------------------\n",
      "Train -> Loss: 0.026753529906273 Acc: 0.839833319187164\n",
      "Valid -> Loss: 0.059965904181202 Acc: 0.594166696071625\n",
      "Epoch: 28250/30000-------------------------------------------\n",
      "Train -> Loss: 0.026738774031401 Acc: 0.841833353042603\n",
      "Valid -> Loss: 0.060172393918037 Acc: 0.593833367029826\n",
      "Epoch: 28260/30000-------------------------------------------\n",
      "Train -> Loss: 0.026731694117188 Acc: 0.843333303928375\n",
      "Valid -> Loss: 0.060191476096710 Acc: 0.592500011126200\n",
      "Epoch: 28270/30000-------------------------------------------\n",
      "Train -> Loss: 0.026724224910140 Acc: 0.842499971389771\n",
      "Valid -> Loss: 0.060179859399796 Acc: 0.592333346605301\n",
      "Epoch: 28280/30000-------------------------------------------\n",
      "Train -> Loss: 0.026718188077211 Acc: 0.842499971389771\n",
      "Valid -> Loss: 0.060177260388931 Acc: 0.592666695515315\n",
      "Epoch: 28290/30000-------------------------------------------\n",
      "Train -> Loss: 0.026712823659182 Acc: 0.842666685581207\n",
      "Valid -> Loss: 0.060202484329542 Acc: 0.592333356539408\n",
      "Epoch: 28300/30000-------------------------------------------\n",
      "Train -> Loss: 0.026707835495472 Acc: 0.842499971389771\n",
      "Valid -> Loss: 0.060227978353699 Acc: 0.592666695515315\n",
      "Epoch: 28310/30000-------------------------------------------\n",
      "Train -> Loss: 0.026703145354986 Acc: 0.842833340167999\n",
      "Valid -> Loss: 0.060246889789899 Acc: 0.592833360036214\n",
      "Epoch: 28320/30000-------------------------------------------\n",
      "Train -> Loss: 0.026698686182499 Acc: 0.842833340167999\n",
      "Valid -> Loss: 0.060269199311733 Acc: 0.592666695515315\n",
      "Epoch: 28330/30000-------------------------------------------\n",
      "Train -> Loss: 0.026694409549236 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.060286449268460 Acc: 0.592166692018509\n",
      "Epoch: 28340/30000-------------------------------------------\n",
      "Train -> Loss: 0.026690283790231 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.060300882284840 Acc: 0.591333359479904\n",
      "Epoch: 28350/30000-------------------------------------------\n",
      "Train -> Loss: 0.026686290279031 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.060314400742451 Acc: 0.591000030438105\n",
      "Epoch: 28360/30000-------------------------------------------\n",
      "Train -> Loss: 0.026682406663895 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.060327759633462 Acc: 0.591166694959005\n",
      "Epoch: 28370/30000-------------------------------------------\n",
      "Train -> Loss: 0.026678619906306 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.060340640445550 Acc: 0.591166694959005\n",
      "Epoch: 28380/30000-------------------------------------------\n",
      "Train -> Loss: 0.026674913242459 Acc: 0.843166649341583\n",
      "Valid -> Loss: 0.060350100820263 Acc: 0.591166694959005\n",
      "Epoch: 28390/30000-------------------------------------------\n",
      "Train -> Loss: 0.026671268045902 Acc: 0.843333303928375\n",
      "Valid -> Loss: 0.060360686232646 Acc: 0.591166694959005\n",
      "Epoch: 28400/30000-------------------------------------------\n",
      "Train -> Loss: 0.026667682453990 Acc: 0.843166649341583\n",
      "Valid -> Loss: 0.060371249293288 Acc: 0.590666691462199\n",
      "Epoch: 28410/30000-------------------------------------------\n",
      "Train -> Loss: 0.026664143428206 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.060381062949697 Acc: 0.590666691462199\n",
      "Epoch: 28420/30000-------------------------------------------\n",
      "Train -> Loss: 0.026660639792681 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.060389431814353 Acc: 0.590500026941299\n",
      "Epoch: 28430/30000-------------------------------------------\n",
      "Train -> Loss: 0.026657177135348 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.060403892770410 Acc: 0.590666691462199\n",
      "Epoch: 28440/30000-------------------------------------------\n",
      "Train -> Loss: 0.026654124259949 Acc: 0.843500018119812\n",
      "Valid -> Loss: 0.060468113670746 Acc: 0.589666694402695\n",
      "Epoch: 28450/30000-------------------------------------------\n",
      "Train -> Loss: 0.026713719591498 Acc: 0.843166649341583\n",
      "Valid -> Loss: 0.061275807519754 Acc: 0.584500034650167\n",
      "Epoch: 28460/30000-------------------------------------------\n",
      "Train -> Loss: 0.037629131227732 Acc: 0.765166640281677\n",
      "Valid -> Loss: 0.065912608057261 Acc: 0.540833353996277\n",
      "Epoch: 28470/30000-------------------------------------------\n",
      "Train -> Loss: 0.038627378642559 Acc: 0.761166632175446\n",
      "Valid -> Loss: 0.063074552764495 Acc: 0.559000035127004\n",
      "Epoch: 28480/30000-------------------------------------------\n",
      "Train -> Loss: 0.028631875291467 Acc: 0.821333348751068\n",
      "Valid -> Loss: 0.058706244453788 Acc: 0.608833372592926\n",
      "Epoch: 28490/30000-------------------------------------------\n",
      "Train -> Loss: 0.027452697977424 Acc: 0.835999965667725\n",
      "Valid -> Loss: 0.058129974951347 Acc: 0.606166680653890\n",
      "Epoch: 28500/30000-------------------------------------------\n",
      "Train -> Loss: 0.027097782120109 Acc: 0.830666661262512\n",
      "Valid -> Loss: 0.058337458719810 Acc: 0.614500015974045\n",
      "Epoch: 28510/30000-------------------------------------------\n",
      "Train -> Loss: 0.031224969774485 Acc: 0.799666643142700\n",
      "Valid -> Loss: 0.062508402392268 Acc: 0.569500039021174\n",
      "Epoch: 28520/30000-------------------------------------------\n",
      "Train -> Loss: 0.028160108253360 Acc: 0.838999986648560\n",
      "Valid -> Loss: 0.053809445351362 Acc: 0.650500029325485\n",
      "Epoch: 28530/30000-------------------------------------------\n",
      "Train -> Loss: 0.082207642495632 Acc: 0.555000007152557\n",
      "Valid -> Loss: 0.068070637683074 Acc: 0.561500022808711\n",
      "Epoch: 28540/30000-------------------------------------------\n",
      "Train -> Loss: 0.069784566760063 Acc: 0.559166669845581\n",
      "Valid -> Loss: 0.068179520467917 Acc: 0.564833362897237\n",
      "Epoch: 28550/30000-------------------------------------------\n",
      "Train -> Loss: 0.062165688723326 Acc: 0.648000001907349\n",
      "Valid -> Loss: 0.052633968492349 Acc: 0.644500037034353\n",
      "Epoch: 28560/30000-------------------------------------------\n",
      "Train -> Loss: 0.043778803199530 Acc: 0.740166664123535\n",
      "Valid -> Loss: 0.064535395552715 Acc: 0.533833364645640\n",
      "Epoch: 28570/30000-------------------------------------------\n",
      "Train -> Loss: 0.041831370443106 Acc: 0.754999995231628\n",
      "Valid -> Loss: 0.065454057107369 Acc: 0.608833372592926\n",
      "Epoch: 28580/30000-------------------------------------------\n",
      "Train -> Loss: 0.044511076062918 Acc: 0.720166683197021\n",
      "Valid -> Loss: 0.057241458445787 Acc: 0.622000038623810\n",
      "Epoch: 28590/30000-------------------------------------------\n",
      "Train -> Loss: 0.040896132588387 Acc: 0.772000014781952\n",
      "Valid -> Loss: 0.061092110350728 Acc: 0.598000019788742\n",
      "Epoch: 28600/30000-------------------------------------------\n",
      "Train -> Loss: 0.030630966648459 Acc: 0.819499969482422\n",
      "Valid -> Loss: 0.059392960121234 Acc: 0.602666685978572\n",
      "Epoch: 28610/30000-------------------------------------------\n",
      "Train -> Loss: 0.027875481173396 Acc: 0.828166663646698\n",
      "Valid -> Loss: 0.054761066411932 Acc: 0.633000036080678\n",
      "Epoch: 28620/30000-------------------------------------------\n",
      "Train -> Loss: 0.027511822059751 Acc: 0.834500014781952\n",
      "Valid -> Loss: 0.056898412605127 Acc: 0.624666700760523\n",
      "Epoch: 28630/30000-------------------------------------------\n",
      "Train -> Loss: 0.027271568775177 Acc: 0.835833311080933\n",
      "Valid -> Loss: 0.057754408568144 Acc: 0.613333374261856\n",
      "Epoch: 28640/30000-------------------------------------------\n",
      "Train -> Loss: 0.026999318972230 Acc: 0.839666664600372\n",
      "Valid -> Loss: 0.058133822555343 Acc: 0.611500034729640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28650/30000-------------------------------------------\n",
      "Train -> Loss: 0.026929428800941 Acc: 0.838499963283539\n",
      "Valid -> Loss: 0.058053470527132 Acc: 0.613333364327749\n",
      "Epoch: 28660/30000-------------------------------------------\n",
      "Train -> Loss: 0.026872262358665 Acc: 0.839666664600372\n",
      "Valid -> Loss: 0.058089877168338 Acc: 0.612333357334137\n",
      "Epoch: 28670/30000-------------------------------------------\n",
      "Train -> Loss: 0.026836358010769 Acc: 0.841000020503998\n",
      "Valid -> Loss: 0.058132580171029 Acc: 0.612666706244151\n",
      "Epoch: 28680/30000-------------------------------------------\n",
      "Train -> Loss: 0.026808803901076 Acc: 0.841333329677582\n",
      "Valid -> Loss: 0.058192798867822 Acc: 0.611833373705546\n",
      "Epoch: 28690/30000-------------------------------------------\n",
      "Train -> Loss: 0.026785004884005 Acc: 0.841499984264374\n",
      "Valid -> Loss: 0.058287456631660 Acc: 0.611166705687841\n",
      "Epoch: 28700/30000-------------------------------------------\n",
      "Train -> Loss: 0.026764193549752 Acc: 0.842499971389771\n",
      "Valid -> Loss: 0.058410435914993 Acc: 0.610166698694229\n",
      "Epoch: 28710/30000-------------------------------------------\n",
      "Train -> Loss: 0.026746101677418 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.058516637732585 Acc: 0.609500030676524\n",
      "Epoch: 28720/30000-------------------------------------------\n",
      "Train -> Loss: 0.026730934157968 Acc: 0.842833340167999\n",
      "Valid -> Loss: 0.058576526741187 Acc: 0.609000027179718\n",
      "Epoch: 28730/30000-------------------------------------------\n",
      "Train -> Loss: 0.026718266308308 Acc: 0.842833340167999\n",
      "Valid -> Loss: 0.058624861761928 Acc: 0.608666688203812\n",
      "Epoch: 28740/30000-------------------------------------------\n",
      "Train -> Loss: 0.026707503944635 Acc: 0.843333303928375\n",
      "Valid -> Loss: 0.058678958564997 Acc: 0.607666701078415\n",
      "Epoch: 28750/30000-------------------------------------------\n",
      "Train -> Loss: 0.026698218658566 Acc: 0.843166649341583\n",
      "Valid -> Loss: 0.058720660085479 Acc: 0.607166687647502\n",
      "Epoch: 28760/30000-------------------------------------------\n",
      "Train -> Loss: 0.026690090075135 Acc: 0.843333303928375\n",
      "Valid -> Loss: 0.058754984289408 Acc: 0.606500019629796\n",
      "Epoch: 28770/30000-------------------------------------------\n",
      "Train -> Loss: 0.026682842522860 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.058790805439154 Acc: 0.606500019629796\n",
      "Epoch: 28780/30000-------------------------------------------\n",
      "Train -> Loss: 0.026676261797547 Acc: 0.844166636466980\n",
      "Valid -> Loss: 0.058821739628911 Acc: 0.606333355108897\n",
      "Epoch: 28790/30000-------------------------------------------\n",
      "Train -> Loss: 0.026670200750232 Acc: 0.844166636466980\n",
      "Valid -> Loss: 0.058850700656573 Acc: 0.606000026067098\n",
      "Epoch: 28800/30000-------------------------------------------\n",
      "Train -> Loss: 0.026664556935430 Acc: 0.843833327293396\n",
      "Valid -> Loss: 0.058878576382995 Acc: 0.606166690587997\n",
      "Epoch: 28810/30000-------------------------------------------\n",
      "Train -> Loss: 0.026659257709980 Acc: 0.843833327293396\n",
      "Valid -> Loss: 0.058904122561216 Acc: 0.606333355108897\n",
      "Epoch: 28820/30000-------------------------------------------\n",
      "Train -> Loss: 0.026654241606593 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.058928565432628 Acc: 0.605666697025299\n",
      "Epoch: 28830/30000-------------------------------------------\n",
      "Train -> Loss: 0.026649471372366 Acc: 0.843833327293396\n",
      "Valid -> Loss: 0.058952323471506 Acc: 0.605833361546198\n",
      "Epoch: 28840/30000-------------------------------------------\n",
      "Train -> Loss: 0.026644906029105 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.058974532410502 Acc: 0.606000026067098\n",
      "Epoch: 28850/30000-------------------------------------------\n",
      "Train -> Loss: 0.026640523225069 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.058996418491006 Acc: 0.606166690587997\n",
      "Epoch: 28860/30000-------------------------------------------\n",
      "Train -> Loss: 0.026636293157935 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.059016925593217 Acc: 0.605666697025299\n",
      "Epoch: 28870/30000-------------------------------------------\n",
      "Train -> Loss: 0.026632200926542 Acc: 0.843833327293396\n",
      "Valid -> Loss: 0.059038030604521 Acc: 0.605666697025299\n",
      "Epoch: 28880/30000-------------------------------------------\n",
      "Train -> Loss: 0.026628226041794 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.059056768193841 Acc: 0.605000029007594\n",
      "Epoch: 28890/30000-------------------------------------------\n",
      "Train -> Loss: 0.026624359190464 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.059076103071372 Acc: 0.604666699965795\n",
      "Epoch: 28900/30000-------------------------------------------\n",
      "Train -> Loss: 0.026620581746101 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.059094411010544 Acc: 0.604333370923996\n",
      "Epoch: 28910/30000-------------------------------------------\n",
      "Train -> Loss: 0.026616889983416 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.059112408508857 Acc: 0.604333370923996\n",
      "Epoch: 28920/30000-------------------------------------------\n",
      "Train -> Loss: 0.026613270863891 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.059129986291130 Acc: 0.604500035444895\n",
      "Epoch: 28930/30000-------------------------------------------\n",
      "Train -> Loss: 0.026609718799591 Acc: 0.843833327293396\n",
      "Valid -> Loss: 0.059146943812569 Acc: 0.604500025510788\n",
      "Epoch: 28940/30000-------------------------------------------\n",
      "Train -> Loss: 0.026606222614646 Acc: 0.843833327293396\n",
      "Valid -> Loss: 0.059163175523281 Acc: 0.604000031948090\n",
      "Epoch: 28950/30000-------------------------------------------\n",
      "Train -> Loss: 0.026602782309055 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.059179151430726 Acc: 0.603166709343592\n",
      "Epoch: 28960/30000-------------------------------------------\n",
      "Train -> Loss: 0.026599386706948 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.059195024892688 Acc: 0.603333373864492\n",
      "Epoch: 28970/30000-------------------------------------------\n",
      "Train -> Loss: 0.026596033945680 Acc: 0.844166636466980\n",
      "Valid -> Loss: 0.059210671111941 Acc: 0.603333373864492\n",
      "Epoch: 28980/30000-------------------------------------------\n",
      "Train -> Loss: 0.026592718437314 Acc: 0.844333350658417\n",
      "Valid -> Loss: 0.059225842977564 Acc: 0.602833360433578\n",
      "Epoch: 28990/30000-------------------------------------------\n",
      "Train -> Loss: 0.026589436456561 Acc: 0.844333350658417\n",
      "Valid -> Loss: 0.059240648522973 Acc: 0.602333356936773\n",
      "Epoch: 29000/30000-------------------------------------------\n",
      "Train -> Loss: 0.026586186140776 Acc: 0.844333350658417\n",
      "Valid -> Loss: 0.059255432958404 Acc: 0.602000017960866\n",
      "Epoch: 29010/30000-------------------------------------------\n",
      "Train -> Loss: 0.026582965627313 Acc: 0.844333350658417\n",
      "Valid -> Loss: 0.059269980837901 Acc: 0.602000017960866\n",
      "Epoch: 29020/30000-------------------------------------------\n",
      "Train -> Loss: 0.026579769328237 Acc: 0.844333350658417\n",
      "Valid -> Loss: 0.059284682696064 Acc: 0.601833353439967\n",
      "Epoch: 29030/30000-------------------------------------------\n",
      "Train -> Loss: 0.026576591655612 Acc: 0.844333350658417\n",
      "Valid -> Loss: 0.059298330297073 Acc: 0.601833353439967\n",
      "Epoch: 29040/30000-------------------------------------------\n",
      "Train -> Loss: 0.026573440060019 Acc: 0.844666659832001\n",
      "Valid -> Loss: 0.059312072892984 Acc: 0.601833353439967\n",
      "Epoch: 29050/30000-------------------------------------------\n",
      "Train -> Loss: 0.026570303365588 Acc: 0.844500005245209\n",
      "Valid -> Loss: 0.059324589247505 Acc: 0.601833353439967\n",
      "Epoch: 29060/30000-------------------------------------------\n",
      "Train -> Loss: 0.026567181572318 Acc: 0.844333350658417\n",
      "Valid -> Loss: 0.059337425976992 Acc: 0.601833353439967\n",
      "Epoch: 29070/30000-------------------------------------------\n",
      "Train -> Loss: 0.026564076542854 Acc: 0.844333350658417\n",
      "Valid -> Loss: 0.059350910286109 Acc: 0.601833353439967\n",
      "Epoch: 29080/30000-------------------------------------------\n",
      "Train -> Loss: 0.026560982689261 Acc: 0.844333350658417\n",
      "Valid -> Loss: 0.059362972776095 Acc: 0.601666688919067\n",
      "Epoch: 29090/30000-------------------------------------------\n",
      "Train -> Loss: 0.026557901874185 Acc: 0.844166636466980\n",
      "Valid -> Loss: 0.059375463674466 Acc: 0.600666691859563\n",
      "Epoch: 29100/30000-------------------------------------------\n",
      "Train -> Loss: 0.026554832234979 Acc: 0.844166636466980\n",
      "Valid -> Loss: 0.059388183057308 Acc: 0.600333352883657\n",
      "Epoch: 29110/30000-------------------------------------------\n",
      "Train -> Loss: 0.026551766321063 Acc: 0.844666659832001\n",
      "Valid -> Loss: 0.059400606900454 Acc: 0.600166688362757\n",
      "Epoch: 29120/30000-------------------------------------------\n",
      "Train -> Loss: 0.026548715308309 Acc: 0.844666659832001\n",
      "Valid -> Loss: 0.059412737066547 Acc: 0.600000013907750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29130/30000-------------------------------------------\n",
      "Train -> Loss: 0.026545668020844 Acc: 0.844833314418793\n",
      "Valid -> Loss: 0.059423735986153 Acc: 0.600166678428650\n",
      "Epoch: 29140/30000-------------------------------------------\n",
      "Train -> Loss: 0.026542624458671 Acc: 0.844833314418793\n",
      "Valid -> Loss: 0.059435028582811 Acc: 0.600000013907750\n",
      "Epoch: 29150/30000-------------------------------------------\n",
      "Train -> Loss: 0.026539588347077 Acc: 0.844833314418793\n",
      "Valid -> Loss: 0.059445179377993 Acc: 0.600000013907750\n",
      "Epoch: 29160/30000-------------------------------------------\n",
      "Train -> Loss: 0.026536567136645 Acc: 0.844833314418793\n",
      "Valid -> Loss: 0.059450140222907 Acc: 0.600166688362757\n",
      "Epoch: 29170/30000-------------------------------------------\n",
      "Train -> Loss: 0.026533843949437 Acc: 0.844833314418793\n",
      "Valid -> Loss: 0.059412965551019 Acc: 0.600333362817764\n",
      "Epoch: 29180/30000-------------------------------------------\n",
      "Train -> Loss: 0.026559552177787 Acc: 0.844833314418793\n",
      "Valid -> Loss: 0.058907185991605 Acc: 0.605666706959406\n",
      "Epoch: 29190/30000-------------------------------------------\n",
      "Train -> Loss: 0.030284807085991 Acc: 0.799333333969116\n",
      "Valid -> Loss: 0.054476900647084 Acc: 0.644166698058446\n",
      "Epoch: 29200/30000-------------------------------------------\n",
      "Train -> Loss: 0.027145560830832 Acc: 0.839833319187164\n",
      "Valid -> Loss: 0.059293500458201 Acc: 0.607666701078415\n",
      "Epoch: 29210/30000-------------------------------------------\n",
      "Train -> Loss: 0.027491444721818 Acc: 0.836166679859161\n",
      "Valid -> Loss: 0.061302409196893 Acc: 0.579000016053518\n",
      "Epoch: 29220/30000-------------------------------------------\n",
      "Train -> Loss: 0.026635795831680 Acc: 0.846499979496002\n",
      "Valid -> Loss: 0.058573463931680 Acc: 0.611666699250539\n",
      "Epoch: 29230/30000-------------------------------------------\n",
      "Train -> Loss: 0.026628602296114 Acc: 0.844833314418793\n",
      "Valid -> Loss: 0.059557845195134 Acc: 0.596833358208338\n",
      "Epoch: 29240/30000-------------------------------------------\n",
      "Train -> Loss: 0.026674291118979 Acc: 0.843166649341583\n",
      "Valid -> Loss: 0.059736123929421 Acc: 0.601000040769577\n",
      "Epoch: 29250/30000-------------------------------------------\n",
      "Train -> Loss: 0.026800215244293 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.061148772637049 Acc: 0.582833359638850\n",
      "Epoch: 29260/30000-------------------------------------------\n",
      "Train -> Loss: 0.029209228232503 Acc: 0.816166639328003\n",
      "Valid -> Loss: 0.062719399109483 Acc: 0.573500027259191\n",
      "Epoch: 29270/30000-------------------------------------------\n",
      "Train -> Loss: 0.026734756305814 Acc: 0.847833335399628\n",
      "Valid -> Loss: 0.059808701276779 Acc: 0.595166703065236\n",
      "Epoch: 29280/30000-------------------------------------------\n",
      "Train -> Loss: 0.026796860620379 Acc: 0.841833353042603\n",
      "Valid -> Loss: 0.058826966832081 Acc: 0.605333377917608\n",
      "Epoch: 29290/30000-------------------------------------------\n",
      "Train -> Loss: 0.026989085599780 Acc: 0.843999981880188\n",
      "Valid -> Loss: 0.058320919051766 Acc: 0.607833365599314\n",
      "Epoch: 29300/30000-------------------------------------------\n",
      "Train -> Loss: 0.029011867940426 Acc: 0.815500020980835\n",
      "Valid -> Loss: 0.056783487399419 Acc: 0.622666686773300\n",
      "Epoch: 29310/30000-------------------------------------------\n",
      "Train -> Loss: 0.026752009987831 Acc: 0.846833348274231\n",
      "Valid -> Loss: 0.059283898522456 Acc: 0.604333360989889\n",
      "Epoch: 29320/30000-------------------------------------------\n",
      "Train -> Loss: 0.026680141687393 Acc: 0.844500005245209\n",
      "Valid -> Loss: 0.060531491413713 Acc: 0.587500035762787\n",
      "Epoch: 29330/30000-------------------------------------------\n",
      "Train -> Loss: 0.026557376608253 Acc: 0.843500018119812\n",
      "Valid -> Loss: 0.059233450020353 Acc: 0.601000020901362\n",
      "Epoch: 29340/30000-------------------------------------------\n",
      "Train -> Loss: 0.026539381593466 Acc: 0.845666646957397\n",
      "Valid -> Loss: 0.059249906490246 Acc: 0.602500031391780\n",
      "Epoch: 29350/30000-------------------------------------------\n",
      "Train -> Loss: 0.026508769020438 Acc: 0.844833314418793\n",
      "Valid -> Loss: 0.059431341787179 Acc: 0.601166695356369\n",
      "Epoch: 29360/30000-------------------------------------------\n",
      "Train -> Loss: 0.026498565450311 Acc: 0.846166670322418\n",
      "Valid -> Loss: 0.059547381475568 Acc: 0.598500033219655\n",
      "Epoch: 29370/30000-------------------------------------------\n",
      "Train -> Loss: 0.026493018493056 Acc: 0.846333324909210\n",
      "Valid -> Loss: 0.059606530393163 Acc: 0.598500033219655\n",
      "Epoch: 29380/30000-------------------------------------------\n",
      "Train -> Loss: 0.026488523930311 Acc: 0.846333324909210\n",
      "Valid -> Loss: 0.059573029478391 Acc: 0.598833362261454\n",
      "Epoch: 29390/30000-------------------------------------------\n",
      "Train -> Loss: 0.026484813541174 Acc: 0.846499979496002\n",
      "Valid -> Loss: 0.059647291898727 Acc: 0.596833348274231\n",
      "Epoch: 29400/30000-------------------------------------------\n",
      "Train -> Loss: 0.026491494849324 Acc: 0.846166670322418\n",
      "Valid -> Loss: 0.059950148065885 Acc: 0.594333360592524\n",
      "Epoch: 29410/30000-------------------------------------------\n",
      "Train -> Loss: 0.029026845470071 Acc: 0.818333327770233\n",
      "Valid -> Loss: 0.066138929997881 Acc: 0.540833358963331\n",
      "Epoch: 29420/30000-------------------------------------------\n",
      "Train -> Loss: 0.026757756248116 Acc: 0.838999986648560\n",
      "Valid -> Loss: 0.059632626051704 Acc: 0.605000029007594\n",
      "Epoch: 29430/30000-------------------------------------------\n",
      "Train -> Loss: 0.026734450832009 Acc: 0.846499979496002\n",
      "Valid -> Loss: 0.061823107923071 Acc: 0.575333366791407\n",
      "Epoch: 29440/30000-------------------------------------------\n",
      "Train -> Loss: 0.026671897619963 Acc: 0.844166636466980\n",
      "Valid -> Loss: 0.059217449898521 Acc: 0.599666694800059\n",
      "Epoch: 29450/30000-------------------------------------------\n",
      "Train -> Loss: 0.026574201881886 Acc: 0.842999994754791\n",
      "Valid -> Loss: 0.059185773755113 Acc: 0.599833349386851\n",
      "Epoch: 29460/30000-------------------------------------------\n",
      "Train -> Loss: 0.026528118178248 Acc: 0.843666672706604\n",
      "Valid -> Loss: 0.059031760940949 Acc: 0.602833380301793\n",
      "Epoch: 29470/30000-------------------------------------------\n",
      "Train -> Loss: 0.026483850553632 Acc: 0.846666634082794\n",
      "Valid -> Loss: 0.059220601494114 Acc: 0.601500034332275\n",
      "Epoch: 29480/30000-------------------------------------------\n",
      "Train -> Loss: 0.026471760123968 Acc: 0.845333337783813\n",
      "Valid -> Loss: 0.059463160733382 Acc: 0.599833359320958\n",
      "Epoch: 29490/30000-------------------------------------------\n",
      "Train -> Loss: 0.026464670896530 Acc: 0.846333324909210\n",
      "Valid -> Loss: 0.059649037818114 Acc: 0.598000029722849\n",
      "Epoch: 29500/30000-------------------------------------------\n",
      "Train -> Loss: 0.026459993794560 Acc: 0.847000002861023\n",
      "Valid -> Loss: 0.059676895538966 Acc: 0.598000029722849\n",
      "Epoch: 29510/30000-------------------------------------------\n",
      "Train -> Loss: 0.026464890688658 Acc: 0.846499979496002\n",
      "Valid -> Loss: 0.059982702136040 Acc: 0.594333360592524\n",
      "Epoch: 29520/30000-------------------------------------------\n",
      "Train -> Loss: 0.028343658894300 Acc: 0.824499964714050\n",
      "Valid -> Loss: 0.065150327980518 Acc: 0.549000034729640\n",
      "Epoch: 29530/30000-------------------------------------------\n",
      "Train -> Loss: 0.032360736280680 Acc: 0.783833324909210\n",
      "Valid -> Loss: 0.055213876068592 Acc: 0.639500031868617\n",
      "Epoch: 29540/30000-------------------------------------------\n",
      "Train -> Loss: 0.027548355981708 Acc: 0.844999969005585\n",
      "Valid -> Loss: 0.058189957713087 Acc: 0.607166697581609\n",
      "Epoch: 29550/30000-------------------------------------------\n",
      "Train -> Loss: 0.026580693200231 Acc: 0.845833301544189\n",
      "Valid -> Loss: 0.059850980838140 Acc: 0.593333363533020\n",
      "Epoch: 29560/30000-------------------------------------------\n",
      "Train -> Loss: 0.026484202593565 Acc: 0.844166636466980\n",
      "Valid -> Loss: 0.059380616992712 Acc: 0.601500034332275\n",
      "Epoch: 29570/30000-------------------------------------------\n",
      "Train -> Loss: 0.026465371251106 Acc: 0.844999969005585\n",
      "Valid -> Loss: 0.059373792260885 Acc: 0.599333355824153\n",
      "Epoch: 29580/30000-------------------------------------------\n",
      "Train -> Loss: 0.026460645720363 Acc: 0.847000002861023\n",
      "Valid -> Loss: 0.059440936893225 Acc: 0.600000033775965\n",
      "Epoch: 29590/30000-------------------------------------------\n",
      "Train -> Loss: 0.026447728276253 Acc: 0.846666634082794\n",
      "Valid -> Loss: 0.059736826146642 Acc: 0.596500019232432\n",
      "Epoch: 29600/30000-------------------------------------------\n",
      "Train -> Loss: 0.026445789262652 Acc: 0.847000002861023\n",
      "Valid -> Loss: 0.059693067645033 Acc: 0.597500026226044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29610/30000-------------------------------------------\n",
      "Train -> Loss: 0.026439948007464 Acc: 0.846333324909210\n",
      "Valid -> Loss: 0.059507848074039 Acc: 0.599333365758260\n",
      "Epoch: 29620/30000-------------------------------------------\n",
      "Train -> Loss: 0.026597952470183 Acc: 0.841499984264374\n",
      "Valid -> Loss: 0.058362963919838 Acc: 0.608666688203812\n",
      "Epoch: 29630/30000-------------------------------------------\n",
      "Train -> Loss: 0.036672834306955 Acc: 0.760166645050049\n",
      "Valid -> Loss: 0.055586798737446 Acc: 0.635833362738291\n",
      "Epoch: 29640/30000-------------------------------------------\n",
      "Train -> Loss: 0.026521882042289 Acc: 0.850333333015442\n",
      "Valid -> Loss: 0.060850898424784 Acc: 0.590666691462199\n",
      "Epoch: 29650/30000-------------------------------------------\n",
      "Train -> Loss: 0.027244325727224 Acc: 0.833833336830139\n",
      "Valid -> Loss: 0.062648506835103 Acc: 0.567833364009857\n",
      "Epoch: 29660/30000-------------------------------------------\n",
      "Train -> Loss: 0.026669649407268 Acc: 0.848666667938232\n",
      "Valid -> Loss: 0.059266215811173 Acc: 0.600333372751872\n",
      "Epoch: 29670/30000-------------------------------------------\n",
      "Train -> Loss: 0.026648219674826 Acc: 0.844333350658417\n",
      "Valid -> Loss: 0.059002661456664 Acc: 0.601666698853175\n",
      "Epoch: 29680/30000-------------------------------------------\n",
      "Train -> Loss: 0.027359772473574 Acc: 0.833000004291534\n",
      "Valid -> Loss: 0.058053296059370 Acc: 0.611500024795532\n",
      "Epoch: 29690/30000-------------------------------------------\n",
      "Train -> Loss: 0.028265357017517 Acc: 0.840499997138977\n",
      "Valid -> Loss: 0.057766977697611 Acc: 0.612333357334137\n",
      "Epoch: 29700/30000-------------------------------------------\n",
      "Train -> Loss: 0.026871439069510 Acc: 0.848666667938232\n",
      "Valid -> Loss: 0.061643881723285 Acc: 0.577166706323624\n",
      "Epoch: 29710/30000-------------------------------------------\n",
      "Train -> Loss: 0.026716118678451 Acc: 0.841333329677582\n",
      "Valid -> Loss: 0.059742878501614 Acc: 0.601500024398168\n",
      "Epoch: 29720/30000-------------------------------------------\n",
      "Train -> Loss: 0.026513697579503 Acc: 0.847000002861023\n",
      "Valid -> Loss: 0.060373992348711 Acc: 0.589833348989487\n",
      "Epoch: 29730/30000-------------------------------------------\n",
      "Train -> Loss: 0.026444973424077 Acc: 0.845666646957397\n",
      "Valid -> Loss: 0.059408459812403 Acc: 0.599333355824153\n",
      "Epoch: 29740/30000-------------------------------------------\n",
      "Train -> Loss: 0.026436313986778 Acc: 0.847166657447815\n",
      "Valid -> Loss: 0.059392552822828 Acc: 0.601166695356369\n",
      "Epoch: 29750/30000-------------------------------------------\n",
      "Train -> Loss: 0.026418343186378 Acc: 0.846333324909210\n",
      "Valid -> Loss: 0.059549067790310 Acc: 0.598833372195562\n",
      "Epoch: 29760/30000-------------------------------------------\n",
      "Train -> Loss: 0.026410555467010 Acc: 0.847833335399628\n",
      "Valid -> Loss: 0.059593425442775 Acc: 0.599000036716461\n",
      "Epoch: 29770/30000-------------------------------------------\n",
      "Train -> Loss: 0.026403233408928 Acc: 0.847166657447815\n",
      "Valid -> Loss: 0.059651736170053 Acc: 0.598166694243749\n",
      "Epoch: 29780/30000-------------------------------------------\n",
      "Train -> Loss: 0.026398325338960 Acc: 0.847666680812836\n",
      "Valid -> Loss: 0.059705322608352 Acc: 0.597500036160151\n",
      "Epoch: 29790/30000-------------------------------------------\n",
      "Train -> Loss: 0.026395529508591 Acc: 0.847499966621399\n",
      "Valid -> Loss: 0.059604694445928 Acc: 0.598666697740555\n",
      "Epoch: 29800/30000-------------------------------------------\n",
      "Train -> Loss: 0.026532325893641 Acc: 0.842499971389771\n",
      "Valid -> Loss: 0.058456088726719 Acc: 0.608000030120214\n",
      "Epoch: 29810/30000-------------------------------------------\n",
      "Train -> Loss: 0.028470756486058 Acc: 0.812500000000000\n",
      "Valid -> Loss: 0.058181595678131 Acc: 0.615166703859965\n",
      "Epoch: 29820/30000-------------------------------------------\n",
      "Train -> Loss: 0.027165135368705 Acc: 0.835833311080933\n",
      "Valid -> Loss: 0.059358738362789 Acc: 0.604666680097580\n",
      "Epoch: 29830/30000-------------------------------------------\n",
      "Train -> Loss: 0.027155427262187 Acc: 0.825833320617676\n",
      "Valid -> Loss: 0.060109945635001 Acc: 0.597000032663345\n",
      "Epoch: 29840/30000-------------------------------------------\n",
      "Train -> Loss: 0.028195910155773 Acc: 0.829500019550323\n",
      "Valid -> Loss: 0.064228783672055 Acc: 0.555833359559377\n",
      "Epoch: 29850/30000-------------------------------------------\n",
      "Train -> Loss: 0.036715984344482 Acc: 0.771666646003723\n",
      "Valid -> Loss: 0.062596227352818 Acc: 0.562333365281423\n",
      "Epoch: 29860/30000-------------------------------------------\n",
      "Train -> Loss: 0.031484730541706 Acc: 0.792833328247070\n",
      "Valid -> Loss: 0.056717413167159 Acc: 0.620666692654292\n",
      "Epoch: 29870/30000-------------------------------------------\n",
      "Train -> Loss: 0.028544262051582 Acc: 0.834999978542328\n",
      "Valid -> Loss: 0.056279723842939 Acc: 0.624666680892309\n",
      "Epoch: 29880/30000-------------------------------------------\n",
      "Train -> Loss: 0.027581913396716 Acc: 0.825666666030884\n",
      "Valid -> Loss: 0.056932852293054 Acc: 0.626833369334539\n",
      "Epoch: 29890/30000-------------------------------------------\n",
      "Train -> Loss: 0.026659106835723 Acc: 0.847333312034607\n",
      "Valid -> Loss: 0.057175691549977 Acc: 0.623666693766912\n",
      "Epoch: 29900/30000-------------------------------------------\n",
      "Train -> Loss: 0.026637192815542 Acc: 0.847000002861023\n",
      "Valid -> Loss: 0.059541733314594 Acc: 0.602500021457672\n",
      "Epoch: 29910/30000-------------------------------------------\n",
      "Train -> Loss: 0.026543568819761 Acc: 0.845833301544189\n",
      "Valid -> Loss: 0.058668222278357 Acc: 0.608333369096120\n",
      "Epoch: 29920/30000-------------------------------------------\n",
      "Train -> Loss: 0.026506392285228 Acc: 0.845499992370605\n",
      "Valid -> Loss: 0.058714271212618 Acc: 0.606000036001205\n",
      "Epoch: 29930/30000-------------------------------------------\n",
      "Train -> Loss: 0.026421910151839 Acc: 0.847499966621399\n",
      "Valid -> Loss: 0.059574238955975 Acc: 0.599166701237361\n",
      "Epoch: 29940/30000-------------------------------------------\n",
      "Train -> Loss: 0.026408860459924 Acc: 0.847833335399628\n",
      "Valid -> Loss: 0.059259885922074 Acc: 0.601000030835470\n",
      "Epoch: 29950/30000-------------------------------------------\n",
      "Train -> Loss: 0.026397515088320 Acc: 0.848166644573212\n",
      "Valid -> Loss: 0.059242031847437 Acc: 0.601666688919067\n",
      "Epoch: 29960/30000-------------------------------------------\n",
      "Train -> Loss: 0.026388891041279 Acc: 0.847499966621399\n",
      "Valid -> Loss: 0.059363229821126 Acc: 0.601333359877268\n",
      "Epoch: 29970/30000-------------------------------------------\n",
      "Train -> Loss: 0.026382455602288 Acc: 0.847999989986420\n",
      "Valid -> Loss: 0.059395485868057 Acc: 0.601000030835470\n",
      "Epoch: 29980/30000-------------------------------------------\n",
      "Train -> Loss: 0.026377031579614 Acc: 0.848500013351440\n",
      "Valid -> Loss: 0.059449909254909 Acc: 0.600666701793671\n",
      "Epoch: 29990/30000-------------------------------------------\n",
      "Train -> Loss: 0.026372170075774 Acc: 0.848333299160004\n",
      "Valid -> Loss: 0.059467076634367 Acc: 0.600666701793671\n",
      "Epoch: 30000/30000-------------------------------------------\n",
      "Train -> Loss: 0.026367697864771 Acc: 0.847999989986420\n",
      "Valid -> Loss: 0.059489653135339 Acc: 0.600166708230972\n",
      "--- 6858.891596317291 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time_processing = time.time()\n",
    "for epoch in range(start_epoch, start_epoch + n_epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    X_train.to(device)\n",
    "    output, hidden = model(X_train)\n",
    "    loss = criterion(output, Y_train.view(-1,len(ACTIONS_LIST)).float())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "\n",
    "        train_loss_arr = np.append(train_loss_arr, loss.item())\n",
    "        train_acc_arr  = np.append(train_acc_arr, get_acc(output, Y_train.reshape(-1, len(ACTIONS_LIST))))\n",
    "    \n",
    "        model.eval()\n",
    "        \n",
    "        epoch_valid_losses = np.array([])\n",
    "        epoch_valid_acc = np.array([])\n",
    "        for seq in range(len(X_train)):\n",
    "            output, hidden = model(torch.unsqueeze(X_train[seq], 1))\n",
    "            loss = criterion(output, Y_train[seq].view(-1,len(ACTIONS_LIST)).float())\n",
    "            epoch_valid_losses = np.append(epoch_valid_losses, loss.item())\n",
    "            epoch_valid_acc = np.append( epoch_valid_acc, get_acc(output, Y_train[seq].reshape(-1, len(ACTIONS_LIST))) )\n",
    "            \n",
    "        if first_epoch:\n",
    "            # valid_loss_arr = epoch_valid_losses.reshape(-1, 1)\n",
    "            valid_loss_arr = np.insert(valid_loss_arr, valid_loss_arr.shape[1], epoch_valid_losses, axis=1)\n",
    "            \n",
    "            valid_acc_arr = epoch_valid_acc.reshape(-1, 1)\n",
    "            first_epoch = False\n",
    "        else:\n",
    "            valid_loss_arr = np.insert(valid_loss_arr, valid_loss_arr.shape[1], epoch_valid_losses, axis=1)\n",
    "            valid_acc_arr = np.insert(valid_acc_arr, valid_acc_arr.shape[1], epoch_valid_acc, axis=1)\n",
    "            \n",
    "        valid_loss_mean_arr = np.append(valid_loss_mean_arr, np.mean(epoch_valid_losses))\n",
    "        valid_acc_mean_arr = np.append(valid_acc_mean_arr, np.mean(epoch_valid_acc))\n",
    "            \n",
    "        valid_loss_mean_arr = np.append(valid_loss_mean_arr, np.mean(epoch_valid_losses))\n",
    "        valid_acc_mean_arr = np.append(valid_acc_mean_arr, np.mean(epoch_valid_acc))\n",
    "        \n",
    "        loss_file.write(\"Epoch: {}/{}-------------------------------------------\\n\".format(epoch, start_epoch + n_epochs - 1))\n",
    "        loss_file.write(\"Train -> Loss: {:.15f} Acc: {:.15f}\\n\".format(train_loss_arr[-1], train_acc_arr[-1]))\n",
    "        loss_file.write(\"Valid -> Loss: {:.15f} Acc: {:.15f}\\n\".format(valid_loss_mean_arr[-1], valid_acc_mean_arr[-1]))\n",
    "            \n",
    "        print(\"Epoch: {}/{}-------------------------------------------\".format(epoch, start_epoch + n_epochs - 1))\n",
    "        print(\"Train -> Loss: {:.15f} Acc: {:.15f}\".format(train_loss_arr[-1], train_acc_arr[-1]))\n",
    "        print(\"Valid -> Loss: {:.15f} Acc: {:.15f}\".format(valid_loss_mean_arr[-1], valid_acc_mean_arr[-1]))\n",
    "        \n",
    "        if train_loss_arr[-1] < best_loss:\n",
    "            state = { 'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
    "                      'optimizer': optimizer.state_dict(), 'losslogger': loss.item(), }\n",
    "            torch.save(state, newpath + '/' + model_name)\n",
    "            best_loss = loss.item()\n",
    "        \n",
    "        if (valid_loss_mean_arr[-1] < min_loss):\n",
    "            break\n",
    "\n",
    "loss_file.close()\n",
    "np.savez(newpath + '/' + \"train_loss_arr\", train_loss_arr)\n",
    "np.savez(newpath + '/' + \"valid_loss_arr\", valid_loss_arr)\n",
    "np.savez(newpath + '/' + \"valid_loss_mean_arr\", valid_loss_mean_arr)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_processing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_acc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fc64d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.clf()\n",
    "plt.plot(train_loss_arr, color='blue')\n",
    "plt.title('model train loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.yscale('log')\n",
    "plt.savefig(newpath + '/' + 'train_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2297767d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.clf()\n",
    "plt.plot(valid_loss_mean_arr, color='blue')\n",
    "plt.title('model valid loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['valid'], loc='upper left')\n",
    "plt.yscale('log')\n",
    "plt.savefig(newpath + '/' + 'valid_loss_mean.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0ebbbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for seq in range(len(X_train)):\n",
    "    # summarize history for loss\n",
    "    plt.clf()\n",
    "    plt.plot(valid_loss_arr[seq], color='blue')\n",
    "    plt.title('model valid loss ' + str(seq))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['valid'], loc='upper left')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(newpath + '/' + f'valid_loss_{seq}.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
