{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ac3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Embedding, LSTM\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d414b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset is a list of sequences/sentences\n",
    "# the elements of the sentences could be anything, as long as it can be contained in a torch tensor\n",
    "# usually, these will be indices of words based on some vocabulary\n",
    "# 0 is commonly reserved for the padding token, here it appears once explicitly and on purpose,\n",
    "#  to check that it functions properly (= in the same way as the automatically added padding tokens)\n",
    "DATA = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8, 9],\n",
    "    [4, 6, 2, 9, 0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0376a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need torch tensors for torch's pad_sequence(); this could be a part of e.g. dataset's __getitem__ instead\n",
    "DATA = list(map(lambda x: torch.tensor(x), DATA))\n",
    "# vocab size (for embedding); including 0 (the padding token)\n",
    "NUM_WORDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f008cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "# for consistent results between runs\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "BATCH_SIZE = 3\n",
    "EMB_DIM = 2\n",
    "LSTM_DIM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f983b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimalDataset(Dataset):\n",
    "    def __init__(self, data) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a019021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MinimalDataset(DATA)\n",
    "# len(data) is not divisible by batch_size on purpose to verify consistency across batch sizes\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee31fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 2, 3]), tensor([4, 5]), tensor([6, 7, 8, 9])]\n"
     ]
    }
   ],
   "source": [
    "# collate_fn is crucial for handling data points of varying length (as is the case here)\n",
    "print(next(iter(data_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00bbcb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, [tensor([1, 2, 3]), tensor([4, 5]), tensor([6, 7, 8, 9])]\n",
      "1, [tensor([4, 6, 2, 9, 0])]\n"
     ]
    }
   ],
   "source": [
    "# I would think that we should always obtain:\n",
    "# [ [1, 2, 3], [4, 5], [6, 7, 8, 9] ]\n",
    "# but, without collate_fn set to identity as above, you would get:\n",
    "# RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 3 and 2 in dimension 1 ...\n",
    "# ¯\\_(ツ)_/¯\n",
    "\n",
    "# iterate through the dataset:\n",
    "for i, batch in enumerate(data_loader):\n",
    "    print(f'{i}, {batch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc4dff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding and [un]packing\n"
     ]
    }
   ],
   "source": [
    "# playing around with padding (= unpacking) and packing (= unpadding)\n",
    "print('padding and [un]packing')\n",
    "# this always gets you the first batch of the dataset:\n",
    "batch = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a805c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: \n",
      "[tensor([1, 2, 3]), tensor([4, 5]), tensor([6, 7, 8, 9])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'batch: \\n{batch}\\n')\n",
    "# need to store the sequence lengths explicitly if we want to later pack the sequence:\n",
    "lens = list(map(len, batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d494c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0] padded: \n",
      "tensor([[1, 2, 3, 0],\n",
      "        [4, 5, 0, 0],\n",
      "        [6, 7, 8, 9]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "padded = pad_sequence(batch, batch_first=True)\n",
    "print(f' [0] padded: \\n{padded}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c803173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] packed: \n",
      "PackedSequence(data=tensor([6, 1, 4, 7, 2, 5, 8, 3, 9]), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))\n",
      "\n",
      " [2] padded: \n",
      "(tensor([[1, 2, 3, 0],\n",
      "        [4, 5, 0, 0],\n",
      "        [6, 7, 8, 9]]), tensor([3, 2, 4]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pytorch <1.1.0 does not support enforce_sorted=False and you would have to sort the sequences manually\n",
    "packed = pack_padded_sequence(padded, lens, batch_first=True, enforce_sorted=False)\n",
    "print(f' [1] packed: \\n{packed}\\n')\n",
    "padded2 = pad_packed_sequence(packed, batch_first=True)\n",
    "print(f' [2] padded: \\n{padded2}\\n')\n",
    "# pad(pack(pad(x))) == pad(x) as pad() and pack() are inverse to each other\n",
    "assert torch.all(torch.eq(padded2[0], padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e199ab30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding\n"
     ]
    }
   ],
   "source": [
    "# putting everything together: dataset - data_loader - padding - embedding - packing - lstm - unpacking (padding)\n",
    "print('embedding')\n",
    "batch = next(iter(data_loader))\n",
    "# or:\n",
    "# for batch in data_loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a381070a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "batch: \n",
      "[tensor([1, 2, 3]), tensor([4, 5]), tensor([6, 7, 8, 9])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'------------------------\\nbatch: \\n{batch}\\n')\n",
    "lens = list(map(len, batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc297380",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(NUM_WORDS, EMB_DIM)\n",
    "lstm = LSTM(input_size=EMB_DIM, hidden_size=LSTM_DIM, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2c9e6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(10, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f8e822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> pad: \n",
      "tensor([[1, 2, 3, 0],\n",
      "        [4, 5, 0, 0],\n",
      "        [6, 7, 8, 9]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we first have to pad, making all sequences in the batch equally long\n",
    "padded = pad_sequence(batch, batch_first=True)\n",
    "print(f'> pad: \\n{padded}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47641966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> pad_embed: \n",
      "tensor([[[ 0.4913, -0.2041],\n",
      "         [ 0.1665,  0.8744],\n",
      "         [-0.1435, -0.1116],\n",
      "         [-0.3561,  0.4372]],\n",
      "\n",
      "        [[-0.6136,  0.0316],\n",
      "         [-0.4927,  0.2484],\n",
      "         [-0.3561,  0.4372],\n",
      "         [-0.3561,  0.4372]],\n",
      "\n",
      "        [[ 0.6181, -0.4128],\n",
      "         [-0.8411, -2.3160],\n",
      "         [-0.1023,  0.7924],\n",
      "         [-0.2897,  0.0525]]], grad_fn=<EmbeddingBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now add the embedding dimension:\n",
    "pad_embed = embedding(padded)\n",
    "print(f'> pad_embed: \\n{pad_embed}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "babd0dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> pad_embed_pack: \n",
      "PackedSequence(data=tensor([[ 0.6181, -0.4128],\n",
      "        [ 0.4913, -0.2041],\n",
      "        [-0.6136,  0.0316],\n",
      "        [-0.8411, -2.3160],\n",
      "        [ 0.1665,  0.8744],\n",
      "        [-0.4927,  0.2484],\n",
      "        [-0.1023,  0.7924],\n",
      "        [-0.1435, -0.1116],\n",
      "        [-0.2897,  0.0525]], grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pack it up to one sequence (where each element is EMB_DIM long)\n",
    "pad_embed_pack = pack_padded_sequence(pad_embed, lens, batch_first=True, enforce_sorted=False)\n",
    "print(f'> pad_embed_pack: \\n{pad_embed_pack}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a5e10ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> pad_embed_pack_lstm: \n",
      "(PackedSequence(data=tensor([[-2.8078e-02, -7.5184e-02, -1.5413e-01, -4.4770e-02,  1.2383e-02],\n",
      "        [-3.6822e-02, -6.6412e-02, -1.4248e-01, -4.7936e-02,  2.4047e-02],\n",
      "        [-8.1972e-02, -5.3362e-02, -1.9377e-01,  3.4363e-02, -2.3898e-04],\n",
      "        [-5.0494e-02, -2.0331e-01, -4.3655e-01,  3.7436e-02, -1.6537e-01],\n",
      "        [-9.4117e-02, -8.0996e-02, -1.1510e-01, -9.3560e-02,  7.8516e-02],\n",
      "        [-1.3141e-01, -9.9222e-02, -2.7083e-01,  6.3981e-02,  6.1639e-03],\n",
      "        [-1.5719e-01, -1.5504e-01, -2.6151e-01,  4.5258e-02,  5.2963e-03],\n",
      "        [-1.0997e-01, -1.5025e-01, -2.4058e-01, -6.0991e-03,  5.5633e-02],\n",
      "        [-1.4524e-01, -1.9434e-01, -3.1854e-01,  7.6890e-02,  3.8153e-03]],\n",
      "       grad_fn=<CatBackward>), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0])), (tensor([[[-0.1100, -0.1502, -0.2406, -0.0061,  0.0556],\n",
      "         [-0.1314, -0.0992, -0.2708,  0.0640,  0.0062],\n",
      "         [-0.1452, -0.1943, -0.3185,  0.0769,  0.0038]]],\n",
      "       grad_fn=<IndexSelectBackward>), tensor([[[-0.2868, -0.3102, -0.3738, -0.0128,  0.1294],\n",
      "         [-0.3498, -0.2124, -0.4346,  0.1197,  0.0165],\n",
      "         [-0.3842, -0.4081, -0.5158,  0.1557,  0.0091]]],\n",
      "       grad_fn=<IndexSelectBackward>)))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run that through the lstm\n",
    "pad_embed_pack_lstm = lstm(pad_embed_pack)\n",
    "print(f'> pad_embed_pack_lstm: \\n{pad_embed_pack_lstm}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b796ad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> pad_embed_pack_lstm_pad: \n",
      "(tensor([[[-3.6822e-02, -6.6412e-02, -1.4248e-01, -4.7936e-02,  2.4047e-02],\n",
      "         [-9.4117e-02, -8.0996e-02, -1.1510e-01, -9.3560e-02,  7.8516e-02],\n",
      "         [-1.0997e-01, -1.5025e-01, -2.4058e-01, -6.0991e-03,  5.5633e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-8.1972e-02, -5.3362e-02, -1.9377e-01,  3.4363e-02, -2.3898e-04],\n",
      "         [-1.3141e-01, -9.9222e-02, -2.7083e-01,  6.3981e-02,  6.1639e-03],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.8078e-02, -7.5184e-02, -1.5413e-01, -4.4770e-02,  1.2383e-02],\n",
      "         [-5.0494e-02, -2.0331e-01, -4.3655e-01,  3.7436e-02, -1.6537e-01],\n",
      "         [-1.5719e-01, -1.5504e-01, -2.6151e-01,  4.5258e-02,  5.2963e-03],\n",
      "         [-1.4524e-01, -1.9434e-01, -3.1854e-01,  7.6890e-02,  3.8153e-03]]],\n",
      "       grad_fn=<IndexSelectBackward>), tensor([3, 2, 4]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# unpack the results (we can do that because it remembers how we packed the sentences)\n",
    "# the [0] just takes the first element (\"out\") of the LSTM output (hidden states after each timestep)\n",
    "pad_embed_pack_lstm_pad = pad_packed_sequence(pad_embed_pack_lstm[0], batch_first=True)\n",
    "print(f'> pad_embed_pack_lstm_pad: \\n{pad_embed_pack_lstm_pad}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23a773cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm last state without unpacking:\n",
      "tensor([[-0.1100, -0.1502, -0.2406, -0.0061,  0.0556],\n",
      "        [-0.1314, -0.0992, -0.2708,  0.0640,  0.0062],\n",
      "        [-0.1452, -0.1943, -0.3185,  0.0769,  0.0038]],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# however, usually, we would just be interested in the last hidden state of the lstm for each sequence,\n",
    "# i.e., the [last] lstm state after it has processed the sentence\n",
    "# for this, the last unpacking/padding is not necessary, as we can obtain this already by:\n",
    "seq, (ht, ct) = pad_embed_pack_lstm\n",
    "print(f'lstm last state without unpacking:\\n{ht[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd67c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm last state after unpacking:\n",
      "tensor([[-0.1100, -0.1502, -0.2406, -0.0061,  0.0556],\n",
      "        [-0.1314, -0.0992, -0.2708,  0.0640,  0.0062],\n",
      "        [-0.1452, -0.1943, -0.3185,  0.0769,  0.0038]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "# which is the same as\n",
    "outs, lens = pad_embed_pack_lstm_pad\n",
    "print(f'lstm last state after unpacking:\\n'\n",
    "      f'{torch.cat([outs[i, len - 1] for i, len in enumerate(lens)]).view((BATCH_SIZE, -1))}')\n",
    "# i.e. the last non-masked/padded/null state\n",
    "# so, you probably shouldn't unpack the sequence if you don't need to"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
