{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d651e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[  0, 52, 62, 80, 106, 117, 137, 142, 156, 159, 166, 185, 215, 226, 235, 242, 252, 259, 279, 281, 292, 296, 299, \n",
    "                303, 308, 315, 318, 321, 329, 333, 335, 354, 360, 374, 377, 382, 386, 390, 393, 402, 414, 420, 444, 447, \n",
    "                465, 469, 487, 491, 504, 506, 510, 513, 525, 528, 538, 552, 558, 570, 576, 581, 584, 588, 595, 598, 604, \n",
    "                607, 610, 618, 619, 622, 631, 641, 645, 662, 672, 685, 693, 697, 704, 718, 724, 726, 735, 739, 745, 754, \n",
    "                755, 770, 773, 789, 790, 799, 805, 809, 823, 834, 850, 854, 857, 868, 874, 875, 877, 883, 885, 904, 906, \n",
    "                911, 919, 923, 926, 932, 943, 962, 965, 984, 991, 999, 1007, 1010, 1015, 1017, 1018],\n",
    "           [   0, 31, 45, 47, 56, 63, 69, 85, 88, 92, 96, 112, 118, 124, 130, 137, 143, 151, 158, 170, 184, 202, 223, 243, 249,\n",
    "             255,260,269,272,275,276,282,285,295,296,297,306,308,318,322,331,334,337,338,341,343,354,357,381,387,400,402,408,\n",
    "             420,423,426,429,441,443,445,448,454,463,465,474,481,502,506,524,533,538,548,556,562,566,570,581,588,603,604,609,\n",
    "             652,668,681,698,710,714,725,729,736,739,743,748,749,752,766,770,774,778,781,792,795,803,804,806,814,818,821,828,\n",
    "             834,837,843,849,855,862,868,874,884,888,895,896,919,935,942,945,957,958,963,964,965,977,980,984,989,997,1000],\n",
    "           [   0,37,53,81,94,99,119,123,124,142,144,146,162,193,211,213,222,230,232,235,238,240,252,255,258,267,270,275,\n",
    "                278,284,287,289,300,307,313,331,352,359,371,379,386,389,392,409,412,432,435,440,442,446,462,467,472,\n",
    "                506,527,531,535,553,557,561,571,579,589,602,607,609,612,616,621,631,634,638,640,644,645,661,669,673,676,\n",
    "                692,695,698,701,711,717,720,721,734,744,747,750,755,759,774,785,793,807,859,891,895,912,927,948,958,969,\n",
    "                980,997,998,1004],\n",
    "           [   0,33,58,75,86,100,118,120,139,142,147,159,162,165,167,174,179,180,183,192,197,199,209,214,217,222,227,231,\n",
    "                232,239,244,251,262,266,271,275,277,282,287,291,294,297,308,311,316,318,322,327,339,342,348,352,362,372,\n",
    "                383,397,399,402,405,417,420, 425,428,454,457,464,470,477,481,485,488,494,495,503,507,517,535,537,540,553,\n",
    "                556,558,577,588,598,601,609,620,634,638,647,650,656,659,660,663,669,672,681,684,696,702,705,708,716,719,726,\n",
    "                730,739,743,746,758,765,766,777,783,785,786,790,792,800,802,808,809,810,816,819,823,827,835,837,842,845,853,\n",
    "                865,868,873,885,889,891,897,904,906,918,941,949,956,961,969,973,976,981,984,991,996,999,1002],\n",
    "           [   0,59,68,73,76,86,94,97,101,104,109,118,120,123,128,134,136,139,143,145,148,154,160,162,177,190,195,199,204,\n",
    "                208,212,220,221,222,232,234,246,251,253,256,263,270,273,287,302,314,322,355,357,368,396,397,401,416,428,433,\n",
    "                437,442,446,452,456,469,475,490,500,506,525,526,538,545,551,554,558,562,571,579,582,586,587,600,612,664,823,\n",
    "                824,832,850,858,870,879,881,889,898,901,913,916,924,932,936,943,952,955,975,985,992,997,1001],\n",
    "           [   0,36,56,94,114,121,136,140,143,153,159,162,171,174,182,190,197,201,215,219,237,239,249,251,254,265,269,297,322,\n",
    "                335,340,343,348,352,355,363,368,371,375,384,388,395,405,411,439,461,464,468,477,483,485,487,494,497,501,503,\n",
    "                514,519,521,526,529,532,538,547,551,555,560,579,584,597,600,602,607,609,617,623,626,634,638,644,649,652,663,\n",
    "                671,672,675,678,685,688,699,700,712,719,724,726,735,744,753,756,775,797,806,812,818,826,829,832,848,852,856,\n",
    "                866,869,872,875,881,886,891,893,895,901,910,930,936,940,953,958,989,997,1004,1006] \n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f23226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from enduro_lstm import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7084614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU (y/n) y\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "use_gpu = input(\"Use GPU (y/n) \")\n",
    "\n",
    "if use_gpu == 'y':\n",
    "    use_gpu = True\n",
    "else:\n",
    "    use_gpu = False\n",
    "    \n",
    "device = conf_cuda(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8adb5d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escreva uma observacao (sem espaco): ryo_lstm_sigmoide\n"
     ]
    }
   ],
   "source": [
    "obs = input('escreva uma observacao (sem espaco): ')\n",
    "\n",
    "if obs == 'zigzag':\n",
    "    zigzag = True\n",
    "else:\n",
    "    zigzag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a27ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epochs: 10000\n",
      "number of hidden neurons: 500\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"../1-generate/data/\"\n",
    "n_epochs = int(input(\"number of epochs: \") ) #5000\n",
    "hidden_neurons = int(input(\"number of hidden neurons: \")) #500\n",
    "stop_train = 1e-5\n",
    "\n",
    "# start_match = int(input(\"start match: \")) #45\n",
    "# end_match = int(input(\"end match: \")) #49\n",
    "\n",
    "start_match = 45\n",
    "end_match = 50\n",
    "\n",
    "# start_frame = int(input(\"start frame: \")) #1\n",
    "# end_frame = int(input(\"end frame: \")) #1000\n",
    "\n",
    "start_frame = 1\n",
    "end_frame = 1020\n",
    "\n",
    "is_softmax = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a76d211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/ryo_lstm_sigmoide_m45to45_f1to1020_epoch10000_H500\n",
      "ATTENTION! folder not created. Training informations will overwrite the existing one\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{obs}_m{start_match}to{end_match}_f{start_frame}to{end_frame}_epoch{n_epochs}_H{hidden_neurons}\"\n",
    "newpath = f\"models/\" + model_name\n",
    "if not os.path.exists(newpath):\n",
    "    print(f\"models/\" + model_name + \" created\")\n",
    "    os.makedirs(newpath)\n",
    "else:\n",
    "    print(f\"models/\" + model_name)\n",
    "    print(\"ATTENTION! folder not created. Training informations will overwrite the existing one\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebe3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_LIST = get_actions_list(zigzag=zigzag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556bf9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded NPZ.\n"
     ]
    }
   ],
   "source": [
    "num_of_frames_arr = []\n",
    "frames_arr = []\n",
    "actions_arr = []\n",
    "\n",
    "for m in range(start_match, end_match + 1):\n",
    "    \n",
    "    num_of_frames, frames, actions, rewards, lifes = load_npz(data_path, m)\n",
    "    frames = frames[start_frame - 1:end_frame]\n",
    "    frames = frames.reshape(end_frame - start_frame + 1, 170, 120)\n",
    "    frames = frames[:, 30:130, :]\n",
    "    frames = frames.reshape(end_frame - start_frame + 1, 12000)\n",
    "    actions = actions[start_frame - 1:end_frame]\n",
    "    \n",
    "    action_one_hot = [prepare_action_data(i, ACTIONS_LIST) for i in actions]\n",
    "    actions = np.array(action_one_hot)\n",
    "    actions = actions.reshape(len(actions), -1)\n",
    "    \n",
    "    frames_arr.append(frames)\n",
    "    actions_arr.append(actions)\n",
    "    num_of_frames_arr.append(end_frame - start_frame + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695e2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunked = []\n",
    "target_chunked = []\n",
    "for i in range(len(frames_arr)):\n",
    "    for j in range(len(indices[i]) - 1):\n",
    "        data_chunked.append(frames_arr[i][indices[i][j]:indices[i][j+1]])\n",
    "        target_chunked.append(actions_arr[i][indices[i][j]:indices[i][j+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264fbd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alece\\miniconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\alece\\miniconda3\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(data_chunked)/255\n",
    "Y_train = np.array(target_chunked)\n",
    "num_of_frames_arr = np.array(num_of_frames_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae9dcdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtrado = []\n",
    "Y_train_filtrado = []\n",
    "for i in range(len(X_train)):\n",
    "    if len(X_train[i]) > 100:\n",
    "        pass\n",
    "    else:\n",
    "        X_train_filtrado.append(X_train[i])\n",
    "        Y_train_filtrado.append(Y_train[i])\n",
    "X_train = X_train_filtrado\n",
    "Y_train = Y_train_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186224ae",
   "metadata": {},
   "source": [
    "teste com zigzag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eecca307",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(frames_arr)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34b48f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = actions_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2d39b",
   "metadata": {},
   "source": [
    "voltando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec2b09cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(map(lambda x: torch.tensor(x), X_train))\n",
    "Y_train = list(map(lambda x: torch.tensor(x), Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "715fe2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([52., 10., 18., 26., 11., 20.,  5., 14.,  3.,  7., 19., 30., 11.,  9.,\n",
       "         7., 10.,  7., 20.,  2., 11.,  4.,  3.,  4.,  5.,  7.,  3.,  3.,  8.,\n",
       "         4.,  2., 19.,  6., 14.,  3.,  5.,  4.,  4.,  3.,  9., 12.,  6., 24.,\n",
       "         3., 18.,  4., 18.,  4., 13.,  2.,  4.,  3., 12.,  3., 10., 14.,  6.,\n",
       "        12.,  6.,  5.,  3.,  4.,  7.,  3.,  6.,  3.,  3.,  8.,  1.,  3.,  9.,\n",
       "        10.,  4., 17., 10., 13.,  8.,  4.,  7., 14.,  6.,  2.,  9.,  4.,  6.,\n",
       "         9.,  1., 15.,  3., 16.,  1.,  9.,  6.,  4., 14., 11., 16.,  4.,  3.,\n",
       "        11.,  6.,  1.,  2.,  6.,  2., 19.,  2.,  5.,  8.,  4.,  3.,  6., 11.,\n",
       "        19.,  3., 19.,  7.,  8.,  8.,  3.,  5.,  2.,  1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = torch.FloatTensor(list(map(len,X_train)))\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fba98461",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequence(X_train, batch_first=True).float()\n",
    "Y_train = pad_sequence(Y_train, batch_first=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36e7d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pack_padded_sequence(X_train, seq_len, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ff029f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, device, input_size, output_size, hidden_dim, n_layers, is_softmax):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # self.h0 = torch.zeros(self.n_layers, 1, self.hidden_dim).to(self.device)\n",
    "        # self.c0 = torch.zeros(self.n_layers, 1, self.hidden_dim).to(self.device)\n",
    "\n",
    "        self.init_hidden()\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)  \n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        if is_softmax:\n",
    "            self.out = nn.Softmax()\n",
    "        else:\n",
    "            self.out = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # batch_size = x.size(0)\n",
    "        batch_size = 1\n",
    "\n",
    "        # Initializing hidden state for first input using method defined below\n",
    "        # hidden = self.init_hidden(batch_size)\n",
    "        # self.h0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "        # self.c0 = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(self.device)\n",
    "\n",
    "        hidden = self.init_hidden()\n",
    "\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        # out, hidden = self.lstm(x)\n",
    "        \n",
    "        pad_embed_pack_lstm = self.lstm(x, hidden)\n",
    "        pad_embed_pack_lstm_pad = pad_packed_sequence(pad_embed_pack_lstm[0], batch_first=True)\n",
    "        \n",
    "        outs, lens = pad_embed_pack_lstm_pad\n",
    "        \n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = outs.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        out = self.out(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # the weights are of the form (nb_layers, batch_size, nb_lstm_units)\n",
    "        hidden_a = torch.randn(1, self.input_size, self.hidden_dim)\n",
    "        hidden_b = torch.randn(1, self.input_size, self.hidden_dim)\n",
    "\n",
    "        if self.device.type == 'cuda':\n",
    "            hidden_a = hidden_a.cuda()\n",
    "            hidden_b = hidden_b.cuda()\n",
    "\n",
    "        hidden_a = Variable(hidden_a)\n",
    "        hidden_b = Variable(hidden_b)\n",
    "\n",
    "        return (hidden_a, hidden_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4309aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(device=device, input_size=12000, output_size=len(ACTIONS_LIST), hidden_dim=hidden_neurons, n_layers=1, is_softmax=is_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7f0073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    X_train = X_train.cuda() \n",
    "    Y_train = Y_train.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b3a18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 1e-05\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04faee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_arr = np.array([])\n",
    "train_acc_arr = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f89a34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 2.00 GiB total capacity; 429.91 MiB already allocated; 45.06 MiB free; 598.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-9656028c1723>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mACTIONS_LIST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Does backpropagation and calculates gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Updates the weights accordinglyw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                    group['eps'])\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 2.00 GiB total capacity; 429.91 MiB already allocated; 45.06 MiB free; 598.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "start_time_processing = time.time()\n",
    "\n",
    "# Training Run\n",
    "loss_file = open(newpath + '/' + \"loss_file.txt\", \"w\")\n",
    "first_time = True\n",
    "\n",
    "best_loss = 1\n",
    "first_epoch = True\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    X_train.to(device)\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, Y_train.view(-1,len(ACTIONS_LIST)).float())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordinglyw\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "\n",
    "        train_loss_arr = np.append(train_loss_arr, loss.item())\n",
    "        train_acc_arr  = np.append(train_acc_arr, get_acc(output, Y_train.reshape(-1, len(ACTIONS_LIST))))\n",
    "        # train_acc_arr  = np.append(train_acc_arr, get_acc_2(output, target_padded.reshape(-1, len(ACTIONS_LIST))))\n",
    "        \n",
    "        loss_file.write(\"Epoch: {}/{}-------------------------------------------\\n\".format(epoch, n_epochs))\n",
    "        loss_file.write(\"Train -> Loss: {:.15f} Acc: {:.15f}\\n\".format(train_loss_arr[-1], train_acc_arr[-1]))\n",
    "            \n",
    "        print(\"Epoch: {}/{}-------------------------------------------\".format(epoch, n_epochs))\n",
    "        print(\"Train -> Loss: {:.15f} Acc: {:.15f}\".format(train_loss_arr[-1], train_acc_arr[-1]))\n",
    "        \n",
    "        if train_loss_arr[-1] < best_loss:\n",
    "            state = { 'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
    "                      'optimizer': optimizer.state_dict(), 'losslogger': loss.item(), }\n",
    "            torch.save(state, newpath + '/' + model_name)\n",
    "            best_loss = loss.item()\n",
    "        else:\n",
    "            print(\"model not saved\")\n",
    "            \n",
    "loss_file.write(\"--- %s seconds ---\" % (time.time() - start_time_processing))\n",
    "loss_file.close()\n",
    "np.savez(newpath + '/' + \"train_loss_arr\", train_loss_arr)\n",
    "#np.savez(newpath + '/' + \"valid_acc_table\", valid_loss_mean_arr)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_processing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9a023ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/novo_teste_m35to35_f1to120_epoch1000_H200/train_loss.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-7f39ebeac190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'upper left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'log'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'train_loss.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 937\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   2960\u001b[0m                 \u001b[0mpatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2962\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2964\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2259\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2260\u001b[0m                         \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2261\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   2262\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2263\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1667\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1669\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[0;32m    509\u001b[0m         mpl.image.imsave(\n\u001b[0;32m    510\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"upper\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1614\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"format\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1615\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dpi\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1616\u001b[1;33m         \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2167\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2168\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2169\u001b[1;33m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/novo_teste_m35to35_f1to120_epoch1000_H200/train_loss.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for loss\n",
    "plt.clf()\n",
    "plt.plot(train_loss_arr, color='blue')\n",
    "plt.title('model train loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.yscale('log')\n",
    "plt.savefig(newpath + '/' + 'train_loss.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
