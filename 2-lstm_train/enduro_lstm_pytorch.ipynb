{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa45a41",
   "metadata": {},
   "source": [
    "# Train LSTM model to Enduro sequence games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9cb59c",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7d4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from enduro_lstm import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29110489",
   "metadata": {},
   "source": [
    "## Set to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737018d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU (y/n) y\n"
     ]
    }
   ],
   "source": [
    "use_gpu = input(\"Use GPU (y/n) \")\n",
    "if use_gpu == 'y':\n",
    "    use_gpu = True\n",
    "else:\n",
    "    use_gpu = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c148033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "device = conf_cuda(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98837389",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73856ba",
   "metadata": {},
   "source": [
    "## Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4f89b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = 'play'\n",
    "if obs == 'zigzag':\n",
    "    zigzag = True\n",
    "else:\n",
    "    zigzag = False\n",
    "zigzag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "economic-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"../1-generate/data/\"\n",
    "n_epochs = 5000\n",
    "hidden_neurons = 200\n",
    "stop_train = 1e-5\n",
    "\n",
    "start_match = 45\n",
    "end_match = 50\n",
    "\n",
    "start_frame = 1\n",
    "end_frame = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348fd38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/play_m45to50_f1to1000_epoch5000_H200\n",
      "ATTENTION! folder not created. Training informations will overwrite the existing one\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{obs}_m{start_match}to{end_match}_f{start_frame}to{end_frame}_epoch{n_epochs}_H{hidden_neurons}\"\n",
    "newpath = f\"models/\" + model_name\n",
    "if not os.path.exists(newpath):\n",
    "    print(f\"models/\" + model_name + \" created\")\n",
    "    os.makedirs(newpath)\n",
    "else:\n",
    "    print(f\"models/\" + model_name)\n",
    "    print(\"ATTENTION! folder not created. Training informations will overwrite the existing one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddc7716",
   "metadata": {},
   "source": [
    "## Load frames and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5023547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTIONS_LIST = get_actions_list(zigzag=zigzag)\n",
    "ACTIONS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "endangered-sacramento",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n",
      "Successfully loaded NPZ.\n"
     ]
    }
   ],
   "source": [
    "num_of_frames_arr = []\n",
    "frames_arr = []\n",
    "actions_arr = []\n",
    "\n",
    "for m in range(start_match, end_match + 1):\n",
    "    \n",
    "    num_of_frames, frames, actions, rewards, lifes = load_npz(data_path, m)\n",
    "    frames = frames[start_frame - 1:end_frame]\n",
    "    actions = actions[start_frame - 1:end_frame]\n",
    "    \n",
    "    action_one_hot = [prepare_action_data(i, ACTIONS_LIST) for i in actions]\n",
    "    actions = np.array(action_one_hot)\n",
    "    actions = actions.reshape(len(actions), -1)\n",
    "    \n",
    "    frames_arr.append(frames)\n",
    "    actions_arr.append(actions)\n",
    "    num_of_frames_arr.append(end_frame - start_frame + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14ffda1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(frames_arr)/255\n",
    "targets = np.array(actions_arr)\n",
    "num_of_frames_arr = np.array(num_of_frames_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "muslim-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(data).float()\n",
    "targets = torch.tensor(targets).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c597ded",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cognitive-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(device=device, input_size=20400, output_size=len(ACTIONS_LIST), hidden_dim=hidden_neurons, n_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce69fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    data = data.cuda() \n",
    "    targets = targets.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "private-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 1e-05\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12bfee5",
   "metadata": {},
   "source": [
    "## Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80ac9a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(predicted, target):\n",
    "    \n",
    "    predicted = torch.argmax(predicted, axis=1)\n",
    "    target = torch.argmax(target, axis=1)\n",
    "    \n",
    "    correct = torch.sum(predicted == target)\n",
    "    \n",
    "    acc = correct/predicted.shape[0]\n",
    "    return float(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "721bd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_epoch(epoch, n_epochs, train_loss, train_acc, valid_loss, valid_acc):\n",
    "    print('Epoch: {}/{}-------------------------------------------'.format(epoch, n_epochs))\n",
    "    print(\"Train -> Loss: {:.15f} Acc: {:.15f}\".format(train_loss, train_acc))\n",
    "    print(\"Valid -> Loss: {:.15f} Acc: {:.15f}\".format(valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c43ef482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 20400])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx = np.setdiff1d([0,1], 1)\n",
    "X_train[train_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-avenue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5000-------------------------------------------\n",
      "Train -> Loss: 0.088802665472031 Acc: 0.750000000000000\n",
      "Valid -> Loss: 0.054896760731936 Acc: 0.750000000000000\n",
      "Epoch: 2/5000-------------------------------------------\n",
      "Train -> Loss: 0.082058683037758 Acc: 0.750000000000000\n",
      "Valid -> Loss: 0.056073226034641 Acc: 0.750000000000000\n",
      "Epoch: 3/5000-------------------------------------------\n",
      "Train -> Loss: 0.075361080467701 Acc: 0.750000000000000\n",
      "Valid -> Loss: 0.057496353983879 Acc: 0.750000000000000\n",
      "Epoch: 4/5000-------------------------------------------\n",
      "Train -> Loss: 0.068789318203926 Acc: 0.750000000000000\n",
      "Valid -> Loss: 0.059159066528082 Acc: 0.750000000000000\n",
      "Epoch: 5/5000-------------------------------------------\n",
      "Train -> Loss: 0.062418837100267 Acc: 0.750000000000000\n",
      "Valid -> Loss: 0.061049349606037 Acc: 0.750000000000000\n",
      "Epoch: 6/5000-------------------------------------------\n",
      "Train -> Loss: 0.056318171322346 Acc: 0.241666659712791\n",
      "Valid -> Loss: 0.063150130212307 Acc: 0.250000000000000\n",
      "Epoch: 7/5000-------------------------------------------\n",
      "Train -> Loss: 0.050546094775200 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.065439499914646 Acc: 0.250000000000000\n",
      "Epoch: 8/5000-------------------------------------------\n",
      "Train -> Loss: 0.045149412006140 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.067891240119934 Acc: 0.250000000000000\n",
      "Epoch: 9/5000-------------------------------------------\n",
      "Train -> Loss: 0.040161486715078 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.070475757122040 Acc: 0.250000000000000\n",
      "Epoch: 10/5000-------------------------------------------\n",
      "Train -> Loss: 0.035601712763309 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.073161162436008 Acc: 0.250000000000000\n",
      "Epoch: 11/5000-------------------------------------------\n",
      "Train -> Loss: 0.031475938856602 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.075914636254311 Acc: 0.250000000000000\n",
      "Epoch: 12/5000-------------------------------------------\n",
      "Train -> Loss: 0.027777865529060 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.078703761100769 Acc: 0.250000000000000\n",
      "Epoch: 13/5000-------------------------------------------\n",
      "Train -> Loss: 0.024491012096405 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.081497684121132 Acc: 0.250000000000000\n",
      "Epoch: 14/5000-------------------------------------------\n",
      "Train -> Loss: 0.021591078490019 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.084268160164356 Acc: 0.250000000000000\n",
      "Epoch: 15/5000-------------------------------------------\n",
      "Train -> Loss: 0.019048448652029 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.086990334093571 Acc: 0.250000000000000\n",
      "Epoch: 16/5000-------------------------------------------\n",
      "Train -> Loss: 0.016830423846841 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.089643143117428 Acc: 0.250000000000000\n",
      "Epoch: 17/5000-------------------------------------------\n",
      "Train -> Loss: 0.014903216622770 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.092209540307522 Acc: 0.250000000000000\n",
      "Epoch: 18/5000-------------------------------------------\n",
      "Train -> Loss: 0.013233553618193 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.094676434993744 Acc: 0.250000000000000\n",
      "Epoch: 19/5000-------------------------------------------\n",
      "Train -> Loss: 0.011789742857218 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.097034342586994 Acc: 0.250000000000000\n",
      "Epoch: 20/5000-------------------------------------------\n",
      "Train -> Loss: 0.010542451404035 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.099277175962925 Acc: 0.250000000000000\n",
      "Epoch: 21/5000-------------------------------------------\n",
      "Train -> Loss: 0.009465105831623 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.101401671767235 Acc: 0.250000000000000\n",
      "Epoch: 22/5000-------------------------------------------\n",
      "Train -> Loss: 0.008534034714103 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.103406988084316 Acc: 0.250000000000000\n",
      "Epoch: 23/5000-------------------------------------------\n",
      "Train -> Loss: 0.007728438824415 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.105294249951839 Acc: 0.250000000000000\n",
      "Epoch: 24/5000-------------------------------------------\n",
      "Train -> Loss: 0.007030227221549 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.107066065073013 Acc: 0.250000000000000\n",
      "Epoch: 25/5000-------------------------------------------\n",
      "Train -> Loss: 0.006423816084862 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.108726188540459 Acc: 0.250000000000000\n",
      "Epoch: 26/5000-------------------------------------------\n",
      "Train -> Loss: 0.005895833950490 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.110279276967049 Acc: 0.250000000000000\n",
      "Epoch: 27/5000-------------------------------------------\n",
      "Train -> Loss: 0.005434881430119 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.111730463802814 Acc: 0.250000000000000\n",
      "Epoch: 28/5000-------------------------------------------\n",
      "Train -> Loss: 0.005031266249716 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.113085225224495 Acc: 0.250000000000000\n",
      "Epoch: 29/5000-------------------------------------------\n",
      "Train -> Loss: 0.004676751326770 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.114349193871021 Acc: 0.250000000000000\n",
      "Epoch: 30/5000-------------------------------------------\n",
      "Train -> Loss: 0.004364368971437 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.115528084337711 Acc: 0.250000000000000\n",
      "Epoch: 31/5000-------------------------------------------\n",
      "Train -> Loss: 0.004088202025741 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.116627417504787 Acc: 0.250000000000000\n",
      "Epoch: 32/5000-------------------------------------------\n",
      "Train -> Loss: 0.003843240439892 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.117652691900730 Acc: 0.250000000000000\n",
      "Epoch: 33/5000-------------------------------------------\n",
      "Train -> Loss: 0.003625228768215 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.118609055876732 Acc: 0.250000000000000\n",
      "Epoch: 34/5000-------------------------------------------\n",
      "Train -> Loss: 0.003430550685152 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.119501493871212 Acc: 0.250000000000000\n",
      "Epoch: 35/5000-------------------------------------------\n",
      "Train -> Loss: 0.003256133990362 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.120334737002850 Acc: 0.250000000000000\n",
      "Epoch: 36/5000-------------------------------------------\n",
      "Train -> Loss: 0.003099353052676 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.121113188564777 Acc: 0.250000000000000\n",
      "Epoch: 37/5000-------------------------------------------\n",
      "Train -> Loss: 0.002957967109978 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.121841020882130 Acc: 0.250000000000000\n",
      "Epoch: 38/5000-------------------------------------------\n",
      "Train -> Loss: 0.002830056007951 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.122522071003914 Acc: 0.250000000000000\n",
      "Epoch: 39/5000-------------------------------------------\n",
      "Train -> Loss: 0.002713969908655 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.123159959912300 Acc: 0.250000000000000\n",
      "Epoch: 40/5000-------------------------------------------\n",
      "Train -> Loss: 0.002608292270452 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.123758047819138 Acc: 0.250000000000000\n",
      "Epoch: 41/5000-------------------------------------------\n",
      "Train -> Loss: 0.002511795610189 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.124319389462471 Acc: 0.250000000000000\n",
      "Epoch: 42/5000-------------------------------------------\n",
      "Train -> Loss: 0.002423424972221 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.124846860766411 Acc: 0.250000000000000\n",
      "Epoch: 43/5000-------------------------------------------\n",
      "Train -> Loss: 0.002342260209844 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.125343129038811 Acc: 0.250000000000000\n",
      "Epoch: 44/5000-------------------------------------------\n",
      "Train -> Loss: 0.002267501084134 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.125810623168945 Acc: 0.250000000000000\n",
      "Epoch: 45/5000-------------------------------------------\n",
      "Train -> Loss: 0.002198453061283 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.126251563429832 Acc: 0.250000000000000\n",
      "Epoch: 46/5000-------------------------------------------\n",
      "Train -> Loss: 0.002134507754818 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.126668050885201 Acc: 0.250000000000000\n",
      "Epoch: 47/5000-------------------------------------------\n",
      "Train -> Loss: 0.002075129887089 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.127061977982521 Acc: 0.250000000000000\n",
      "Epoch: 48/5000-------------------------------------------\n",
      "Train -> Loss: 0.002019854960963 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.127435088157654 Acc: 0.250000000000000\n",
      "Epoch: 49/5000-------------------------------------------\n",
      "Train -> Loss: 0.001968270866200 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.127789020538330 Acc: 0.250000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/5000-------------------------------------------\n",
      "Train -> Loss: 0.001920010661706 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.128125220537186 Acc: 0.250000000000000\n",
      "Epoch: 51/5000-------------------------------------------\n",
      "Train -> Loss: 0.001874758163467 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.128445073962212 Acc: 0.250000000000000\n",
      "Epoch: 52/5000-------------------------------------------\n",
      "Train -> Loss: 0.001832225127146 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.128749787807465 Acc: 0.250000000000000\n",
      "Epoch: 53/5000-------------------------------------------\n",
      "Train -> Loss: 0.001792160328478 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.129040569067001 Acc: 0.250000000000000\n",
      "Epoch: 54/5000-------------------------------------------\n",
      "Train -> Loss: 0.001754340482876 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.129318401217461 Acc: 0.250000000000000\n",
      "Epoch: 55/5000-------------------------------------------\n",
      "Train -> Loss: 0.001718565472402 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.129584327340126 Acc: 0.250000000000000\n",
      "Epoch: 56/5000-------------------------------------------\n",
      "Train -> Loss: 0.001684656133875 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.129839196801186 Acc: 0.250000000000000\n",
      "Epoch: 57/5000-------------------------------------------\n",
      "Train -> Loss: 0.001652450533584 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.130083829164505 Acc: 0.250000000000000\n",
      "Epoch: 58/5000-------------------------------------------\n",
      "Train -> Loss: 0.001621808740310 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.130318984389305 Acc: 0.250000000000000\n",
      "Epoch: 59/5000-------------------------------------------\n",
      "Train -> Loss: 0.001592601300217 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.130545318126678 Acc: 0.250000000000000\n",
      "Epoch: 60/5000-------------------------------------------\n",
      "Train -> Loss: 0.001564714009874 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.130763500928879 Acc: 0.250000000000000\n",
      "Epoch: 61/5000-------------------------------------------\n",
      "Train -> Loss: 0.001538041979074 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.130974143743515 Acc: 0.250000000000000\n",
      "Epoch: 62/5000-------------------------------------------\n",
      "Train -> Loss: 0.001512490096502 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.131177723407745 Acc: 0.250000000000000\n",
      "Epoch: 63/5000-------------------------------------------\n",
      "Train -> Loss: 0.001487977686338 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.131374716758728 Acc: 0.250000000000000\n",
      "Epoch: 64/5000-------------------------------------------\n",
      "Train -> Loss: 0.001464424654841 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.131565615534782 Acc: 0.250000000000000\n",
      "Epoch: 65/5000-------------------------------------------\n",
      "Train -> Loss: 0.001441764063202 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.131750836968422 Acc: 0.250000000000000\n",
      "Epoch: 66/5000-------------------------------------------\n",
      "Train -> Loss: 0.001419931999408 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.131930753588676 Acc: 0.250000000000000\n",
      "Epoch: 67/5000-------------------------------------------\n",
      "Train -> Loss: 0.001398873748258 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.132105737924576 Acc: 0.250000000000000\n",
      "Epoch: 68/5000-------------------------------------------\n",
      "Train -> Loss: 0.001378534710966 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.132276058197021 Acc: 0.250000000000000\n",
      "Epoch: 69/5000-------------------------------------------\n",
      "Train -> Loss: 0.001358869136311 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.132442072033882 Acc: 0.250000000000000\n",
      "Epoch: 70/5000-------------------------------------------\n",
      "Train -> Loss: 0.001339834416285 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.132604002952576 Acc: 0.250000000000000\n",
      "Epoch: 71/5000-------------------------------------------\n",
      "Train -> Loss: 0.001321392133832 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.132762178778648 Acc: 0.250000000000000\n",
      "Epoch: 72/5000-------------------------------------------\n",
      "Train -> Loss: 0.001303504570387 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.132916688919067 Acc: 0.250000000000000\n",
      "Epoch: 73/5000-------------------------------------------\n",
      "Train -> Loss: 0.001286139711738 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.133067891001701 Acc: 0.250000000000000\n",
      "Epoch: 74/5000-------------------------------------------\n",
      "Train -> Loss: 0.001269267173484 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.133215889334679 Acc: 0.250000000000000\n",
      "Epoch: 75/5000-------------------------------------------\n",
      "Train -> Loss: 0.001252861809917 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.133360952138901 Acc: 0.250000000000000\n",
      "Epoch: 76/5000-------------------------------------------\n",
      "Train -> Loss: 0.001236897194758 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.133503153920174 Acc: 0.250000000000000\n",
      "Epoch: 77/5000-------------------------------------------\n",
      "Train -> Loss: 0.001221348182298 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.133642688393593 Acc: 0.250000000000000\n",
      "Epoch: 78/5000-------------------------------------------\n",
      "Train -> Loss: 0.001206194516271 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.133779689669609 Acc: 0.250000000000000\n",
      "Epoch: 79/5000-------------------------------------------\n",
      "Train -> Loss: 0.001191416056827 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.133914336562157 Acc: 0.250000000000000\n",
      "Epoch: 80/5000-------------------------------------------\n",
      "Train -> Loss: 0.001176996855065 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.134046688675880 Acc: 0.250000000000000\n",
      "Epoch: 81/5000-------------------------------------------\n",
      "Train -> Loss: 0.001162917702459 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.134176924824715 Acc: 0.250000000000000\n",
      "Epoch: 82/5000-------------------------------------------\n",
      "Train -> Loss: 0.001149163581431 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.134305059909821 Acc: 0.250000000000000\n",
      "Epoch: 83/5000-------------------------------------------\n",
      "Train -> Loss: 0.001135719823651 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.134431228041649 Acc: 0.250000000000000\n",
      "Epoch: 84/5000-------------------------------------------\n",
      "Train -> Loss: 0.001122573972680 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.134555533528328 Acc: 0.250000000000000\n",
      "Epoch: 85/5000-------------------------------------------\n",
      "Train -> Loss: 0.001109711476602 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.134678050875664 Acc: 0.250000000000000\n",
      "Epoch: 86/5000-------------------------------------------\n",
      "Train -> Loss: 0.001097122905776 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.134798854589462 Acc: 0.250000000000000\n",
      "Epoch: 87/5000-------------------------------------------\n",
      "Train -> Loss: 0.001084796618670 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.134918048977852 Acc: 0.250000000000000\n",
      "Epoch: 88/5000-------------------------------------------\n",
      "Train -> Loss: 0.001072722254321 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.135035619139671 Acc: 0.250000000000000\n",
      "Epoch: 89/5000-------------------------------------------\n",
      "Train -> Loss: 0.001060890615918 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.135151669383049 Acc: 0.250000000000000\n",
      "Epoch: 90/5000-------------------------------------------\n",
      "Train -> Loss: 0.001049292506650 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.135266318917274 Acc: 0.250000000000000\n",
      "Epoch: 91/5000-------------------------------------------\n",
      "Train -> Loss: 0.001037920010276 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.135379523038864 Acc: 0.250000000000000\n",
      "Epoch: 92/5000-------------------------------------------\n",
      "Train -> Loss: 0.001026765210554 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.135491371154785 Acc: 0.250000000000000\n",
      "Epoch: 93/5000-------------------------------------------\n",
      "Train -> Loss: 0.001015820307657 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.135601922869682 Acc: 0.250000000000000\n",
      "Epoch: 94/5000-------------------------------------------\n",
      "Train -> Loss: 0.001005078549497 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.135711193084717 Acc: 0.250000000000000\n",
      "Epoch: 95/5000-------------------------------------------\n",
      "Train -> Loss: 0.000994533533230 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.135819241404533 Acc: 0.250000000000000\n",
      "Epoch: 96/5000-------------------------------------------\n",
      "Train -> Loss: 0.000984179088846 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.135926082730293 Acc: 0.250000000000000\n",
      "Epoch: 97/5000-------------------------------------------\n",
      "Train -> Loss: 0.000974010210484 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.136031791567802 Acc: 0.250000000000000\n",
      "Epoch: 98/5000-------------------------------------------\n",
      "Train -> Loss: 0.000964020029642 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.136136367917061 Acc: 0.250000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/5000-------------------------------------------\n",
      "Train -> Loss: 0.000954203133006 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.136239871382713 Acc: 0.250000000000000\n",
      "Epoch: 100/5000-------------------------------------------\n",
      "Train -> Loss: 0.000944554922171 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.136342301964760 Acc: 0.250000000000000\n",
      "Epoch: 101/5000-------------------------------------------\n",
      "Train -> Loss: 0.000935071730055 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.136443689465523 Acc: 0.250000000000000\n",
      "Epoch: 102/5000-------------------------------------------\n",
      "Train -> Loss: 0.000925749249291 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.136544093489647 Acc: 0.250000000000000\n",
      "Epoch: 103/5000-------------------------------------------\n",
      "Train -> Loss: 0.000916579039767 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.136643484234810 Acc: 0.250000000000000\n",
      "Epoch: 104/5000-------------------------------------------\n",
      "Train -> Loss: 0.000907562673092 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.136741966009140 Acc: 0.250000000000000\n",
      "Epoch: 105/5000-------------------------------------------\n",
      "Train -> Loss: 0.000898692174815 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.136839434504509 Acc: 0.250000000000000\n",
      "Epoch: 106/5000-------------------------------------------\n",
      "Train -> Loss: 0.000889966031536 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.136936053633690 Acc: 0.250000000000000\n",
      "Epoch: 107/5000-------------------------------------------\n",
      "Train -> Loss: 0.000881379644852 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137031763792038 Acc: 0.250000000000000\n",
      "Epoch: 108/5000-------------------------------------------\n",
      "Train -> Loss: 0.000872929056641 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137126564979553 Acc: 0.250000000000000\n",
      "Epoch: 109/5000-------------------------------------------\n",
      "Train -> Loss: 0.000864612287842 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137220531702042 Acc: 0.250000000000000\n",
      "Epoch: 110/5000-------------------------------------------\n",
      "Train -> Loss: 0.000856424972881 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137313634157181 Acc: 0.250000000000000\n",
      "Epoch: 111/5000-------------------------------------------\n",
      "Train -> Loss: 0.000848365132697 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137405917048454 Acc: 0.250000000000000\n",
      "Epoch: 112/5000-------------------------------------------\n",
      "Train -> Loss: 0.000840429216623 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137497425079346 Acc: 0.250000000000000\n",
      "Epoch: 113/5000-------------------------------------------\n",
      "Train -> Loss: 0.000832613557577 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137588098645210 Acc: 0.250000000000000\n",
      "Epoch: 114/5000-------------------------------------------\n",
      "Train -> Loss: 0.000824917631689 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137677967548370 Acc: 0.250000000000000\n",
      "Epoch: 115/5000-------------------------------------------\n",
      "Train -> Loss: 0.000817336025648 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137767091393471 Acc: 0.250000000000000\n",
      "Epoch: 116/5000-------------------------------------------\n",
      "Train -> Loss: 0.000809868914075 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137855485081673 Acc: 0.250000000000000\n",
      "Epoch: 117/5000-------------------------------------------\n",
      "Train -> Loss: 0.000802511291113 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.137943118810654 Acc: 0.250000000000000\n",
      "Epoch: 118/5000-------------------------------------------\n",
      "Train -> Loss: 0.000795263331383 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138030007481575 Acc: 0.250000000000000\n",
      "Epoch: 119/5000-------------------------------------------\n",
      "Train -> Loss: 0.000788121193182 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138116195797920 Acc: 0.250000000000000\n",
      "Epoch: 120/5000-------------------------------------------\n",
      "Train -> Loss: 0.000781081325840 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138201683759689 Acc: 0.250000000000000\n",
      "Epoch: 121/5000-------------------------------------------\n",
      "Train -> Loss: 0.000774144486059 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138286471366882 Acc: 0.250000000000000\n",
      "Epoch: 122/5000-------------------------------------------\n",
      "Train -> Loss: 0.000767306308262 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138370558619499 Acc: 0.250000000000000\n",
      "Epoch: 123/5000-------------------------------------------\n",
      "Train -> Loss: 0.000760566152167 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138453990221024 Acc: 0.250000000000000\n",
      "Epoch: 124/5000-------------------------------------------\n",
      "Train -> Loss: 0.000753921573050 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138536736369133 Acc: 0.250000000000000\n",
      "Epoch: 125/5000-------------------------------------------\n",
      "Train -> Loss: 0.000747370009776 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138618841767311 Acc: 0.250000000000000\n",
      "Epoch: 126/5000-------------------------------------------\n",
      "Train -> Loss: 0.000740910356399 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138700291514397 Acc: 0.250000000000000\n",
      "Epoch: 127/5000-------------------------------------------\n",
      "Train -> Loss: 0.000734541681595 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138781100511551 Acc: 0.250000000000000\n",
      "Epoch: 128/5000-------------------------------------------\n",
      "Train -> Loss: 0.000728259794414 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138861298561096 Acc: 0.250000000000000\n",
      "Epoch: 129/5000-------------------------------------------\n",
      "Train -> Loss: 0.000722065160517 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.138940870761871 Acc: 0.250000000000000\n",
      "Epoch: 130/5000-------------------------------------------\n",
      "Train -> Loss: 0.000715954869520 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139019817113876 Acc: 0.250000000000000\n",
      "Epoch: 131/5000-------------------------------------------\n",
      "Train -> Loss: 0.000709928513970 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139098167419434 Acc: 0.250000000000000\n",
      "Epoch: 132/5000-------------------------------------------\n",
      "Train -> Loss: 0.000703982484993 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139175921678543 Acc: 0.250000000000000\n",
      "Epoch: 133/5000-------------------------------------------\n",
      "Train -> Loss: 0.000698117015418 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139253109693527 Acc: 0.250000000000000\n",
      "Epoch: 134/5000-------------------------------------------\n",
      "Train -> Loss: 0.000692330533639 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139329716563225 Acc: 0.250000000000000\n",
      "Epoch: 135/5000-------------------------------------------\n",
      "Train -> Loss: 0.000686620478518 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139405727386475 Acc: 0.250000000000000\n",
      "Epoch: 136/5000-------------------------------------------\n",
      "Train -> Loss: 0.000680986791849 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139481201767921 Acc: 0.250000000000000\n",
      "Epoch: 137/5000-------------------------------------------\n",
      "Train -> Loss: 0.000675427261740 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139556095004082 Acc: 0.250000000000000\n",
      "Epoch: 138/5000-------------------------------------------\n",
      "Train -> Loss: 0.000669939967338 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139630451798439 Acc: 0.250000000000000\n",
      "Epoch: 139/5000-------------------------------------------\n",
      "Train -> Loss: 0.000664524908643 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139704272150993 Acc: 0.250000000000000\n",
      "Epoch: 140/5000-------------------------------------------\n",
      "Train -> Loss: 0.000659179408103 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139777526259422 Acc: 0.250000000000000\n",
      "Epoch: 141/5000-------------------------------------------\n",
      "Train -> Loss: 0.000653902941849 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139850288629532 Acc: 0.250000000000000\n",
      "Epoch: 142/5000-------------------------------------------\n",
      "Train -> Loss: 0.000648694694974 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139922529459000 Acc: 0.250000000000000\n",
      "Epoch: 143/5000-------------------------------------------\n",
      "Train -> Loss: 0.000643553270493 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.139994218945503 Acc: 0.250000000000000\n",
      "Epoch: 144/5000-------------------------------------------\n",
      "Train -> Loss: 0.000638476922177 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140065401792526 Acc: 0.250000000000000\n",
      "Epoch: 145/5000-------------------------------------------\n",
      "Train -> Loss: 0.000633464893326 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140136063098907 Acc: 0.250000000000000\n",
      "Epoch: 146/5000-------------------------------------------\n",
      "Train -> Loss: 0.000628516194411 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140206262469292 Acc: 0.250000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 147/5000-------------------------------------------\n",
      "Train -> Loss: 0.000623629137408 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140275970101357 Acc: 0.250000000000000\n",
      "Epoch: 148/5000-------------------------------------------\n",
      "Train -> Loss: 0.000618803198449 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140345185995102 Acc: 0.250000000000000\n",
      "Epoch: 149/5000-------------------------------------------\n",
      "Train -> Loss: 0.000614037096966 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140413895249367 Acc: 0.250000000000000\n",
      "Epoch: 150/5000-------------------------------------------\n",
      "Train -> Loss: 0.000609330309089 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140482112765312 Acc: 0.250000000000000\n",
      "Epoch: 151/5000-------------------------------------------\n",
      "Train -> Loss: 0.000604681205004 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140549927949905 Acc: 0.250000000000000\n",
      "Epoch: 152/5000-------------------------------------------\n",
      "Train -> Loss: 0.000600088387728 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140617236495018 Acc: 0.250000000000000\n",
      "Epoch: 153/5000-------------------------------------------\n",
      "Train -> Loss: 0.000595552846789 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140684083104134 Acc: 0.250000000000000\n",
      "Epoch: 154/5000-------------------------------------------\n",
      "Train -> Loss: 0.000591072021052 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140750467777252 Acc: 0.250000000000000\n",
      "Epoch: 155/5000-------------------------------------------\n",
      "Train -> Loss: 0.000586644280702 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140816420316696 Acc: 0.250000000000000\n",
      "Epoch: 156/5000-------------------------------------------\n",
      "Train -> Loss: 0.000582270324230 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140881925821304 Acc: 0.250000000000000\n",
      "Epoch: 157/5000-------------------------------------------\n",
      "Train -> Loss: 0.000577949103899 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.140946984291077 Acc: 0.250000000000000\n",
      "Epoch: 158/5000-------------------------------------------\n",
      "Train -> Loss: 0.000573679280933 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141011595726013 Acc: 0.250000000000000\n",
      "Epoch: 159/5000-------------------------------------------\n",
      "Train -> Loss: 0.000569459341932 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141075789928436 Acc: 0.250000000000000\n",
      "Epoch: 160/5000-------------------------------------------\n",
      "Train -> Loss: 0.000565289985389 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141139581799507 Acc: 0.250000000000000\n",
      "Epoch: 161/5000-------------------------------------------\n",
      "Train -> Loss: 0.000561169814318 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141202911734581 Acc: 0.250000000000000\n",
      "Epoch: 162/5000-------------------------------------------\n",
      "Train -> Loss: 0.000557097489946 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141265854239464 Acc: 0.250000000000000\n",
      "Epoch: 163/5000-------------------------------------------\n",
      "Train -> Loss: 0.000553072139155 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141328364610672 Acc: 0.250000000000000\n",
      "Epoch: 164/5000-------------------------------------------\n",
      "Train -> Loss: 0.000549094460439 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141390472650528 Acc: 0.250000000000000\n",
      "Epoch: 165/5000-------------------------------------------\n",
      "Train -> Loss: 0.000545162009075 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141452148556709 Acc: 0.250000000000000\n",
      "Epoch: 166/5000-------------------------------------------\n",
      "Train -> Loss: 0.000541274552234 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141513496637344 Acc: 0.250000000000000\n",
      "Epoch: 167/5000-------------------------------------------\n",
      "Train -> Loss: 0.000537432031706 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141574412584305 Acc: 0.250000000000000\n",
      "Epoch: 168/5000-------------------------------------------\n",
      "Train -> Loss: 0.000533633457962 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141634926199913 Acc: 0.250000000000000\n",
      "Epoch: 169/5000-------------------------------------------\n",
      "Train -> Loss: 0.000529877841473 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141695052385330 Acc: 0.250000000000000\n",
      "Epoch: 170/5000-------------------------------------------\n",
      "Train -> Loss: 0.000526164425537 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141754806041718 Acc: 0.250000000000000\n",
      "Epoch: 171/5000-------------------------------------------\n",
      "Train -> Loss: 0.000522493617609 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141814202070236 Acc: 0.250000000000000\n",
      "Epoch: 172/5000-------------------------------------------\n",
      "Train -> Loss: 0.000518862565514 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141873180866241 Acc: 0.250000000000000\n",
      "Epoch: 173/5000-------------------------------------------\n",
      "Train -> Loss: 0.000515272608027 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141931816935539 Acc: 0.250000000000000\n",
      "Epoch: 174/5000-------------------------------------------\n",
      "Train -> Loss: 0.000511723104864 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.141990095376968 Acc: 0.250000000000000\n",
      "Epoch: 175/5000-------------------------------------------\n",
      "Train -> Loss: 0.000508213066496 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142047986388206 Acc: 0.250000000000000\n",
      "Epoch: 176/5000-------------------------------------------\n",
      "Train -> Loss: 0.000504740164615 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142105519771576 Acc: 0.250000000000000\n",
      "Epoch: 177/5000-------------------------------------------\n",
      "Train -> Loss: 0.000501306727529 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142162695527077 Acc: 0.250000000000000\n",
      "Epoch: 178/5000-------------------------------------------\n",
      "Train -> Loss: 0.000497910426930 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142219543457031 Acc: 0.250000000000000\n",
      "Epoch: 179/5000-------------------------------------------\n",
      "Train -> Loss: 0.000494550680742 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142276003956795 Acc: 0.250000000000000\n",
      "Epoch: 180/5000-------------------------------------------\n",
      "Train -> Loss: 0.000491227954626 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142332151532173 Acc: 0.250000000000000\n",
      "Epoch: 181/5000-------------------------------------------\n",
      "Train -> Loss: 0.000487941055326 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142387956380844 Acc: 0.250000000000000\n",
      "Epoch: 182/5000-------------------------------------------\n",
      "Train -> Loss: 0.000484689633595 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142443388700485 Acc: 0.250000000000000\n",
      "Epoch: 183/5000-------------------------------------------\n",
      "Train -> Loss: 0.000481472292449 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142498522996902 Acc: 0.250000000000000\n",
      "Epoch: 184/5000-------------------------------------------\n",
      "Train -> Loss: 0.000478289584862 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142553299665451 Acc: 0.250000000000000\n",
      "Epoch: 185/5000-------------------------------------------\n",
      "Train -> Loss: 0.000475140521303 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142607763409615 Acc: 0.250000000000000\n",
      "Epoch: 186/5000-------------------------------------------\n",
      "Train -> Loss: 0.000472025130875 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142661914229393 Acc: 0.250000000000000\n",
      "Epoch: 187/5000-------------------------------------------\n",
      "Train -> Loss: 0.000468942191219 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142715692520142 Acc: 0.250000000000000\n",
      "Epoch: 188/5000-------------------------------------------\n",
      "Train -> Loss: 0.000465891993372 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142769202589989 Acc: 0.250000000000000\n",
      "Epoch: 189/5000-------------------------------------------\n",
      "Train -> Loss: 0.000462873780634 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142822384834290 Acc: 0.250000000000000\n",
      "Epoch: 190/5000-------------------------------------------\n",
      "Train -> Loss: 0.000459886417957 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142875224351883 Acc: 0.250000000000000\n",
      "Epoch: 191/5000-------------------------------------------\n",
      "Train -> Loss: 0.000456930662040 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142927795648575 Acc: 0.250000000000000\n",
      "Epoch: 192/5000-------------------------------------------\n",
      "Train -> Loss: 0.000454004883068 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.142980054020882 Acc: 0.250000000000000\n",
      "Epoch: 193/5000-------------------------------------------\n",
      "Train -> Loss: 0.000451109372079 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143031984567642 Acc: 0.250000000000000\n",
      "Epoch: 194/5000-------------------------------------------\n",
      "Train -> Loss: 0.000448243721621 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143083617091179 Acc: 0.250000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 195/5000-------------------------------------------\n",
      "Train -> Loss: 0.000445407000370 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143134951591492 Acc: 0.250000000000000\n",
      "Epoch: 196/5000-------------------------------------------\n",
      "Train -> Loss: 0.000442598800873 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143185988068581 Acc: 0.250000000000000\n",
      "Epoch: 197/5000-------------------------------------------\n",
      "Train -> Loss: 0.000439819938038 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143236756324768 Acc: 0.250000000000000\n",
      "Epoch: 198/5000-------------------------------------------\n",
      "Train -> Loss: 0.000437069422333 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143287211656570 Acc: 0.250000000000000\n",
      "Epoch: 199/5000-------------------------------------------\n",
      "Train -> Loss: 0.000434345449321 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143337398767471 Acc: 0.250000000000000\n",
      "Epoch: 200/5000-------------------------------------------\n",
      "Train -> Loss: 0.000431649037637 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143387302756310 Acc: 0.250000000000000\n",
      "Epoch: 201/5000-------------------------------------------\n",
      "Train -> Loss: 0.000428979954449 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143436908721924 Acc: 0.250000000000000\n",
      "Epoch: 202/5000-------------------------------------------\n",
      "Train -> Loss: 0.000426337064710 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143486246466637 Acc: 0.250000000000000\n",
      "Epoch: 203/5000-------------------------------------------\n",
      "Train -> Loss: 0.000423720252002 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143535286188126 Acc: 0.250000000000000\n",
      "Epoch: 204/5000-------------------------------------------\n",
      "Train -> Loss: 0.000421129341703 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143584057688713 Acc: 0.250000000000000\n",
      "Epoch: 205/5000-------------------------------------------\n",
      "Train -> Loss: 0.000418564130086 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143632575869560 Acc: 0.250000000000000\n",
      "Epoch: 206/5000-------------------------------------------\n",
      "Train -> Loss: 0.000416023482103 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143680825829506 Acc: 0.250000000000000\n",
      "Epoch: 207/5000-------------------------------------------\n",
      "Train -> Loss: 0.000413508067140 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143728777766228 Acc: 0.250000000000000\n",
      "Epoch: 208/5000-------------------------------------------\n",
      "Train -> Loss: 0.000411016982980 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143776491284370 Acc: 0.250000000000000\n",
      "Epoch: 209/5000-------------------------------------------\n",
      "Train -> Loss: 0.000408550491557 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143823951482773 Acc: 0.250000000000000\n",
      "Epoch: 210/5000-------------------------------------------\n",
      "Train -> Loss: 0.000406106963055 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143871143460274 Acc: 0.250000000000000\n",
      "Epoch: 211/5000-------------------------------------------\n",
      "Train -> Loss: 0.000403687503422 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143918052315712 Acc: 0.250000000000000\n",
      "Epoch: 212/5000-------------------------------------------\n",
      "Train -> Loss: 0.000401290657464 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.143964737653732 Acc: 0.250000000000000\n",
      "Epoch: 213/5000-------------------------------------------\n",
      "Train -> Loss: 0.000398917123675 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144011154770851 Acc: 0.250000000000000\n",
      "Epoch: 214/5000-------------------------------------------\n",
      "Train -> Loss: 0.000396566145355 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144057303667068 Acc: 0.250000000000000\n",
      "Epoch: 215/5000-------------------------------------------\n",
      "Train -> Loss: 0.000394237198634 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144103258848190 Acc: 0.250000000000000\n",
      "Epoch: 216/5000-------------------------------------------\n",
      "Train -> Loss: 0.000391930254409 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144148916006088 Acc: 0.250000000000000\n",
      "Epoch: 217/5000-------------------------------------------\n",
      "Train -> Loss: 0.000389645370888 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144194334745407 Acc: 0.250000000000000\n",
      "Epoch: 218/5000-------------------------------------------\n",
      "Train -> Loss: 0.000387381733162 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144239544868469 Acc: 0.250000000000000\n",
      "Epoch: 219/5000-------------------------------------------\n",
      "Train -> Loss: 0.000385139195714 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144284471869469 Acc: 0.250000000000000\n",
      "Epoch: 220/5000-------------------------------------------\n",
      "Train -> Loss: 0.000382917583920 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144329205155373 Acc: 0.250000000000000\n",
      "Epoch: 221/5000-------------------------------------------\n",
      "Train -> Loss: 0.000380716111977 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144373670220375 Acc: 0.250000000000000\n",
      "Epoch: 222/5000-------------------------------------------\n",
      "Train -> Loss: 0.000378535769414 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144417911767960 Acc: 0.250000000000000\n",
      "Epoch: 223/5000-------------------------------------------\n",
      "Train -> Loss: 0.000376374868210 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144461914896965 Acc: 0.250000000000000\n",
      "Epoch: 224/5000-------------------------------------------\n",
      "Train -> Loss: 0.000374233699404 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144505709409714 Acc: 0.250000000000000\n",
      "Epoch: 225/5000-------------------------------------------\n",
      "Train -> Loss: 0.000372112583136 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144549265503883 Acc: 0.250000000000000\n",
      "Epoch: 226/5000-------------------------------------------\n",
      "Train -> Loss: 0.000370010617189 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144592598080635 Acc: 0.250000000000000\n",
      "Epoch: 227/5000-------------------------------------------\n",
      "Train -> Loss: 0.000367927859770 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144635707139969 Acc: 0.250000000000000\n",
      "Epoch: 228/5000-------------------------------------------\n",
      "Train -> Loss: 0.000365863583283 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144678562879562 Acc: 0.250000000000000\n",
      "Epoch: 229/5000-------------------------------------------\n",
      "Train -> Loss: 0.000363817758625 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144721224904060 Acc: 0.250000000000000\n",
      "Epoch: 230/5000-------------------------------------------\n",
      "Train -> Loss: 0.000361790880561 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144763678312302 Acc: 0.250000000000000\n",
      "Epoch: 231/5000-------------------------------------------\n",
      "Train -> Loss: 0.000359782337910 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144805908203125 Acc: 0.250000000000000\n",
      "Epoch: 232/5000-------------------------------------------\n",
      "Train -> Loss: 0.000357791199349 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144847914576530 Acc: 0.250000000000000\n",
      "Epoch: 233/5000-------------------------------------------\n",
      "Train -> Loss: 0.000355817785021 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144889712333679 Acc: 0.250000000000000\n",
      "Epoch: 234/5000-------------------------------------------\n",
      "Train -> Loss: 0.000353862094926 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144931316375732 Acc: 0.250000000000000\n",
      "Epoch: 235/5000-------------------------------------------\n",
      "Train -> Loss: 0.000351923343260 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.144972696900368 Acc: 0.250000000000000\n",
      "Epoch: 236/5000-------------------------------------------\n",
      "Train -> Loss: 0.000350002257619 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145013853907585 Acc: 0.250000000000000\n",
      "Epoch: 237/5000-------------------------------------------\n",
      "Train -> Loss: 0.000348097237293 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145054817199707 Acc: 0.250000000000000\n",
      "Epoch: 238/5000-------------------------------------------\n",
      "Train -> Loss: 0.000346209591953 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145095586776733 Acc: 0.250000000000000\n",
      "Epoch: 239/5000-------------------------------------------\n",
      "Train -> Loss: 0.000344338419382 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145136132836342 Acc: 0.250000000000000\n",
      "Epoch: 240/5000-------------------------------------------\n",
      "Train -> Loss: 0.000342482875567 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145176500082016 Acc: 0.250000000000000\n",
      "Epoch: 241/5000-------------------------------------------\n",
      "Train -> Loss: 0.000340643950040 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145216673612595 Acc: 0.250000000000000\n",
      "Epoch: 242/5000-------------------------------------------\n",
      "Train -> Loss: 0.000338820304023 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145256623625755 Acc: 0.250000000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 243/5000-------------------------------------------\n",
      "Train -> Loss: 0.000337012606906 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145296379923820 Acc: 0.250000000000000\n",
      "Epoch: 244/5000-------------------------------------------\n",
      "Train -> Loss: 0.000335220945999 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145335987210274 Acc: 0.250000000000000\n",
      "Epoch: 245/5000-------------------------------------------\n",
      "Train -> Loss: 0.000333444011630 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145375341176987 Acc: 0.250000000000000\n",
      "Epoch: 246/5000-------------------------------------------\n",
      "Train -> Loss: 0.000331682473188 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145414546132088 Acc: 0.250000000000000\n",
      "Epoch: 247/5000-------------------------------------------\n",
      "Train -> Loss: 0.000329935108311 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145453542470932 Acc: 0.250000000000000\n",
      "Epoch: 248/5000-------------------------------------------\n",
      "Train -> Loss: 0.000328203284880 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145492330193520 Acc: 0.250000000000000\n",
      "Epoch: 249/5000-------------------------------------------\n",
      "Train -> Loss: 0.000326486217091 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145530954003334 Acc: 0.250000000000000\n",
      "Epoch: 250/5000-------------------------------------------\n",
      "Train -> Loss: 0.000324783293763 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145569398999214 Acc: 0.250000000000000\n",
      "Epoch: 251/5000-------------------------------------------\n",
      "Train -> Loss: 0.000323094544001 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145607665181160 Acc: 0.250000000000000\n",
      "Epoch: 252/5000-------------------------------------------\n",
      "Train -> Loss: 0.000321419909596 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145645737648010 Acc: 0.250000000000000\n",
      "Epoch: 253/5000-------------------------------------------\n",
      "Train -> Loss: 0.000319759506965 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145683616399765 Acc: 0.250000000000000\n",
      "Epoch: 254/5000-------------------------------------------\n",
      "Train -> Loss: 0.000318112928653 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145721301436424 Acc: 0.250000000000000\n",
      "Epoch: 255/5000-------------------------------------------\n",
      "Train -> Loss: 0.000316479738103 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145758882164955 Acc: 0.250000000000000\n",
      "Epoch: 256/5000-------------------------------------------\n",
      "Train -> Loss: 0.000314860051731 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145796224474907 Acc: 0.250000000000000\n",
      "Epoch: 257/5000-------------------------------------------\n",
      "Train -> Loss: 0.000313253403874 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145833417773247 Acc: 0.250000000000000\n",
      "Epoch: 258/5000-------------------------------------------\n",
      "Train -> Loss: 0.000311660463922 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145870402455330 Acc: 0.250000000000000\n",
      "Epoch: 259/5000-------------------------------------------\n",
      "Train -> Loss: 0.000310079980409 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145907238125801 Acc: 0.250000000000000\n",
      "Epoch: 260/5000-------------------------------------------\n",
      "Train -> Loss: 0.000308512389893 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145943894982338 Acc: 0.250000000000000\n",
      "Epoch: 261/5000-------------------------------------------\n",
      "Train -> Loss: 0.000306958216242 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.145980373024940 Acc: 0.250000000000000\n",
      "Epoch: 262/5000-------------------------------------------\n",
      "Train -> Loss: 0.000305415684124 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.146016702055931 Acc: 0.250000000000000\n",
      "Epoch: 263/5000-------------------------------------------\n",
      "Train -> Loss: 0.000303886423353 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.146052867174149 Acc: 0.250000000000000\n",
      "Epoch: 264/5000-------------------------------------------\n",
      "Train -> Loss: 0.000302369444398 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.146088853478432 Acc: 0.250000000000000\n",
      "Epoch: 265/5000-------------------------------------------\n",
      "Train -> Loss: 0.000300864019664 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.146124705672264 Acc: 0.250000000000000\n",
      "Epoch: 266/5000-------------------------------------------\n",
      "Train -> Loss: 0.000299370934954 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.146160349249840 Acc: 0.250000000000000\n",
      "Epoch: 267/5000-------------------------------------------\n",
      "Train -> Loss: 0.000297889579087 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.146195814013481 Acc: 0.250000000000000\n",
      "Epoch: 268/5000-------------------------------------------\n",
      "Train -> Loss: 0.000296420301311 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.146231174468994 Acc: 0.250000000000000\n",
      "Epoch: 269/5000-------------------------------------------\n",
      "Train -> Loss: 0.000294962723274 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.146266341209412 Acc: 0.250000000000000\n",
      "Epoch: 270/5000-------------------------------------------\n",
      "Train -> Loss: 0.000293516146485 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.146301388740540 Acc: 0.250000000000000\n",
      "Epoch: 271/5000-------------------------------------------\n",
      "Train -> Loss: 0.000292081356747 Acc: 0.250000000000000\n",
      "Valid -> Loss: 0.146336242556572 Acc: 0.250000000000000\n"
     ]
    }
   ],
   "source": [
    "all_idx = np.arange(len(data))\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    for valid_idx in range(len(data)):\n",
    "        \n",
    "        train_idx = np.setdiff1d(all_idx, train_idx)\n",
    "        X_train = data[train_idx]\n",
    "        Y_train = targets[train_idx]\n",
    "        X_valid = data[valid_idx]\n",
    "        Y_valid = targets[valid_idx]\n",
    "    \n",
    "        model.train()\n",
    "\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        X_train.to(device)\n",
    "        output, hidden = model(X_train)\n",
    "        loss = criterion(output, Y_train.view(-1,len(ACTIONS_LIST)).float())\n",
    "        loss.backward() # Does backpropagation and calculates gradients\n",
    "        optimizer.step() # Updates the weights accordinglyw\n",
    "        \n",
    "        if epoch%10 == 0:\n",
    "\n",
    "            train_loss_arr = np.append(train_loss_arr, loss.item())\n",
    "            train_acc_arr  = np.append(train_acc_arr, get_acc(output, Y_train.reshape(-1, len(ACTIONS_LIST))))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            epoch_valid_losses = np.array([])\n",
    "            epoch_valid_acc = np.array([])\n",
    "            \n",
    "            output, hidden = model(X_valid)\n",
    "            loss = criterion(output, Y_valid.view(-1,len(ACTIONS_LIST)).float())\n",
    "            epoch_valid_losses = np.append(epoch_valid_losses, loss.item())\n",
    "            epoch_valid_acc = np.append( epoch_valid_acc, get_acc(output, Y_valid.reshape(-1, len(ACTIONS_LIST))) )\n",
    "\n",
    "            if first_epoch:\n",
    "                valid_loss_arr = epoch_valid_losses.reshape(-1, 1)\n",
    "                valid_acc_arr = epoch_valid_acc.reshape(-1, 1)\n",
    "                first_epoch = False\n",
    "            else:\n",
    "                valid_loss_arr = np.insert(valid_loss_arr, valid_loss_arr.shape[1], epoch_valid_losses, axis=1)\n",
    "                valid_acc_arr = np.insert(valid_acc_arr, valid_acc_arr.shape[1], epoch_valid_acc, axis=1)\n",
    "\n",
    "            valid_loss_mean_arr = np.append(valid_loss_mean_arr, np.mean(epoch_valid_losses))\n",
    "            valid_acc_mean_arr = np.append(valid_acc_mean_arr, np.mean(epoch_valid_acc))\n",
    "\n",
    "            loss_file.write(\"Epoch: {}/{}-------------------------------------------\\n\".format(epoch, n_epochs))\n",
    "            loss_file.write(\"Train -> Loss: {:.15f} Acc: {:.15f}\\n\".format(train_loss_arr[-1], train_acc_arr[-1]))\n",
    "            loss_file.write(\"Valid -> Loss: {:.15f} Acc: {:.15f}\\n\".format(valid_loss_mean_arr[-1], valid_acc_mean_arr[-1]))\n",
    "\n",
    "            print(\"Epoch: {}/{}-------------------------------------------\".format(epoch, n_epochs))\n",
    "            print(\"Train -> Loss: {:.15f} Acc: {:.15f}\".format(train_loss_arr[-1], train_acc_arr[-1]))\n",
    "            print(\"Valid -> Loss: {:.15f} Acc: {:.15f}\".format(valid_loss_mean_arr[-1], valid_acc_mean_arr[-1]))\n",
    "\n",
    "            if train_loss_arr[-1] < best_loss:\n",
    "                state = { 'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
    "                          'optimizer': optimizer.state_dict(), 'losslogger': loss.item(), }\n",
    "                torch.save(state, newpath + '/' + model_name)\n",
    "                best_loss = loss.item()\n",
    "            else:\n",
    "                print(\"model not saved\")\n",
    "\n",
    "            if (valid_loss_mean_arr[-1] < min_loss):\n",
    "                break\n",
    "        \n",
    "loss_file.close()\n",
    "np.savez(newpath + '/' + \"train_loss_arr\", train_loss_arr)\n",
    "np.savez(newpath + '/' + \"valid_loss_arr\", valid_loss_arr)\n",
    "np.savez(newpath + '/' + \"valid_loss_mean_arr\", valid_loss_mean_arr)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_processing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ab67be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for loss\n",
    "plt.clf()\n",
    "plt.plot(train_loss_arr, color='blue')\n",
    "plt.title('model train loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.yscale('log')\n",
    "plt.savefig(newpath + '/' + 'train_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.clf()\n",
    "plt.plot(valid_loss_mean_arr, color='blue')\n",
    "plt.title('model valid loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['valid'], loc='upper left')\n",
    "plt.yscale('log')\n",
    "plt.savefig(newpath + '/' + 'valid_loss_mean.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "liquid-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in range(len(X_train)):\n",
    "    # summarize history for loss\n",
    "    plt.clf()\n",
    "    plt.plot(valid_loss_arr[seq], color='blue')\n",
    "    plt.title('model valid loss ' + str(seq))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['valid'], loc='upper left')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(newpath + '/' + f'valid_loss_{seq}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
