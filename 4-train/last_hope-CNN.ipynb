{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be11962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [[  0, 52, 62, 80, 106, 117, 137, 142, 156, 159, 166, 185, 215, 226, 235, 242, 252, 259, 279, 281, 292, 296, 299, \n",
    "                303, 308, 315, 318, 321, 329, 333, 335, 354, 360, 374, 377, 382, 386, 390, 393, 402, 414, 420, 444, 447, \n",
    "                465, 469, 487, 491, 504, 506, 510, 513, 525, 528, 538, 552, 558, 570, 576, 581, 584, 588, 595, 598, 604, \n",
    "                607, 610, 618, 619, 622, 631, 641, 645, 662, 672, 685, 693, 697, 704, 718, 724, 726, 735, 739, 745, 754, \n",
    "                755, 770, 773, 789, 790, 799, 805, 809, 823, 834, 850, 854, 857, 868, 874, 875, 877, 883, 885, 904, 906, \n",
    "                911, 919, 923, 926, 932, 943, 962, 965, 984, 991, 999, 1007, 1010, 1015, 1017, 1018],\n",
    "           [   0, 31, 45, 47, 56, 63, 69, 85, 88, 92, 96, 112, 118, 124, 130, 137, 143, 151, 158, 170, 184, 202, 223, 243, 249,\n",
    "             255,260,269,272,275,276,282,285,295,296,297,306,308,318,322,331,334,337,338,341,343,354,357,381,387,400,402,408,\n",
    "             420,423,426,429,441,443,445,448,454,463,465,474,481,502,506,524,533,538,548,556,562,566,570,581,588,603,604,609,\n",
    "             652,668,681,698,710,714,725,729,736,739,743,748,749,752,766,770,774,778,781,792,795,803,804,806,814,818,821,828,\n",
    "             834,837,843,849,855,862,868,874,884,888,895,896,919,935,942,945,957,958,963,964,965,977,980,984,989,997,1000],\n",
    "           [   0,37,53,81,94,99,119,123,124,142,144,146,162,193,211,213,222,230,232,235,238,240,252,255,258,267,270,275,\n",
    "                278,284,287,289,300,307,313,331,352,359,371,379,386,389,392,409,412,432,435,440,442,446,462,467,472,\n",
    "                506,527,531,535,553,557,561,571,579,589,602,607,609,612,616,621,631,634,638,640,644,645,661,669,673,676,\n",
    "                692,695,698,701,711,717,720,721,734,744,747,750,755,759,774,785,793,807,859,891,895,912,927,948,958,969,\n",
    "                980,997,998,1004],\n",
    "           [   0,33,58,75,86,100,118,120,139,142,147,159,162,165,167,174,179,180,183,192,197,199,209,214,217,222,227,231,\n",
    "                232,239,244,251,262,266,271,275,277,282,287,291,294,297,308,311,316,318,322,327,339,342,348,352,362,372,\n",
    "                383,397,399,402,405,417,420, 425,428,454,457,464,470,477,481,485,488,494,495,503,507,517,535,537,540,553,\n",
    "                556,558,577,588,598,601,609,620,634,638,647,650,656,659,660,663,669,672,681,684,696,702,705,708,716,719,726,\n",
    "                730,739,743,746,758,765,766,777,783,785,786,790,792,800,802,808,809,810,816,819,823,827,835,837,842,845,853,\n",
    "                865,868,873,885,889,891,897,904,906,918,941,949,956,961,969,973,976,981,984,991,996,999,1002],\n",
    "           [   0,59,68,73,76,86,94,97,101,104,109,118,120,123,128,134,136,139,143,145,148,154,160,162,177,190,195,199,204,\n",
    "                208,212,220,221,222,232,234,246,251,253,256,263,270,273,287,302,314,322,355,357,368,396,397,401,416,428,433,\n",
    "                437,442,446,452,456,469,475,490,500,506,525,526,538,545,551,554,558,562,571,579,582,586,587,600,612,664,823,\n",
    "                824,832,850,858,870,879,881,889,898,901,913,916,924,932,936,943,952,955,975,985,992,997,1001],\n",
    "           [   0,36,56,94,114,121,136,140,143,153,159,162,171,174,182,190,197,201,215,219,237,239,249,251,254,265,269,297,322,\n",
    "                335,340,343,348,352,355,363,368,371,375,384,388,395,405,411,439,461,464,468,477,483,485,487,494,497,501,503,\n",
    "                514,519,521,526,529,532,538,547,551,555,560,579,584,597,600,602,607,609,617,623,626,634,638,644,649,652,663,\n",
    "                671,672,675,678,685,688,699,700,712,719,724,726,735,744,753,756,775,797,806,812,818,826,829,832,848,852,856,\n",
    "                866,869,872,875,881,886,891,893,895,901,910,930,936,940,953,958,989,997,1004,1006] \n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f456a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from enduro_lstm import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2398e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU (y/n) n\n",
      "Selected CPU\n"
     ]
    }
   ],
   "source": [
    "use_gpu = input(\"Use GPU (y/n) \")\n",
    "\n",
    "if use_gpu == 'y':\n",
    "    use_gpu = True\n",
    "else:\n",
    "    use_gpu = False\n",
    "    \n",
    "device = conf_cuda(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36512f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escreva uma observacao (sem espaco): teste_cnn\n"
     ]
    }
   ],
   "source": [
    "obs = input('escreva uma observacao (sem espaco): ')\n",
    "\n",
    "if obs == 'zigzag':\n",
    "    zigzag = True\n",
    "else:\n",
    "    zigzag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0825400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epochs: 10\n",
      "number of hidden neurons: 200\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"../1-generate/data/\"\n",
    "n_epochs = int(input(\"number of epochs: \") ) #5000\n",
    "hidden_neurons = int(input(\"number of hidden neurons: \")) #500\n",
    "stop_train = 1e-5\n",
    "\n",
    "# start_match = int(input(\"start match: \")) #45\n",
    "# end_match = int(input(\"end match: \")) #49\n",
    "\n",
    "start_match = 35\n",
    "end_match = 35\n",
    "\n",
    "# start_frame = int(input(\"start frame: \")) #1\n",
    "# end_frame = int(input(\"end frame: \")) #1000\n",
    "\n",
    "start_frame = 1\n",
    "end_frame = 120\n",
    "\n",
    "is_softmax = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0461f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/teste_cnn_m35to35_f1to120_epoch10_H200\n",
      "ATTENTION! folder not created. Training informations will overwrite the existing one\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"{obs}_m{start_match}to{end_match}_f{start_frame}to{end_frame}_epoch{n_epochs}_H{hidden_neurons}\"\n",
    "newpath = f\"models/\" + model_name\n",
    "if not os.path.exists(newpath):\n",
    "    print(f\"models/\" + model_name + \" created\")\n",
    "    os.makedirs(newpath)\n",
    "else:\n",
    "    print(f\"models/\" + model_name)\n",
    "    print(\"ATTENTION! folder not created. Training informations will overwrite the existing one\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7bc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS_LIST = get_actions_list(zigzag=zigzag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f65c5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded NPZ.\n"
     ]
    }
   ],
   "source": [
    "num_of_frames_arr = []\n",
    "frames_arr = []\n",
    "actions_arr = []\n",
    "\n",
    "for m in range(start_match, end_match + 1):\n",
    "    \n",
    "    num_of_frames, frames, actions, rewards, lifes = load_npz(data_path, m)\n",
    "    frames = frames[start_frame - 1:end_frame]\n",
    "    frames = frames.reshape(end_frame - start_frame + 1, 170, 120)\n",
    "    frames = frames[:, 30:130, 10:110]\n",
    "    frames = frames.reshape(end_frame - start_frame + 1, 100, 100)\n",
    "    actions = actions[start_frame - 1:end_frame]\n",
    "    \n",
    "    action_one_hot = [prepare_action_data(i, ACTIONS_LIST) for i in actions]\n",
    "    actions = np.array(action_one_hot)\n",
    "    actions = actions.reshape(len(actions), -1)\n",
    "    \n",
    "    frames_arr.append(frames)\n",
    "    actions_arr.append(actions)\n",
    "    num_of_frames_arr.append(end_frame - start_frame + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f87921",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(frames_arr)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c241dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = actions_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14d62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(map(lambda x: torch.tensor(x), X_train))\n",
    "Y_train = list(map(lambda x: torch.tensor(x), Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa5af117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([120.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = torch.FloatTensor(list(map(len,X_train)))\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22bcba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequence(X_train, batch_first=True).float()\n",
    "Y_train = pad_sequence(Y_train, batch_first=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd2f5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0569ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    X_train = X_train.cuda() \n",
    "    Y_train = Y_train.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fce6db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 1e-05\n",
    "# Define Loss, Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2565608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_arr = np.array([])\n",
    "train_acc_arr = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98711684",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [500, 1, 5, 5], expected input[1, 120, 100, 100] to have 1 channels, but got 120 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-9656028c1723>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Clears existing gradients from previous epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mACTIONS_LIST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Does backpropagation and calculates gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\UnB\\tcc\\rnn_enduro\\2-lstm_train\\enduro_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[1;32m--> 396\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [500, 1, 5, 5], expected input[1, 120, 100, 100] to have 1 channels, but got 120 channels instead"
     ]
    }
   ],
   "source": [
    "start_time_processing = time.time()\n",
    "\n",
    "# Training Run\n",
    "loss_file = open(newpath + '/' + \"loss_file.txt\", \"w\")\n",
    "first_time = True\n",
    "\n",
    "best_loss = 1\n",
    "first_epoch = True\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    X_train.to(device)\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, Y_train.view(-1,len(ACTIONS_LIST)).float())\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordinglyw\n",
    "        \n",
    "    if epoch%10 == 0:\n",
    "\n",
    "        train_loss_arr = np.append(train_loss_arr, loss.item())\n",
    "        train_acc_arr  = np.append(train_acc_arr, get_acc(output, Y_train.reshape(-1, len(ACTIONS_LIST))))\n",
    "        # train_acc_arr  = np.append(train_acc_arr, get_acc_2(output, target_padded.reshape(-1, len(ACTIONS_LIST))))\n",
    "        \n",
    "        loss_file.write(\"Epoch: {}/{}-------------------------------------------\\n\".format(epoch, n_epochs))\n",
    "        loss_file.write(\"Train -> Loss: {:.15f} Acc: {:.15f}\\n\".format(train_loss_arr[-1], train_acc_arr[-1]))\n",
    "            \n",
    "        print(\"Epoch: {}/{}-------------------------------------------\".format(epoch, n_epochs))\n",
    "        print(\"Train -> Loss: {:.15f} Acc: {:.15f}\".format(train_loss_arr[-1], train_acc_arr[-1]))\n",
    "        \n",
    "        if train_loss_arr[-1] < best_loss:\n",
    "            state = { 'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
    "                      'optimizer': optimizer.state_dict(), 'losslogger': loss.item(), }\n",
    "            torch.save(state, newpath + '/' + model_name)\n",
    "            best_loss = loss.item()\n",
    "        else:\n",
    "            print(\"model not saved\")\n",
    "            \n",
    "loss_file.write(\"--- %s seconds ---\" % (time.time() - start_time_processing))\n",
    "loss_file.close()\n",
    "np.savez(newpath + '/' + \"train_loss_arr\", train_loss_arr)\n",
    "#np.savez(newpath + '/' + \"valid_acc_table\", valid_loss_mean_arr)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_processing))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
